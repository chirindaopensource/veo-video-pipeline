{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43hAjVCIO7jC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Essential Modules"
      ],
      "metadata": {
        "id": "yEWjetm1PRoV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eslPBZiqPUVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementations"
      ],
      "metadata": {
        "id": "VcsKZbXJPVX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## o3 Draft"
      ],
      "metadata": {
        "id": "gq1e6ftjPXY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "video_chain_vertex_ai.py\n",
        "Industrial-grade pipeline for chained video generation using\n",
        "Google Vertex-AI VEO-2.  © MIT CSAIL 2024\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "# ──────────────────────────────────────────────────────────\n",
        "# Standard library\n",
        "import os\n",
        "import io\n",
        "import json\n",
        "import shutil\n",
        "import logging\n",
        "from contextlib import contextmanager\n",
        "from pathlib import Path\n",
        "from typing import List, Generator, Tuple\n",
        "\n",
        "# ──────────────────────────────────────────────────────────\n",
        "# Third-party\n",
        "import cv2  # OpenCV-Python\n",
        "import numpy as np\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips  # type: ignore\n",
        "\n",
        "from google.api_core.exceptions import GoogleAPICallError\n",
        "from google.auth.exceptions import DefaultCredentialsError\n",
        "import vertexai\n",
        "from vertexai.preview.generative_models import (\n",
        "    GenerativeModel,\n",
        "    VideoGenerationResponse,\n",
        "    Image as VertexImage,\n",
        ")\n",
        "\n",
        "# ──────────────────────────────────────────────────────────\n",
        "# Logging config\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
        ")\n",
        "LOGGER = logging.getLogger(\"video_chain_vertex_ai\")\n",
        "\n",
        "\n",
        "# ──────────────────────────────────────────────────────────\n",
        "# Helper context manager for Vertex calls\n",
        "@contextmanager\n",
        "def vertex_error_guard(step_description: str) -> Generator[None, None, None]:\n",
        "    \"\"\"\n",
        "    Context manager that converts Google API errors into user-friendly RuntimeError.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    step_description : str\n",
        "        Human-readable description of the API step, for logging and error messages.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        yield\n",
        "    except (GoogleAPICallError, DefaultCredentialsError) as err:\n",
        "        LOGGER.error(\"Vertex-AI failure during %s: %s\", step_description, err)\n",
        "        raise RuntimeError(f\"Vertex-AI failure during {step_description}\") from err\n",
        "\n",
        "\n",
        "# ──────────────────────────────────────────────────────────\n",
        "# Main public callable\n",
        "def generate_chained_videos(\n",
        "    reference_image_path: str,\n",
        "    prompts: List[str],\n",
        "    api_key: str,\n",
        "    output_folder_name: str,\n",
        "    *,\n",
        "    project: str | None = None,\n",
        "    location: str = \"us-central1\",\n",
        "    video_duration: int = 6,\n",
        "    fps: int = 24,\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    Generate a chain of videos from an initial still image & prompt list using\n",
        "    Vertex-AI VEO-2, then concatenate them into a single final video.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    reference_image_path : str\n",
        "        Absolute or relative path of the seed image.\n",
        "    prompts : List[str]\n",
        "        Ordered list of textual scene descriptions.\n",
        "    api_key : str\n",
        "        Vertex-AI API key (will be injected into env var GOOGLE_API_KEY).\n",
        "    output_folder_name : str\n",
        "        Name of the folder (created inside user `$HOME`) that will store videos.\n",
        "    project : str | None, optional\n",
        "        GCP project ID.  If None, uses env var GOOGLE_CLOUD_PROJECT.\n",
        "    location : str, optional\n",
        "        Vertex region; default 'us-central1'.\n",
        "    video_duration : int, optional\n",
        "        Duration **per prompt** in seconds (uniform to ease concatenation).\n",
        "    fps : int, optional\n",
        "        Frames-per-second for generated videos.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Path\n",
        "        Absolute path to the stitched final video `<out_dir>/final.mp4`.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    FileNotFoundError\n",
        "        If the reference image does not exist.\n",
        "    ValueError\n",
        "        For empty prompt list or invalid arguments.\n",
        "    RuntimeError\n",
        "        On Vertex-AI failures or OpenCV processing problems.\n",
        "    \"\"\"\n",
        "    # ──────────────────────────────────────────────────────\n",
        "    # 0. Input validation\n",
        "    ref_path = Path(reference_image_path).expanduser().resolve()\n",
        "    if not ref_path.exists() or not ref_path.is_file():\n",
        "        raise FileNotFoundError(f\"Reference image not found: {ref_path}\")\n",
        "    if not prompts:\n",
        "        raise ValueError(\"Prompts list is empty.\")\n",
        "    if not api_key.strip():\n",
        "        raise ValueError(\"API key is empty.\")\n",
        "    if not output_folder_name.strip():\n",
        "        raise ValueError(\"Output folder name is empty.\")\n",
        "\n",
        "    # ──────────────────────────────────────────────────────\n",
        "    # 1. Create output directory in $HOME\n",
        "    out_dir = Path.home() / output_folder_name\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    LOGGER.info(\"Output directory: %s\", out_dir)\n",
        "\n",
        "    # ──────────────────────────────────────────────────────\n",
        "    # 2. Read reference image\n",
        "    reference_bgr = cv2.imread(str(ref_path))\n",
        "    if reference_bgr is None:\n",
        "        raise RuntimeError(f\"OpenCV could not decode image: {ref_path}\")\n",
        "    # Convert last frame to PNG bytes for Vertex\n",
        "    reference_png_bytes = _encode_frame_to_png(reference_bgr)\n",
        "\n",
        "    # ──────────────────────────────────────────────────────\n",
        "    # 3. Initialise Vertex-AI client (once)\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "    vertexai.init(project=project, location=location)\n",
        "    model = GenerativeModel(\"veo@002\")\n",
        "\n",
        "    # Uniform video_config dict\n",
        "    video_cfg = {\n",
        "        \"duration\": f\"{video_duration}s\",\n",
        "        \"fps\": fps,\n",
        "        \"format\": \"MP4\",\n",
        "    }\n",
        "\n",
        "    # Keep path list for later concatenation\n",
        "    generated_paths: List[Path] = []\n",
        "\n",
        "    # ──────────────────────────────────────────────────────\n",
        "    # 4. Iterate over prompts\n",
        "    last_frame_bytes = reference_png_bytes  # first iteration seed\n",
        "    for idx, prompt in enumerate(prompts, start=1):\n",
        "        video_mode = \"GENERATE\" if idx == 1 else \"EDIT\"\n",
        "        filename = f\"{idx}.mp4\"\n",
        "        video_path = out_dir / filename\n",
        "        LOGGER.info(\"↳  Generating video #%d (%s) …\", idx, video_mode)\n",
        "\n",
        "        # Build request payload\n",
        "        vertex_images = [VertexImage.from_bytes(last_frame_bytes)]\n",
        "        request_payload = {\n",
        "            \"prompt\": prompt,\n",
        "            \"images\": vertex_images,\n",
        "            \"video_config\": {**video_cfg, \"video_mode\": video_mode},\n",
        "        }\n",
        "\n",
        "        # Call Vertex-AI VEO-2\n",
        "        with vertex_error_guard(f\"video generation #{idx}\"):\n",
        "            response: VideoGenerationResponse = model.generate_video(**request_payload)\n",
        "\n",
        "        # Save video bytes\n",
        "        _dump_vertex_video_to_disk(response, video_path)\n",
        "        generated_paths.append(video_path)\n",
        "\n",
        "        # Decompose & grab last frame for next iteration\n",
        "        last_frame_bgr = _extract_last_frame(video_path)\n",
        "        last_frame_bytes = _encode_frame_to_png(last_frame_bgr)\n",
        "\n",
        "    # ──────────────────────────────────────────────────────\n",
        "    # 5. Concatenate all videos into final.mp4\n",
        "    final_path = out_dir / \"final.mp4\"\n",
        "    _concatenate_videos(generated_paths, final_path)\n",
        "    LOGGER.info(\"✅  Final stitched video written to %s\", final_path)\n",
        "\n",
        "    # ──────────────────────────────────────────────────────\n",
        "    # 6. Return path to caller for downstream usage\n",
        "    return final_path\n",
        "\n",
        "\n",
        "# ──────────────────────────────────────────────────────────\n",
        "# ----------------------- helper utils --------------------\n",
        "def _encode_frame_to_png(bgr_array: np.ndarray) -> bytes:\n",
        "    \"\"\"\n",
        "    Convert a BGR image (OpenCV) to PNG bytes for Vertex.\n",
        "    \"\"\"\n",
        "    success, buf = cv2.imencode(\".png\", bgr_array)\n",
        "    if not success:\n",
        "        raise RuntimeError(\"OpenCV failed to encode frame to PNG.\")\n",
        "    return buf.tobytes()\n",
        "\n",
        "\n",
        "def _dump_vertex_video_to_disk(\n",
        "    response: VideoGenerationResponse,\n",
        "    out_path: Path,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Persist the video bytes contained in a Vertex response to disk.\n",
        "\n",
        "    The response contains:\n",
        "       • `response.media[0].data`  – raw bytes\n",
        "       • OR `response.media[0].uri` – GCS URI\n",
        "    We stream bytes for maximal portability.\n",
        "    \"\"\"\n",
        "    media = response.media[0]\n",
        "    if media.data:\n",
        "        video_bytes = media.data\n",
        "        out_path.write_bytes(video_bytes)\n",
        "    elif media.uri:\n",
        "        # Fallback: download from GCS URI\n",
        "        import requests  # local import to avoid hard dep\n",
        "        with requests.get(media.uri, stream=True, timeout=45) as r:\n",
        "            r.raise_for_status()\n",
        "            with out_path.open(\"wb\") as fh:\n",
        "                shutil.copyfileobj(r.raw, fh)\n",
        "    else:\n",
        "        raise RuntimeError(\"Vertex response contained neither data nor URI.\")\n",
        "\n",
        "\n",
        "def _extract_last_frame(video_path: Path) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Open `video_path` with OpenCV and return the last frame as BGR ndarray.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        raise RuntimeError(f\"Unable to open video: {video_path}\")\n",
        "    last_frame: np.ndarray | None = None\n",
        "    while True:\n",
        "        grabbed, frame = cap.read()\n",
        "        if not grabbed:\n",
        "            break\n",
        "        last_frame = frame\n",
        "    cap.release()\n",
        "    if last_frame is None:\n",
        "        raise RuntimeError(f\"No frames found in video: {video_path}\")\n",
        "    return last_frame\n",
        "\n",
        "\n",
        "def _concatenate_videos(video_paths: List[Path], out_path: Path) -> None:\n",
        "    \"\"\"\n",
        "    Concatenate a list of video files (same FPS & resolution) preserving order.\n",
        "    \"\"\"\n",
        "    clips = [VideoFileClip(str(p)) for p in video_paths]\n",
        "    final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
        "    final_clip.write_videofile(str(out_path), codec=\"libx264\", audio=False)\n",
        "    # Close resources to avoid memory leaks\n",
        "    final_clip.close()\n",
        "    for c in clips:\n",
        "        c.close()\n",
        "\n",
        "## 3.  Usage example\n",
        "\n",
        "from video_chain_vertex_ai import generate_chained_videos\n",
        "\n",
        "final_path = generate_chained_videos(\n",
        "    reference_image_path=\"/data/seed.jpg\",\n",
        "    prompts=[\n",
        "        \"A serene sunrise over a calm ocean, cinematic.\",\n",
        "        \"Clouds gather and a storm begins to brew, dramatic.\",\n",
        "        \"Rainbow appears as the storm clears, hopeful.\"\n",
        "    ],\n",
        "    api_key=\"AIza…your-key…\",\n",
        "    output_folder_name=\"ocean_story\",\n",
        "    project=\"my-gcp-project\",  # optional if ADC set\n",
        ")\n",
        "print(\"Stitched video is at:\", final_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "jmCz2TjmPb2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opus 4 Draft\n",
        "\n"
      ],
      "metadata": {
        "id": "8MWSRDk3QWtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "import time\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Dict, Any, Tuple\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import imageio\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "from google.cloud import aiplatform\n",
        "from google.oauth2 import service_account\n",
        "import vertexai\n",
        "from vertexai.preview.vision_models import Image as VertexImage, VideoGenerationModel\n",
        "\n",
        "# Configure logging for production-grade error tracking\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def generate_sequential_videos_with_veo2(\n",
        "    reference_image_path: str,\n",
        "    scene_prompts: List[str],\n",
        "    vertex_api_key: str,\n",
        "    output_folder_name: str\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    Generate a sequence of videos using Google's VEO-2 model, where each video\n",
        "    uses the last frame of the previous video as input.\n",
        "\n",
        "    This function implements a sequential video generation pipeline using VEO-2,\n",
        "    creating smooth transitions between scenes by using the last frame of each\n",
        "    generated video as the starting point for the next.\n",
        "\n",
        "    Args:\n",
        "        reference_image_path (str): File path to the initial reference image.\n",
        "            Must be a valid image file (JPEG, PNG, etc.).\n",
        "        scene_prompts (List[str]): List of prompts describing each scene to generate.\n",
        "            Each prompt should be descriptive and specific for best results.\n",
        "        vertex_api_key (str): Google Cloud Vertex AI API key for authentication.\n",
        "            Must have permissions for VEO-2 video generation.\n",
        "        output_folder_name (str): Name of the folder to create in home directory\n",
        "            for storing generated videos.\n",
        "\n",
        "    Returns:\n",
        "        Path: Path to the final stitched video file.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If inputs are invalid (empty prompts, invalid paths, etc.).\n",
        "        FileNotFoundError: If reference image doesn't exist.\n",
        "        PermissionError: If unable to create output directory.\n",
        "        RuntimeError: If video generation or processing fails.\n",
        "\n",
        "    Example:\n",
        "        >>> final_video = generate_sequential_videos_with_veo2(\n",
        "        ...     \"reference.jpg\",\n",
        "        ...     [\"Scene 1: Sunrise\", \"Scene 2: Noon\", \"Scene 3: Sunset\"],\n",
        "        ...     \"your-api-key\",\n",
        "        ...     \"generated_videos\"\n",
        "        ... )\n",
        "    \"\"\"\n",
        "    # Input validation to ensure all parameters meet requirements\n",
        "    if not reference_image_path or not os.path.exists(reference_image_path):\n",
        "        raise FileNotFoundError(f\"Reference image not found: {reference_image_path}\")\n",
        "\n",
        "    if not scene_prompts or not all(isinstance(p, str) and p.strip() for p in scene_prompts):\n",
        "        raise ValueError(\"Scene prompts must be a non-empty list of non-empty strings\")\n",
        "\n",
        "    if not vertex_api_key or not isinstance(vertex_api_key, str):\n",
        "        raise ValueError(\"Valid Vertex API key required\")\n",
        "\n",
        "    if not output_folder_name or not isinstance(output_folder_name, str):\n",
        "        raise ValueError(\"Output folder name must be a non-empty string\")\n",
        "\n",
        "    # Step 1: Create output directory in home directory\n",
        "    # Using pathlib for cross-platform compatibility\n",
        "    home_dir = Path.home()\n",
        "    output_dir = home_dir / output_folder_name\n",
        "\n",
        "    try:\n",
        "        # Create directory with parents if needed, exist_ok prevents errors if exists\n",
        "        output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        logger.info(f\"Created output directory: {output_dir}\")\n",
        "    except PermissionError as e:\n",
        "        raise PermissionError(f\"Unable to create directory {output_dir}: {e}\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Unexpected error creating directory: {e}\")\n",
        "\n",
        "    # Initialize Vertex AI with credentials\n",
        "    # Setting up authentication and project configuration\n",
        "    try:\n",
        "        # Initialize Vertex AI client with API key\n",
        "        # Note: In production, use service account credentials file\n",
        "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = vertex_api_key\n",
        "\n",
        "        # Initialize with your project and location\n",
        "        # These should be configured based on your Vertex AI setup\n",
        "        PROJECT_ID = \"your-project-id\"  # Replace with actual project ID\n",
        "        LOCATION = \"us-central1\"  # VEO-2 availability region\n",
        "\n",
        "        vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "        model = VideoGenerationModel.from_pretrained(\"veo-2\")\n",
        "\n",
        "        logger.info(\"Successfully initialized Vertex AI client\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Failed to initialize Vertex AI: {e}\")\n",
        "\n",
        "    # Step 2: Read reference image into memory\n",
        "    # Using PIL for robust image handling\n",
        "    try:\n",
        "        # Open and validate image\n",
        "        reference_image = Image.open(reference_image_path)\n",
        "\n",
        "        # Convert to RGB if necessary (handles RGBA, grayscale, etc.)\n",
        "        if reference_image.mode != 'RGB':\n",
        "            reference_image = reference_image.convert('RGB')\n",
        "\n",
        "        # Validate image dimensions for VEO-2 (recommended max 1024x1024)\n",
        "        max_dimension = 1024\n",
        "        if max(reference_image.size) > max_dimension:\n",
        "            # Resize maintaining aspect ratio\n",
        "            reference_image.thumbnail((max_dimension, max_dimension), Image.Resampling.LANCZOS)\n",
        "            logger.info(f\"Resized image to {reference_image.size}\")\n",
        "\n",
        "        logger.info(f\"Successfully loaded reference image: {reference_image.size}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Failed to load reference image: {e}\")\n",
        "\n",
        "    # List to store paths of all generated videos for final stitching\n",
        "    generated_video_paths: List[Path] = []\n",
        "\n",
        "    # Variable to track the current input image/frame for video generation\n",
        "    current_input_image = reference_image\n",
        "\n",
        "    # Step 3-5: Iterate through prompts and generate videos\n",
        "    for iteration_index, prompt in enumerate(scene_prompts):\n",
        "        try:\n",
        "            # Log current iteration for debugging\n",
        "            logger.info(f\"Processing iteration {iteration_index + 1}/{len(scene_prompts)}: {prompt[:50]}...\")\n",
        "\n",
        "            # Convert current image to format suitable for VEO-2 API\n",
        "            # VEO-2 expects base64-encoded image data\n",
        "            image_buffer = io.BytesIO()\n",
        "            current_input_image.save(image_buffer, format='PNG')\n",
        "            image_bytes = image_buffer.getvalue()\n",
        "\n",
        "            # Create VertexImage object for API\n",
        "            vertex_image = VertexImage(image_bytes)\n",
        "\n",
        "            # Generate video using VEO-2 with proper parameters\n",
        "            # Following VEO-2 API specifications from documentation\n",
        "            generation_params = {\n",
        "                \"prompt\": prompt,\n",
        "                \"image\": vertex_image,\n",
        "                \"duration\": 5,  # 5 seconds per video segment\n",
        "                \"fps\": 30,  # 30 frames per second for smooth playback\n",
        "                \"resolution\": \"720p\",  # Balance quality and processing time\n",
        "                \"aspect_ratio\": \"16:9\",  # Standard video aspect ratio\n",
        "            }\n",
        "\n",
        "            # Call VEO-2 model with retry logic for robustness\n",
        "            max_retries = 3\n",
        "            retry_delay = 5  # seconds\n",
        "\n",
        "            for retry in range(max_retries):\n",
        "                try:\n",
        "                    # Generate video using VEO-2\n",
        "                    logger.info(f\"Calling VEO-2 API (attempt {retry + 1}/{max_retries})\")\n",
        "\n",
        "                    video_response = model.generate_video(\n",
        "                        **generation_params\n",
        "                    )\n",
        "\n",
        "                    # Wait for video generation to complete\n",
        "                    # VEO-2 operations are asynchronous\n",
        "                    while not video_response.is_done():\n",
        "                        time.sleep(2)\n",
        "                        logger.info(\"Waiting for video generation to complete...\")\n",
        "\n",
        "                    # Retrieve generated video\n",
        "                    generated_video = video_response.result()\n",
        "                    break\n",
        "\n",
        "                except Exception as e:\n",
        "                    if retry < max_retries - 1:\n",
        "                        logger.warning(f\"VEO-2 API call failed, retrying in {retry_delay}s: {e}\")\n",
        "                        time.sleep(retry_delay)\n",
        "                    else:\n",
        "                        raise RuntimeError(f\"VEO-2 API call failed after {max_retries} attempts: {e}\")\n",
        "\n",
        "            # Save generated video with sequential naming\n",
        "            # Using 1-based indexing as specified\n",
        "            video_filename = f\"{iteration_index + 1}.mp4\"\n",
        "            video_path = output_dir / video_filename\n",
        "\n",
        "            # Write video data to file\n",
        "            with open(video_path, 'wb') as video_file:\n",
        "                video_file.write(generated_video.video_data)\n",
        "\n",
        "            logger.info(f\"Saved video: {video_path}\")\n",
        "            generated_video_paths.append(video_path)\n",
        "\n",
        "            # Decompose video into frames to extract last frame\n",
        "            # Using OpenCV for efficient frame extraction\n",
        "            cap = cv2.VideoCapture(str(video_path))\n",
        "\n",
        "            if not cap.isOpened():\n",
        "                raise RuntimeError(f\"Failed to open video: {video_path}\")\n",
        "\n",
        "            # Get total frame count for seeking to last frame\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "            if total_frames == 0:\n",
        "                raise RuntimeError(f\"Video has no frames: {video_path}\")\n",
        "\n",
        "            # Seek to last frame efficiently\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)\n",
        "\n",
        "            # Read the last frame\n",
        "            ret, last_frame = cap.read()\n",
        "            cap.release()\n",
        "\n",
        "            if not ret or last_frame is None:\n",
        "                raise RuntimeError(f\"Failed to extract last frame from video: {video_path}\")\n",
        "\n",
        "            # Convert OpenCV BGR format to RGB for PIL\n",
        "            last_frame_rgb = cv2.cvtColor(last_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Convert to PIL Image for next iteration\n",
        "            current_input_image = Image.fromarray(last_frame_rgb)\n",
        "\n",
        "            logger.info(f\"Extracted last frame for next iteration: {current_input_image.size}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in iteration {iteration_index + 1}: {e}\")\n",
        "            raise RuntimeError(f\"Video generation failed at iteration {iteration_index + 1}: {e}\")\n",
        "\n",
        "    # Step 6: Stitch all videos together into final video\n",
        "    try:\n",
        "        logger.info(f\"Stitching {len(generated_video_paths)} videos together...\")\n",
        "\n",
        "        # Load all video clips using moviepy\n",
        "        # MoviePy handles codec compatibility and frame rate normalization\n",
        "        video_clips = []\n",
        "\n",
        "        for video_path in generated_video_paths:\n",
        "            try:\n",
        "                clip = VideoFileClip(str(video_path))\n",
        "                video_clips.append(clip)\n",
        "                logger.info(f\"Loaded clip: {video_path.name} - Duration: {clip.duration}s\")\n",
        "            except Exception as e:\n",
        "                raise RuntimeError(f\"Failed to load video clip {video_path}: {e}\")\n",
        "\n",
        "        # Concatenate all clips in sequence\n",
        "        # Method='compose' ensures smooth transitions\n",
        "        final_video = concatenate_videoclips(video_clips, method=\"compose\")\n",
        "\n",
        "        # Define output path for final video\n",
        "        final_video_path = output_dir / \"final.mp4\"\n",
        "\n",
        "        # Write final video with optimal encoding settings\n",
        "        # codec='libx264' for wide compatibility, audio_codec for any audio tracks\n",
        "        final_video.write_videofile(\n",
        "            str(final_video_path),\n",
        "            codec='libx264',\n",
        "            audio_codec='aac',\n",
        "            temp_audiofile='temp-audio.m4a',\n",
        "            remove_temp=True,\n",
        "            fps=30,  # Maintain consistent frame rate\n",
        "            preset='medium',  # Balance between speed and compression\n",
        "            ffmpeg_params=['-crf', '23']  # Quality setting (lower = better quality)\n",
        "        )\n",
        "\n",
        "        # Clean up resources\n",
        "        for clip in video_clips:\n",
        "            clip.close()\n",
        "        final_video.close()\n",
        "\n",
        "        logger.info(f\"Successfully created final video: {final_video_path}\")\n",
        "\n",
        "        return final_video_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error stitching videos: {e}\")\n",
        "        raise RuntimeError(f\"Failed to stitch videos together: {e}\")\n",
        "\n",
        "\n",
        "# Additional helper function for validating VEO-2 connectivity\n",
        "def validate_veo2_connection(api_key: str) -> bool:\n",
        "    \"\"\"\n",
        "    Validate that VEO-2 API is accessible with given credentials.\n",
        "\n",
        "    Args:\n",
        "        api_key (str): Vertex AI API key\n",
        "\n",
        "    Returns:\n",
        "        bool: True if connection successful, False otherwise\n",
        "    \"\"\"\n",
        "    try:\n",
        "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = api_key\n",
        "        vertexai.init()\n",
        "        model = VideoGenerationModel.from_pretrained(\"veo-2\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"VEO-2 connection validation failed: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# Import required for BytesIO\n",
        "import io\n"
      ],
      "metadata": {
        "id": "ThNTKx43Q5td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gemini Pro 2.5 June Draft"
      ],
      "metadata": {
        "id": "2kV3-EFmR8sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import List, Optional\n",
        "\n",
        "# Third-party libraries\n",
        "# Ensure you have installed the necessary packages:\n",
        "# pip install google-cloud-aiplatform pillow opencv-python numpy\n",
        "import cv2\n",
        "import numpy as np\n",
        "import vertexai\n",
        "from google.api_core import exceptions as google_exceptions\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from vertexai.preview.vision_models import Video, VideoGenerationModel\n",
        "\n",
        "# Configure logging for clear output\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "def generate_sequential_video_story(\n",
        "    reference_image_path: str,\n",
        "    prompts: List[str],\n",
        "    project_id: str,\n",
        "    location: str,\n",
        "    output_folder_name: str\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Generates a sequential video story by chaining VEO-2 model calls.\n",
        "\n",
        "    This function creates a narrative video sequence where each segment is\n",
        "    generated based on the last frame of the previous segment. It begins with a\n",
        "    provided reference image and a series of prompts.\n",
        "\n",
        "    Prerequisites:\n",
        "    1.  Google Cloud SDK (`gcloud`) installed and authenticated. Run the\n",
        "        following command in your terminal:\n",
        "        `gcloud auth application-default login`\n",
        "    2.  The Vertex AI API must be enabled for the specified `project_id`.\n",
        "    3.  Necessary Python packages installed: `google-cloud-aiplatform`,\n",
        "        `Pillow`, `opencv-python`, `numpy`.\n",
        "\n",
        "    Args:\n",
        "        reference_image_path (str):\n",
        "            The absolute or relative file path to the initial reference image\n",
        "            (e.g., 'images/start.png').\n",
        "        prompts (List[str]):\n",
        "            A list of strings, where each string is a prompt for a video\n",
        "            segment. The list must not be empty.\n",
        "        project_id (str):\n",
        "            The Google Cloud Project ID to use for Vertex AI API calls.\n",
        "        location (str):\n",
        "            The Google Cloud location/region for the Vertex AI endpoint\n",
        "            (e.g., 'us-central1').\n",
        "        output_folder_name (str):\n",
        "            The name of the folder to be created in the user's home\n",
        "            directory to store the generated video segments and the final\n",
        "            stitched video.\n",
        "\n",
        "    Returns:\n",
        "        Optional[str]:\n",
        "            The absolute path to the final stitched video file if successful,\n",
        "            otherwise None.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If inputs are invalid (e.g., empty prompts list, bad path).\n",
        "        FileNotFoundError: If the reference_image_path does not exist.\n",
        "        RuntimeError: If an API call or a video processing step fails.\n",
        "    \"\"\"\n",
        "    # --- Input Validation ---\n",
        "    # Validate that the reference_image_path is a valid file.\n",
        "    if not Path(reference_image_path).is_file():\n",
        "        raise FileNotFoundError(\n",
        "            f\"Reference image not found at path: {reference_image_path}\"\n",
        "        )\n",
        "    # Validate that the prompts list is not empty.\n",
        "    if not prompts:\n",
        "        raise ValueError(\"The 'prompts' list cannot be empty.\")\n",
        "    # Validate that all other string inputs are non-empty.\n",
        "    if not all([project_id, location, output_folder_name]):\n",
        "        raise ValueError(\n",
        "            \"project_id, location, and output_folder_name must be non-empty strings.\"\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        # --- Step 1: Create a sub-directory in the home-directory ---\n",
        "        logging.info(\"Step 1: Creating output directory.\")\n",
        "        # Get the user's home directory in a platform-agnostic way.\n",
        "        home_dir = Path.home()\n",
        "        # Define the full path for the output directory.\n",
        "        output_dir = home_dir / output_folder_name\n",
        "        # Create the directory. exist_ok=True prevents an error if it already exists.\n",
        "        output_dir.mkdir(exist_ok=True, parents=True)\n",
        "        logging.info(f\"Output directory created/ensured at: {output_dir}\")\n",
        "\n",
        "        # --- Initialize Vertex AI ---\n",
        "        logging.info(\"Initializing Vertex AI with Project ID and Location.\")\n",
        "        # This uses Application Default Credentials (ADC) for authentication.\n",
        "        vertexai.init(project=project_id, location=location)\n",
        "        # Load the VEO-2 model (or a compatible video generation model).\n",
        "        # The model name \"imagen-video\" is used here as a placeholder for the\n",
        "        # specific, potentially private preview, VEO-2 model identifier.\n",
        "        model = VideoGenerationModel.from_pretrained(\"imagen-video@002\")\n",
        "\n",
        "        # --- Step 2: Read the initial reference image into memory ---\n",
        "        logging.info(\"Step 2: Reading and preparing the initial reference image.\")\n",
        "        # This variable will hold the image data (in bytes) for each generation step.\n",
        "        current_frame_bytes: Optional[bytes] = None\n",
        "        try:\n",
        "            # Open the image file from the provided path.\n",
        "            with Image.open(reference_image_path) as img:\n",
        "                # Create an in-memory binary stream.\n",
        "                with io.BytesIO() as byte_stream:\n",
        "                    # Save the image to the stream in PNG format (lossless).\n",
        "                    img.save(byte_stream, format=\"PNG\")\n",
        "                    # Get the byte value of the stream.\n",
        "                    current_frame_bytes = byte_stream.getvalue()\n",
        "        except UnidentifiedImageError:\n",
        "            # Handle cases where the file is not a valid image.\n",
        "            raise ValueError(f\"File at {reference_image_path} is not a valid image.\")\n",
        "\n",
        "        # --- Steps 3, 4, 5: Iterate, Generate, Decompose, and Chain ---\n",
        "        logging.info(\"Starting iterative video generation loop.\")\n",
        "        generated_video_paths = []\n",
        "\n",
        "        for i, prompt in enumerate(prompts):\n",
        "            video_number = i + 1\n",
        "            logging.info(f\"--- Iteration {video_number}/{len(prompts)} ---\")\n",
        "            logging.info(f\"Prompt: '{prompt}'\")\n",
        "\n",
        "            # --- Step 4 & 5.c/f: Generate video using the model ---\n",
        "            # The input for the first iteration is the reference image.\n",
        "            # For subsequent iterations, it's the last frame of the previous video.\n",
        "            if current_frame_bytes is None:\n",
        "                # This should not be reached if logic is correct, but is a safeguard.\n",
        "                raise RuntimeError(\"Image bytes are missing for video generation.\")\n",
        "\n",
        "            logging.info(\"Generating video with Vertex AI VEO-2 model...\")\n",
        "            try:\n",
        "                # This is the core API call. We generate a short video.\n",
        "                # Cost-efficiency note: shorter videos are cheaper. A 4-second\n",
        "                # length is a reasonable default for animated segments.\n",
        "                response: Video = model.generate(\n",
        "                    prompt=prompt,\n",
        "                    # The seed image provides the starting point for generation.\n",
        "                    seed_image=Image.open(io.BytesIO(current_frame_bytes)),\n",
        "                    # Generate a 4-second video at 24 FPS.\n",
        "                    video_length_sec=4,\n",
        "                    fps=24,\n",
        "                )\n",
        "            except google_exceptions.GoogleAPICallError as e:\n",
        "                # Catch API errors (e.g., rate limits, invalid arguments).\n",
        "                raise RuntimeError(\n",
        "                    f\"Vertex AI API call failed at iteration {video_number}: {e}\"\n",
        "                ) from e\n",
        "\n",
        "            # --- Step 5.a/d: Save the generated video to the folder ---\n",
        "            video_path = output_dir / f\"{video_number}.mp4\"\n",
        "            # The API returns video data which we write to a file.\n",
        "            response.save(str(video_path))\n",
        "            # Keep track of the path for the final stitching step.\n",
        "            generated_video_paths.append(video_path)\n",
        "            logging.info(f\"Saved video segment to: {video_path}\")\n",
        "\n",
        "            # --- Prepare for the next iteration (if not the last one) ---\n",
        "            if video_number < len(prompts):\n",
        "                logging.info(\"Decomposing video to get the last frame for the next iteration.\")\n",
        "                # --- Step 5.b/e: Decompose the generated video into image frames ---\n",
        "                video_capture = None\n",
        "                try:\n",
        "                    # Open the video we just saved.\n",
        "                    video_capture = cv2.VideoCapture(str(video_path))\n",
        "                    # Get the total number of frames in the video.\n",
        "                    frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "                    if frame_count == 0:\n",
        "                        raise RuntimeError(f\"Video file {video_path} is empty or corrupt.\")\n",
        "\n",
        "                    # --- Step 5.c/f: Use the last frame ---\n",
        "                    # Set the video position to the last frame.\n",
        "                    video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_count - 1)\n",
        "                    # Read the last frame.\n",
        "                    success, last_frame_np = video_capture.read()\n",
        "\n",
        "                    if not success:\n",
        "                        raise RuntimeError(f\"Could not read the last frame from {video_path}.\")\n",
        "\n",
        "                    # Convert the last frame (NumPy array in BGR) to bytes for the next API call.\n",
        "                    # Convert color from OpenCV's BGR to Pillow's RGB.\n",
        "                    last_frame_rgb = cv2.cvtColor(last_frame_np, cv2.COLOR_BGR2RGB)\n",
        "                    # Create a Pillow Image object from the NumPy array.\n",
        "                    last_frame_pil = Image.fromarray(last_frame_rgb)\n",
        "\n",
        "                    # Use the same in-memory stream technique to get bytes.\n",
        "                    with io.BytesIO() as byte_stream:\n",
        "                        last_frame_pil.save(byte_stream, format=\"PNG\")\n",
        "                        current_frame_bytes = byte_stream.getvalue()\n",
        "\n",
        "                    logging.info(\"Successfully extracted last frame for the next cycle.\")\n",
        "\n",
        "                finally:\n",
        "                    # CRITICAL: Always release the video capture resource.\n",
        "                    if video_capture:\n",
        "                        video_capture.release()\n",
        "\n",
        "        # --- Step 6: Stitch all generated videos together ---\n",
        "        logging.info(\"--- All segments generated. Starting final stitching process. ---\")\n",
        "        if not generated_video_paths:\n",
        "            logging.warning(\"No video segments were generated. Cannot stitch.\")\n",
        "            return None\n",
        "\n",
        "        # Sort the video paths numerically to ensure correct order.\n",
        "        # This prevents '10.mp4' from coming before '2.mp4'.\n",
        "        sorted_paths = sorted(\n",
        "            generated_video_paths, key=lambda p: int(p.stem)\n",
        "        )\n",
        "\n",
        "        # Get video properties (width, height, fps) from the first clip.\n",
        "        # We assume all clips have the same properties, a reasonable expectation\n",
        "        # from the same generative model session.\n",
        "        first_clip = cv2.VideoCapture(str(sorted_paths[0]))\n",
        "        if not first_clip.isOpened():\n",
        "            raise RuntimeError(f\"Failed to open first video clip at {sorted_paths[0]} for stitching.\")\n",
        "\n",
        "        frame_width = int(first_clip.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        frame_height = int(first_clip.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(first_clip.get(cv2.CAP_PROP_FPS))\n",
        "        first_clip.release()\n",
        "\n",
        "        # Define the path for the final output video.\n",
        "        final_video_path = output_dir / \"final.mp4\"\n",
        "        # Define the video codec and create the VideoWriter object.\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        video_writer = cv2.VideoWriter(str(final_video_path), fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "        try:\n",
        "            # Iterate through each video segment in the correct order.\n",
        "            for video_path in sorted_paths:\n",
        "                logging.info(f\"Stitching {video_path}...\")\n",
        "                cap = cv2.VideoCapture(str(video_path))\n",
        "                try:\n",
        "                    # Read each frame from the segment and write it to the final video.\n",
        "                    while cap.isOpened():\n",
        "                        ret, frame = cap.read()\n",
        "                        if not ret:\n",
        "                            break\n",
        "                        # Check if frame dimensions match, a safety measure.\n",
        "                        if frame.shape[1] != frame_width or frame.shape[0] != frame_height:\n",
        "                            logging.warning(f\"Frame mismatch in {video_path}, resizing. This may impact quality.\")\n",
        "                            frame = cv2.resize(frame, (frame_width, frame_height))\n",
        "                        video_writer.write(frame)\n",
        "                finally:\n",
        "                    # Ensure each video capture is released.\n",
        "                    cap.release()\n",
        "\n",
        "            logging.info(f\"Successfully stitched all segments into: {final_video_path}\")\n",
        "            # Return the path to the final video.\n",
        "            return str(final_video_path.resolve())\n",
        "\n",
        "        finally:\n",
        "            # CRITICAL: Always release the final video writer.\n",
        "            video_writer.release()\n",
        "            logging.info(\"Final video writer released.\")\n",
        "\n",
        "    except (ValueError, FileNotFoundError, RuntimeError) as e:\n",
        "        # Catch our own raised errors and log them before re-raising or exiting.\n",
        "        logging.error(f\"A critical error occurred: {e}\")\n",
        "        # Depending on desired behavior, you might re-raise or just return None\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        # Catch any unexpected errors.\n",
        "        logging.error(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "KHNW2I0gSCw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini Pro June Draft with Websearch"
      ],
      "metadata": {
        "id": "oqEhyV-afwK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from typing import List, Tuple\n",
        "\n",
        "# Note: The following imports are required for Google Cloud Vertex AI.\n",
        "# Ensure you have authenticated your environment correctly.\n",
        "# e.g., via `gcloud auth application-default login`\n",
        "from google.cloud import aiplatform\n",
        "from google.api_core import exceptions as google_exceptions\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def _get_last_frame_as_base64(video_path: Path) -> str:\n",
        "    \"\"\"\n",
        "    Reads a video file, extracts its very last frame, and returns it as a base64 encoded string.\n",
        "\n",
        "    Args:\n",
        "        video_path: The path to the video file.\n",
        "\n",
        "    Returns:\n",
        "        A base64 encoded string of the last frame (PNG format).\n",
        "\n",
        "    Raises:\n",
        "        IOError: If the video file cannot be opened or read.\n",
        "        cv2.error: If there is an OpenCV-specific error.\n",
        "    \"\"\"\n",
        "    # Intext Comment: Check if the video file exists before proceeding.\n",
        "    if not video_path.is_file():\n",
        "        raise FileNotFoundError(f\"Video file not found at: {video_path}\")\n",
        "\n",
        "    # Intext Comment: Initialize video capture object from the video file path.\n",
        "    cap = cv2.VideoCapture(str(video_path))\n",
        "    if not cap.isOpened():\n",
        "        raise IOError(f\"Could not open video file: {video_path}\")\n",
        "\n",
        "    try:\n",
        "        # Intext Comment: Get the total number of frames in the video.\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        if total_frames == 0:\n",
        "            raise ValueError(\"Video file contains no frames.\")\n",
        "\n",
        "        # Intext Comment: Set the capture position to the last frame (index is total_frames - 1).\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)\n",
        "\n",
        "        # Intext Comment: Read the frame at the current position.\n",
        "        success, frame = cap.read()\n",
        "        if not success or frame is None:\n",
        "            raise IOError(f\"Failed to read the last frame from {video_path}.\")\n",
        "\n",
        "        # Intext Comment: Encode the frame (NumPy array) into a PNG image in memory.\n",
        "        # The 'imencode' function returns a tuple (success_flag, buffer).\n",
        "        success, buffer = cv2.imencode('.png', frame)\n",
        "        if not success:\n",
        "            raise RuntimeError(\"Failed to encode frame into PNG format.\")\n",
        "\n",
        "        # Intext Comment: Convert the memory buffer to bytes.\n",
        "        image_bytes = buffer.tobytes()\n",
        "\n",
        "        # Intext Comment: Encode the bytes into a base64 string and decode to UTF-8 for API compatibility.\n",
        "        return base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "    finally:\n",
        "        # Intext Comment: Always release the video capture object to free up resources.\n",
        "        cap.release()\n",
        "\n",
        "\n",
        "def _generate_video_from_veo(\n",
        "    project_id: str,\n",
        "    location: str,\n",
        "    input_image_base64: str,\n",
        "    prompt: str\n",
        ") -> bytes:\n",
        "    \"\"\"\n",
        "    Calls the Vertex AI VEO model to generate a video.\n",
        "\n",
        "    Args:\n",
        "        project_id: The Google Cloud project ID.\n",
        "        location: The Google Cloud location (e.g., \"us-central1\").\n",
        "        input_image_base64: The base64 encoded input image.\n",
        "        prompt: The text prompt for video generation.\n",
        "\n",
        "    Returns:\n",
        "        The raw bytes of the generated video.\n",
        "\n",
        "    Raises:\n",
        "        google_exceptions.GoogleAPICallError: If the API call fails.\n",
        "    \"\"\"\n",
        "    # Intext Comment: Initialize the Vertex AI SDK.\n",
        "    aiplatform.init(project=project_id, location=location)\n",
        "\n",
        "    # Intext Comment: Define the model endpoint for VEO.\n",
        "    # Note: \"veo-2\" is a placeholder for the actual model name.\n",
        "    # You must replace this with the official model identifier when available.\n",
        "    model = aiplatform.Model(\"projects/vertex-ai-vision-public-preview/locations/us-central1/models/veo-2-0605\")\n",
        "\n",
        "    # Intext Comment: Construct the instance payload for the model prediction.\n",
        "    # The exact format may vary based on the final VEO API specification.\n",
        "    instance = {\n",
        "        \"prompt\": prompt,\n",
        "        \"image_bytes\": input_image_base64,\n",
        "        # Intext Comment: Additional parameters can be added here, e.g., video length.\n",
        "        \"video_length_sec\": 4, # Example parameter\n",
        "    }\n",
        "\n",
        "    # Intext Comment: Make the prediction call to the Vertex AI endpoint.\n",
        "    # The response is expected to contain the video content, likely base64 encoded.\n",
        "    response = model.predict(instances=[instance])\n",
        "\n",
        "    # Intext Comment: Extract the base64 encoded video content from the first prediction.\n",
        "    # The key 'video_bytes' is an assumption based on typical Vertex AI responses.\n",
        "    video_base64 = response.predictions[0]['video_bytes']\n",
        "\n",
        "    # Intext Comment: Decode the base64 string to get the raw video bytes.\n",
        "    return base64.b64decode(video_base64)\n",
        "\n",
        "\n",
        "# --- Main Function ---\n",
        "\n",
        "def create_generative_video_story(\n",
        "    reference_image_path: str,\n",
        "    prompts: List[str],\n",
        "    gcp_project_id: str,\n",
        "    gcp_location: str,\n",
        "    output_folder_name: str\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    Creates a continuous video story from a reference image and a series of prompts using Google's VEO-2 model.\n",
        "\n",
        "    This function performs the following steps:\n",
        "    1. Creates a dedicated output directory.\n",
        "    2. Loads an initial reference image.\n",
        "    3. Iteratively generates video segments:\n",
        "       - The first segment is based on the reference image and the first prompt.\n",
        "       - Each subsequent segment is based on the last frame of the previous video and the next prompt.\n",
        "    4. Saves each video segment sequentially.\n",
        "    5. Stitches all segments together into a final, seamless video.\n",
        "\n",
        "    Args:\n",
        "        reference_image_path (str): The full path to the starting reference image file.\n",
        "        prompts (List[str]): A list of strings, where each string is a prompt for a scene.\n",
        "        gcp_project_id (str): Your Google Cloud Project ID.\n",
        "        gcp_location (str): The Google Cloud location for the Vertex AI API call (e.g., \"us-central1\").\n",
        "        output_folder_name (str): The name for the sub-directory where generated videos will be saved.\n",
        "\n",
        "    Returns:\n",
        "        Path: The path to the final stitched video file.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the prompts list is empty or inputs are invalid.\n",
        "        FileNotFoundError: If the reference image file does not exist.\n",
        "        IOError: If there are issues reading files or writing video.\n",
        "        google_exceptions.GoogleAPICallError: If a Vertex AI API call fails.\n",
        "    \"\"\"\n",
        "    # --- 0. Input Validation ---\n",
        "    # Intext Comment: Ensure the reference image path is a valid string.\n",
        "    if not isinstance(reference_image_path, str) or not reference_image_path:\n",
        "        raise ValueError(\"The 'reference_image_path' must be a non-empty string.\")\n",
        "    # Intext Comment: Ensure the prompts list is a non-empty list of strings.\n",
        "    if not prompts or not isinstance(prompts, list) or not all(isinstance(p, str) for p in prompts):\n",
        "        raise ValueError(\"The 'prompts' must be a non-empty list of strings.\")\n",
        "    # Intext Comment: Ensure GCP and folder name inputs are valid strings.\n",
        "    if not isinstance(gcp_project_id, str) or not gcp_project_id:\n",
        "        raise ValueError(\"The 'gcp_project_id' must be a non-empty string.\")\n",
        "    if not isinstance(gcp_location, str) or not gcp_location:\n",
        "        raise ValueError(\"The 'gcp_location' must be a non-empty string.\")\n",
        "    if not isinstance(output_folder_name, str) or not output_folder_name:\n",
        "        raise ValueError(\"The 'output_folder_name' must be a non-empty string.\")\n",
        "\n",
        "    # --- 1. Create Output Sub-directory ---\n",
        "    try:\n",
        "        # Intext Comment: Get the user's home directory and create the full path for the output folder.\n",
        "        output_dir = Path.home() / output_folder_name\n",
        "        # Intext Comment: Create the directory. `exist_ok=True` prevents an error if it already exists.\n",
        "        output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"Successfully created or found output directory: {output_dir}\")\n",
        "    except PermissionError:\n",
        "        # Intext Comment: Handle cases where the script doesn't have permission to create the directory.\n",
        "        raise PermissionError(f\"Permission denied to create directory at {output_dir}.\")\n",
        "\n",
        "    # --- 2. Read and Prepare the Initial Reference Image ---\n",
        "    try:\n",
        "        # Intext Comment: Open the image file using Pillow.\n",
        "        with Image.open(reference_image_path) as img:\n",
        "            # Intext Comment: Convert to RGB to ensure consistency and handle formats like PNG with alpha channels.\n",
        "            img_rgb = img.convert('RGB')\n",
        "            # Intext Comment: Create an in-memory binary stream to save the image.\n",
        "            from io import BytesIO\n",
        "            buffer = BytesIO()\n",
        "            # Intext Comment: Save the image into the buffer in JPEG format.\n",
        "            img_rgb.save(buffer, format=\"JPEG\")\n",
        "            # Intext Comment: Get the byte value of the buffer.\n",
        "            image_bytes = buffer.getvalue()\n",
        "            # Intext Comment: Encode the image bytes to a base64 string for the API.\n",
        "            current_image_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
        "            print(f\"Successfully read and encoded reference image: {reference_image_path}\")\n",
        "    except FileNotFoundError:\n",
        "        # Intext Comment: Handle the case where the image file does not exist.\n",
        "        raise FileNotFoundError(f\"Reference image not found at: {reference_image_path}\")\n",
        "    except UnidentifiedImageError:\n",
        "        # Intext Comment: Handle cases where the file is not a valid image.\n",
        "        raise IOError(f\"The file at {reference_image_path} is not a valid or supported image format.\")\n",
        "\n",
        "    # --- 3. to 5. Iterate, Generate, Save, and Decompose ---\n",
        "    generated_video_paths = []\n",
        "    for i, prompt in enumerate(prompts, 1):\n",
        "        print(f\"\\n--- Processing Prompt {i}/{len(prompts)}: '{prompt}' ---\")\n",
        "        try:\n",
        "            # Intext Comment: Step 4 & 5c/f - Generate video using the current image and prompt.\n",
        "            print(\"Generating video with VEO-2... (This may take some time)\")\n",
        "            video_bytes = _generate_video_from_veo(\n",
        "                project_id=gcp_project_id,\n",
        "                location=gcp_location,\n",
        "                input_image_base64=current_image_base64,\n",
        "                prompt=prompt\n",
        "            )\n",
        "\n",
        "            # Intext Comment: Step 5a/d - Save the generated video to the output folder.\n",
        "            video_path = output_dir / f\"{i}.mp4\"\n",
        "            with open(video_path, \"wb\") as f:\n",
        "                f.write(video_bytes)\n",
        "            generated_video_paths.append(video_path)\n",
        "            print(f\"Successfully saved video segment to: {video_path}\")\n",
        "\n",
        "            # Intext Comment: If this is not the last prompt, extract the last frame for the next iteration.\n",
        "            if i < len(prompts):\n",
        "                # Intext Comment: Step 5b/e - Decompose video and get the last frame as base64.\n",
        "                print(\"Decomposing video to extract the last frame...\")\n",
        "                current_image_base64 = _get_last_frame_as_base64(video_path)\n",
        "                print(\"Successfully extracted last frame for the next iteration.\")\n",
        "\n",
        "        except google_exceptions.GoogleAPICallError as e:\n",
        "            print(f\"An error occurred with the Vertex AI API on prompt {i}: {e}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred during video generation for prompt {i}: {e}\")\n",
        "            raise\n",
        "\n",
        "    # --- 6. Stitch All Videos Together ---\n",
        "    if not generated_video_paths:\n",
        "        print(\"No videos were generated, skipping final stitching.\")\n",
        "        return None\n",
        "\n",
        "    print(\"\\n--- Stitching all video segments into a final video ---\")\n",
        "    clips = []\n",
        "    try:\n",
        "        # Intext Comment: Create a list of VideoFileClip objects from the generated video paths.\n",
        "        # The list is already in the correct order (1, 2, 3, ...).\n",
        "        for video_path in generated_video_paths:\n",
        "            clips.append(VideoFileClip(str(video_path)))\n",
        "\n",
        "        # Intext Comment: Concatenate all the video clips into a single timeline.\n",
        "        final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
        "\n",
        "        # Intext Comment: Define the path for the final output video.\n",
        "        final_video_path = output_dir / \"final.mp4\"\n",
        "\n",
        "        # Intext Comment: Write the final concatenated video to a file.\n",
        "        # `codec=\"libx264\"` is a high-quality, widely compatible codec.\n",
        "        # `audio_codec=\"aac\"` is a standard audio codec.\n",
        "        final_clip.write_videofile(\n",
        "            str(final_video_path),\n",
        "            codec=\"libx264\",\n",
        "            audio_codec=\"aac\",\n",
        "            temp_audiofile='temp-audio.m4a',\n",
        "            remove_temp=True\n",
        "        )\n",
        "        print(f\"Successfully stitched all segments. Final video saved to: {final_video_path}\")\n",
        "        return final_video_path\n",
        "\n",
        "    except Exception as e:\n",
        "        # Intext Comment: Handle potential errors during the moviepy processing.\n",
        "        print(f\"An error occurred during the final video stitching process: {e}\")\n",
        "        raise\n",
        "    finally:\n",
        "        # Intext Comment: Best practice: explicitly close all clip objects to release file handles.\n",
        "        for clip in clips:\n",
        "            clip.close()\n"
      ],
      "metadata": {
        "id": "zVZhChJrfu-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### **The Complete Professional-Grade Python Function**\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import cv2\n",
        "import numpy as np\n",
        "import vertexai\n",
        "from vertexai.preview.vision_models import VideoGenerationModel, Video\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "\n",
        "def generate_sequential_video_from_prompts(\n",
        "    reference_image_path: str,\n",
        "    scene_prompts: List[str],\n",
        "    vertex_project_id: str,\n",
        "    vertex_location: str,\n",
        "    vertex_api_key: str,\n",
        "    output_folder_name: str,\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Generates a sequential video from a reference image and a list of prompts.\n",
        "\n",
        "    This function performs the following steps:\n",
        "    1. Creates a subdirectory in the home directory for the output.\n",
        "    2. Reads the initial reference image.\n",
        "    3. Iterates through the prompts, generating a video for each.\n",
        "    4. The first video is generated from the reference image.\n",
        "    5. Subsequent videos are generated from the last frame of the previous video.\n",
        "    6. Each generated video is saved sequentially.\n",
        "    7. Finally, all generated videos are stitched into a single \"final.mp4\" video.\n",
        "\n",
        "    Args:\n",
        "        reference_image_path: Path to the initial reference image.\n",
        "        scene_prompts: A list of strings, where each string is a prompt for a scene.\n",
        "        vertex_project_id: Your Google Cloud project ID.\n",
        "        vertex_location: The location of the Vertex AI resources (e.g., \"us-central1\").\n",
        "        vertex_api_key: Your Google Vertex AI API key.\n",
        "        output_folder_name: The name of the folder to save the generated videos.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the list of scene prompts is empty.\n",
        "        FileNotFoundError: If the reference image is not found.\n",
        "        UnidentifiedImageError: If the reference file is not a valid image.\n",
        "        Exception: For errors related to API calls, video processing, or file I/O.\n",
        "    \"\"\"\n",
        "    # --- Input Validation ---\n",
        "    if not scene_prompts:\n",
        "        raise ValueError(\"The 'scene_prompts' list cannot be empty.\")\n",
        "    if not all(isinstance(p, str) for p in scene_prompts):\n",
        "        raise TypeError(\"All elements in 'scene_prompts' must be strings.\")\n",
        "    if not isinstance(reference_image_path, str) or not reference_image_path:\n",
        "        raise ValueError(\"'reference_image_path' must be a non-empty string.\")\n",
        "    # Add more validation for other parameters as needed.\n",
        "\n",
        "    try:\n",
        "        # --- Step 1: Create Output Directory ---\n",
        "        print(\"Step 1: Creating output directory...\")\n",
        "        output_directory = create_output_directory(output_folder_name)\n",
        "        print(f\"Successfully created directory at: {output_directory}\")\n",
        "\n",
        "        # --- Step 2: Read Reference Image ---\n",
        "        print(\"Step 2: Reading reference image...\")\n",
        "        current_frame = load_reference_image(reference_image_path)\n",
        "        print(f\"Successfully loaded reference image from: {reference_image_path}\")\n",
        "\n",
        "        # --- Initialize Vertex AI ---\n",
        "        print(\"Initializing Vertex AI...\")\n",
        "        vertexai.init(project=vertex_project_id, location=vertex_location, credentials=vertex_api_key)\n",
        "        model = VideoGenerationModel.from_pretrained(\"video-generation-001\")\n",
        "        print(\"Vertex AI initialized and model loaded.\")\n",
        "\n",
        "        # --- Steps 3, 4, & 5: Iterate, Generate, Save, Decompose ---\n",
        "        print(\"Starting video generation loop...\")\n",
        "        for i, prompt in enumerate(scene_prompts):\n",
        "            iteration_num = i + 1\n",
        "            print(f\"\\n--- Iteration {iteration_num}/{len(scene_prompts)} ---\")\n",
        "            print(f\"Prompt: '{prompt}'\")\n",
        "\n",
        "            # --- Generate Video ---\n",
        "            print(\"Generating video with Veo-2...\")\n",
        "            video_generation_response = model.generate(\n",
        "                prompt=prompt,\n",
        "                image=current_frame,\n",
        "            )\n",
        "            generated_video = video_generation_response.videos[0]\n",
        "\n",
        "            # --- Save Generated Video ---\n",
        "            video_filename = f\"{iteration_num}.mp4\"\n",
        "            video_path = output_directory / video_filename\n",
        "            print(f\"Saving video to: {video_path}\")\n",
        "            generated_video.save(str(video_path))\n",
        "\n",
        "            # --- Decompose and Get Last Frame for Next Iteration ---\n",
        "            if iteration_num < len(scene_prompts):\n",
        "                print(\"Decomposing video to get the last frame for the next iteration...\")\n",
        "                current_frame = decompose_video_and_get_last_frame(video_path)\n",
        "                print(\"Successfully extracted last frame.\")\n",
        "\n",
        "        print(\"\\nAll video segments have been generated.\")\n",
        "\n",
        "        # --- Step 6: Stitch Videos ---\n",
        "        print(\"\\nStep 6: Stitching all video segments together...\")\n",
        "        stitch_videos(output_directory, \"final\")\n",
        "        print(f\"Successfully stitched videos. Final video saved as 'final.mp4' in '{output_directory}'\")\n",
        "\n",
        "    except (ValueError, TypeError, FileNotFoundError, UnidentifiedImageError) as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        # Re-raise the exception after logging it.\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        # Catch any other exceptions (API errors, etc.)\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        raise\n",
        "\n",
        "#### **Step 1: Create a Sub-directory**\n",
        "\n",
        "def create_output_directory(folder_name: str) -> Path:\n",
        "    \"\"\"\n",
        "    Creates a subdirectory in the user's home directory.\n",
        "\n",
        "    Args:\n",
        "        folder_name: The name of the directory to create.\n",
        "\n",
        "    Returns:\n",
        "        The path to the created directory.\n",
        "\n",
        "    Raises:\n",
        "        OSError: If the directory cannot be created.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Construct the full path to the desired directory within the home directory.\n",
        "        home_directory = Path.home()\n",
        "        output_directory = home_directory / folder_name\n",
        "        # Create the directory. The `exist_ok=True` argument prevents an error\n",
        "        # if the directory already exists.\n",
        "        output_directory.mkdir(parents=True, exist_ok=True)\n",
        "        return output_directory\n",
        "    except OSError as e:\n",
        "        # Handle potential OS-level errors during directory creation.\n",
        "        print(f\"Error creating directory: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "#### **Step 2: Read the Reference Image**\n",
        "\n",
        "\n",
        "def load_reference_image(image_path: str) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Loads an image from the specified path into a PIL Image object.\n",
        "\n",
        "    Args:\n",
        "        image_path: The full path to the reference image file.\n",
        "\n",
        "    Returns:\n",
        "        A PIL Image object.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the image file does not exist.\n",
        "        UnidentifiedImageError: If the file is not a valid image.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Open the image file using a 'with' statement for automatic resource management.\n",
        "        with Image.open(image_path) as img:\n",
        "            # Load the image data into memory.\n",
        "            img.load()\n",
        "            return img\n",
        "    except FileNotFoundError:\n",
        "        # Handle the case where the file does not exist.\n",
        "        print(f\"Error: The image file was not found at '{image_path}'\")\n",
        "        raise\n",
        "    except UnidentifiedImageError:\n",
        "        # Handle the case where the file is not a valid image.\n",
        "        print(f\"Error: The file at '{image_path}' is not a valid image.\")\n",
        "        raise\n",
        "\n",
        "#### **Step 3 & 4: Iterate and Generate the First Video**\n",
        "\n",
        "def generate_initial_video(\n",
        "    project_id: str,\n",
        "    location: str,\n",
        "    reference_image: Image.Image,\n",
        "    prompt: str,\n",
        "    api_key: str\n",
        ") -> Video:\n",
        "    \"\"\"\n",
        "    Generates the initial video from a reference image and a prompt.\n",
        "\n",
        "    Args:\n",
        "        project_id: The Google Cloud project ID.\n",
        "        location: The Google Cloud location.\n",
        "        reference_image: The reference PIL Image.\n",
        "        prompt: The text prompt for the video generation.\n",
        "        api_key: The Vertex AI API key.\n",
        "\n",
        "    Returns:\n",
        "        The generated Video object.\n",
        "    \"\"\"\n",
        "    # Initialize Vertex AI\n",
        "    vertexai.init(project=project_id, location=location, credentials=api_key)\n",
        "\n",
        "    # Load the model\n",
        "    model = VideoGenerationModel.from_pretrained(\"video-generation-001\")\n",
        "\n",
        "    # Generate the video\n",
        "    video_generation_response = model.generate(\n",
        "        prompt=prompt,\n",
        "        image=reference_image,\n",
        "    )\n",
        "    return video_generation_response.videos[0]\n",
        "\n",
        "\n",
        "#### **Step 5: Save, Decompose, and Iterate**\n",
        "\n",
        "def save_video(video: Video, output_path: Path):\n",
        "    \"\"\"\n",
        "    Saves a Vertex AI Video object to a file.\n",
        "\n",
        "    Args:\n",
        "        video: The Video object to save.\n",
        "        output_path: The path to save the video file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Save the video to the specified path.\n",
        "        video.save(str(output_path))\n",
        "    except Exception as e:\n",
        "        # Handle potential errors during saving.\n",
        "        print(f\"Error saving video to {output_path}: {e}\")\n",
        "        raise\n",
        "\n",
        "def decompose_video_and_get_last_frame(video_path: Path) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Decomposes a video and returns the last frame as a PIL Image.\n",
        "\n",
        "    Args:\n",
        "        video_path: The path to the video file.\n",
        "\n",
        "    Returns:\n",
        "        The last frame of the video as a PIL Image.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the video cannot be opened or has no frames.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Open the video file.\n",
        "        cap = cv2.VideoCapture(str(video_path))\n",
        "        if not cap.isOpened():\n",
        "            raise ValueError(f\"Could not open video file: {video_path}\")\n",
        "\n",
        "        last_frame = None\n",
        "        while True:\n",
        "            # Read the next frame.\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                # Break the loop if there are no more frames.\n",
        "                break\n",
        "            last_frame = frame\n",
        "\n",
        "        # Release the video capture object.\n",
        "        cap.release()\n",
        "\n",
        "        if last_frame is None:\n",
        "            raise ValueError(f\"Video has no frames: {video_path}\")\n",
        "\n",
        "        # Convert the last frame from BGR (OpenCV format) to RGB (PIL format).\n",
        "        last_frame_rgb = cv2.cvtColor(last_frame, cv2.COLOR_BGR2RGB)\n",
        "        # Create a PIL Image from the NumPy array.\n",
        "        return Image.fromarray(last_frame_rgb)\n",
        "    except cv2.error as e:\n",
        "        # Handle OpenCV-specific errors.\n",
        "        print(f\"OpenCV error processing video {video_path}: {e}\")\n",
        "        raise\n",
        "\n",
        "def generate_subsequent_video(\n",
        "    project_id: str,\n",
        "    location: str,\n",
        "    last_frame: Image.Image,\n",
        "    prompt: str,\n",
        "    api_key: str\n",
        ") -> Video:\n",
        "    \"\"\"\n",
        "    Generates a subsequent video from a reference frame and a prompt.\n",
        "\n",
        "    Args:\n",
        "        project_id: The Google Cloud project ID.\n",
        "        location: The Google Cloud location.\n",
        "        last_frame: The reference PIL Image (last frame of the previous video).\n",
        "        prompt: The text prompt for the video generation.\n",
        "        api_key: The Vertex AI API key.\n",
        "\n",
        "    Returns:\n",
        "        The generated Video object.\n",
        "    \"\"\"\n",
        "    # This function is conceptually the same as generate_initial_video,\n",
        "    # but is separated for clarity in the main loop.\n",
        "    return generate_initial_video(project_id, location, last_frame, prompt, api_key)\n",
        "\n",
        "#### **Step 6: Stitch Videos**\n",
        "\n",
        "def stitch_videos(video_directory: Path, final_video_name: str):\n",
        "    \"\"\"\n",
        "    Stitches all videos in a directory into a single video.\n",
        "\n",
        "    Args:\n",
        "        video_directory: The directory containing the video files.\n",
        "        final_video_name: The name for the final stitched video (without extension).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get all .mp4 files in the directory.\n",
        "        video_files = sorted(\n",
        "            [f for f in video_directory.glob(\"*.mp4\") if f.stem.isdigit()],\n",
        "            key=lambda f: int(f.stem)\n",
        "        )\n",
        "\n",
        "        if not video_files:\n",
        "            print(\"No video files found to stitch.\")\n",
        "            return\n",
        "\n",
        "        # Create a list of VideoFileClip objects.\n",
        "        clips = [VideoFileClip(str(f)) for f in video_files]\n",
        "\n",
        "        # Concatenate the video clips.\n",
        "        final_clip = concatenate_videoclips(clips)\n",
        "\n",
        "        # Write the final video file.\n",
        "        final_output_path = video_directory / f\"{final_video_name}.mp4\"\n",
        "        final_clip.write_videofile(str(final_output_path), codec=\"libx264\")\n",
        "\n",
        "        # Close the clips to release resources.\n",
        "        for clip in clips:\n",
        "            clip.close()\n",
        "        final_clip.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle potential errors during video stitching.\n",
        "        print(f\"Error stitching videos: {e}\")\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "fTYTzOF3ixf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini 2.5 Pro May Draft"
      ],
      "metadata": {
        "id": "uJ0KVDPiSbCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "from PIL import Image as PILImage # Used for initial image validation, if desired\n",
        "import cv2 # OpenCV for video frame extraction\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips # For stitching videos\n",
        "\n",
        "# Google Cloud specific imports\n",
        "from google.cloud import aiplatform_v1beta1 as aiplatform\n",
        "from google.protobuf import json_format, struct_pb2\n",
        "from google.api_core.client_options import ClientOptions\n",
        "# Note: For google.auth, typical ADC usage doesn't require explicit imports here,\n",
        "# but if using service account keys directly:\n",
        "# from google.oauth2.service_account import Credentials\n",
        "\n",
        "def generate_animated_video_sequence(\n",
        "    reference_image_file_path: str,\n",
        "    prompts: List[str],\n",
        "    gcp_project_id: str,\n",
        "    gcp_location: str,\n",
        "    google_vertex_api_key: str,\n",
        "    output_folder_name: str,\n",
        "    veo_model_id: str = \"video-generation-001\" # Example model ID, replace with actual VEO-2 ID\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Generates a sequence of animated videos based on a reference image and prompts,\n",
        "    using a Google Vertex AI video generation model (e.g., VEO-2).\n",
        "\n",
        "    The process involves:\n",
        "    1. Creating an output directory.\n",
        "    2. Reading an initial reference image.\n",
        "    3. Iteratively generating video segments:\n",
        "        - The first segment uses the initial image and the first prompt.\n",
        "        - Subsequent segments use the last frame of the previously generated\n",
        "          video and the next prompt.\n",
        "        - Each segment is saved numerically (1.mp4, 2.mp4, ...).\n",
        "    4. Stitching all generated segments into a final video named \"final.mp4\".\n",
        "\n",
        "    Args:\n",
        "        reference_image_file_path: Path to the initial reference image file.\n",
        "        prompts: A list of text prompts, one for each video segment.\n",
        "        gcp_project_id: Google Cloud Project ID.\n",
        "        gcp_location: Google Cloud region for Vertex AI services (e.g., \"us-central1\").\n",
        "        google_vertex_api_key: Google Vertex API Key. This will be passed to\n",
        "                               ClientOptions. Standard Vertex AI authentication\n",
        "                               (ADC/Service Account) is typically preferred.\n",
        "        output_folder_name: Name of the sub-directory in the user's home directory\n",
        "                            for storing generated videos.\n",
        "        veo_model_id: The Vertex AI model ID for VEO-2 or a compatible video\n",
        "                      generation model (e.g., \"video-generation-001\" for Imagen).\n",
        "\n",
        "    Returns:\n",
        "        The file path to the final stitched video.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the reference image file does not exist.\n",
        "        ValueError: If inputs are invalid (e.g., empty prompts list).\n",
        "        RuntimeError: If any part of the video generation or processing fails.\n",
        "        PermissionError: If directory creation fails due to permissions.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Input Validation ---\n",
        "    # Validate reference_image_file_path\n",
        "    if not Path(reference_image_file_path).is_file():\n",
        "        raise FileNotFoundError(f\"Reference image file not found: {reference_image_file_path}\")\n",
        "\n",
        "    # Validate prompts\n",
        "    if not prompts:\n",
        "        raise ValueError(\"Prompts list cannot be empty.\")\n",
        "    if not all(isinstance(p, str) and p.strip() for p in prompts):\n",
        "        raise ValueError(\"All prompts must be non-empty strings.\")\n",
        "\n",
        "    # Validate other essential string inputs\n",
        "    for arg_name, arg_val in [\n",
        "        (\"gcp_project_id\", gcp_project_id),\n",
        "        (\"gcp_location\", gcp_location),\n",
        "        (\"output_folder_name\", output_folder_name),\n",
        "        (\"veo_model_id\", veo_model_id)\n",
        "    ]: # google_vertex_api_key can be empty if auth handled differently\n",
        "        if not isinstance(arg_val, str) or not arg_val.strip():\n",
        "            raise ValueError(f\"{arg_name} must be a non-empty string.\")\n",
        "    if not isinstance(google_vertex_api_key, str): # API key must be a string, even if empty\n",
        "        raise ValueError(\"google_vertex_api_key must be a string.\")\n",
        "\n",
        "\n",
        "    # --- Step 1: Create output sub-directory ---\n",
        "    # Construct the full path for the output directory in the home directory.\n",
        "    home_dir = Path.home()\n",
        "    # Create the full path to the output directory.\n",
        "    output_dir = home_dir / output_folder_name\n",
        "    try:\n",
        "        # Create the output directory. `exist_ok=True` prevents an error if it already exists.\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "    except PermissionError:\n",
        "        # Handle PermissionError if the script cannot create the directory.\n",
        "        raise PermissionError(f\"Permission denied to create directory: {output_dir}\")\n",
        "    except OSError as e:\n",
        "        # Handle other OS-related errors during directory creation.\n",
        "        raise RuntimeError(f\"Failed to create output directory {output_dir}: {e}\")\n",
        "\n",
        "    # --- Initialize Vertex AI Prediction Client ---\n",
        "    # Construct the API endpoint for the Vertex AI Prediction service.\n",
        "    api_endpoint = f\"{gcp_location}-aiplatform.googleapis.com\"\n",
        "    # Client options including the API key.\n",
        "    # Note: Efficacy of API key depends on service and its auth configuration.\n",
        "    client_options_args = {\"api_endpoint\": api_endpoint}\n",
        "    if google_vertex_api_key: # Only add api_key if it's provided\n",
        "        client_options_args[\"api_key\"] = google_vertex_api_key\n",
        "    client_options = ClientOptions(**client_options_args)\n",
        "\n",
        "    try:\n",
        "        # Initialize the Prediction Service client.\n",
        "        prediction_client = aiplatform.PredictionServiceClient(client_options=client_options)\n",
        "    except Exception as e:\n",
        "        # Handle errors during Vertex AI client initialization.\n",
        "        raise RuntimeError(f\"Failed to initialize Vertex AI PredictionServiceClient: {e}. \"\n",
        "                           \"Ensure authentication (ADC or API key) is correctly configured for the project/service.\")\n",
        "\n",
        "    # The full model resource name for Vertex AI prediction.\n",
        "    # This assumes `veo_model_id` is a published model like \"video-generation-001\".\n",
        "    model_resource_name = (\n",
        "        f\"projects/{gcp_project_id}/locations/{gcp_location}/publishers/google/models/{veo_model_id}\"\n",
        "    )\n",
        "\n",
        "    # --- Helper Function: Generate video using Vertex AI Model ---\n",
        "    def _generate_video_from_vertex_ai(\n",
        "        image_bytes: bytes,\n",
        "        prompt_text: str,\n",
        "        video_length_sec: int = 5, # Default, VEO-2 might have different/more params\n",
        "        fps: int = 24              # Default, VEO-2 might have different/more params\n",
        "    ) -> bytes:\n",
        "        # Encode image bytes to base64 for JSON payload.\n",
        "        encoded_image_string = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "\n",
        "        # Construct the instance payload for the prediction request.\n",
        "        # THIS PAYLOAD IS AN EXAMPLE AND MUST MATCH THE VEO-2 MODEL'S ACTUAL API SCHEMA.\n",
        "        instance_dict = {\n",
        "            \"prompt\": prompt_text,\n",
        "            \"image\": {\"bytesBase64Encoded\": encoded_image_string},\n",
        "            # VEO-2 might require other specific fields here.\n",
        "        }\n",
        "        instance_pb = json_format.ParseDict(instance_dict, struct_pb2.Value())\n",
        "        instances = [instance_pb]\n",
        "\n",
        "        # Define model parameters. THESE ARE EXAMPLES AND MUST MATCH VEO-2's API.\n",
        "        parameters_dict = {\n",
        "            \"videoLengthSec\": video_length_sec, # Common naming: videoLength (camelCase)\n",
        "            \"fps\": fps,\n",
        "            # \"safetyFilter\": True, # Example boolean parameter\n",
        "            # Add other VEO-2 specific parameters here.\n",
        "        }\n",
        "        parameters_pb = json_format.ParseDict(parameters_dict, struct_pb2.Value())\n",
        "\n",
        "        try:\n",
        "            # Make the prediction request to the Vertex AI model.\n",
        "            response = prediction_client.predict(\n",
        "                endpoint=model_resource_name,\n",
        "                instances=instances,\n",
        "                parameters=parameters_pb,\n",
        "            )\n",
        "            # Process the response. THIS PROCESSING LOGIC IS AN EXAMPLE.\n",
        "            if not response.predictions:\n",
        "                raise RuntimeError(\"Vertex AI API call returned no predictions.\")\n",
        "\n",
        "            # Prediction result parsing depends heavily on the model's output schema.\n",
        "            prediction_result = json_format.MessageToDict(response.predictions[0])\n",
        "\n",
        "            if \"bytesBase64Encoded\" in prediction_result: # Common for direct byte output\n",
        "                video_bytes_b64 = prediction_result[\"bytesBase64Encoded\"]\n",
        "                generated_video_bytes = base64.b64decode(video_bytes_b64)\n",
        "                return generated_video_bytes\n",
        "            # VEO-2 might return a GCS URI instead, requiring download logic.\n",
        "            elif \"gcsUri\" in prediction_result:\n",
        "                gcs_uri = prediction_result[\"gcsUri\"]\n",
        "                raise NotImplementedError(\n",
        "                    f\"Video generation resulted in a GCS URI ({gcs_uri}). \"\n",
        "                    \"Direct GCS download is not implemented. Assumed direct byte output.\"\n",
        "                )\n",
        "            else:\n",
        "                raise RuntimeError(f\"Unexpected API response format. Prediction: {prediction_result}\")\n",
        "        except Exception as e:\n",
        "            # Handle errors during the API call.\n",
        "            raise RuntimeError(f\"Vertex AI API call failed for prompt '{prompt_text}': {e}\")\n",
        "\n",
        "    # --- Helper Function: Decompose video and get last frame ---\n",
        "    def _get_last_frame_from_video(video_file_path: str) -> bytes:\n",
        "        try:\n",
        "            # Open the video file using OpenCV.\n",
        "            cap = cv2.VideoCapture(video_file_path)\n",
        "            if not cap.isOpened():\n",
        "                raise RuntimeError(f\"OpenCV: Failed to open video file: {video_file_path}\")\n",
        "\n",
        "            # Get the total number of frames.\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            if total_frames == 0:\n",
        "                cap.release()\n",
        "                raise RuntimeError(f\"OpenCV: Video file has no frames: {video_file_path}\")\n",
        "\n",
        "            # Set video capture position to the last frame (0-indexed).\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)\n",
        "            # Read the last frame.\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            if not ret or frame is None:\n",
        "                cap.release()\n",
        "                raise RuntimeError(f\"OpenCV: Failed to read last frame from: {video_file_path}\")\n",
        "\n",
        "            # Release video capture object.\n",
        "            cap.release()\n",
        "\n",
        "            # Encode frame (numpy array) to JPEG image bytes.\n",
        "            success, encoded_image = cv2.imencode(\".jpg\", frame, [cv2.IMWRITE_JPEG_QUALITY, 90])\n",
        "            if not success:\n",
        "                raise RuntimeError(f\"OpenCV: Failed to encode last frame to JPEG from: {video_file_path}\")\n",
        "\n",
        "            return encoded_image.tobytes()\n",
        "        except Exception as e:\n",
        "            # Catch-all for OpenCV or processing errors.\n",
        "            if 'cap' in locals() and cap.isOpened():\n",
        "                cap.release()\n",
        "            raise RuntimeError(f\"OpenCV: Error processing video {video_file_path} for last frame: {e}\")\n",
        "\n",
        "    # --- Main Processing Loop ---\n",
        "    generated_video_segment_paths: List[str] = []\n",
        "    current_input_image_bytes: bytes\n",
        "\n",
        "    # --- Step 2: Read the initial reference image into memory ---\n",
        "    try:\n",
        "        # Read the initial reference image file as bytes.\n",
        "        current_input_image_bytes = Path(reference_image_file_path).read_bytes()\n",
        "    except Exception as e:\n",
        "        # Handle potential errors during file reading.\n",
        "        raise RuntimeError(f\"Failed to read reference image file {reference_image_file_path}: {e}\")\n",
        "\n",
        "    # --- Step 3 & onwards: Iterate through prompts, generate videos, extract frames ---\n",
        "    for idx, prompt_text in enumerate(prompts):\n",
        "        # Determine if this is the first iteration for logging/logic if needed.\n",
        "        # is_first_iteration = (idx == 0) (not strictly used below but good for clarity)\n",
        "\n",
        "        # --- Step 4 (First Iteration) / Step 5.c (Subsequent Iterations): Generate video ---\n",
        "        try:\n",
        "            # Call helper to generate video using current input image and prompt.\n",
        "            generated_video_bytes = _generate_video_from_vertex_ai(\n",
        "                image_bytes=current_input_image_bytes,\n",
        "                prompt_text=prompt_text\n",
        "                # Pass other VEO-2 specific parameters if needed\n",
        "            )\n",
        "        except Exception as e:\n",
        "            # Propagate error from video generation.\n",
        "            raise RuntimeError(f\"Video generation failed for prompt #{idx + 1} ('{prompt_text}'): {e}\")\n",
        "\n",
        "        # --- Step 5.a / 5.d: Save the generated video ---\n",
        "        # Filename uses 1-based indexing.\n",
        "        video_segment_filename = f\"{idx + 1}.mp4\" # Assuming MP4 format from VEO-2.\n",
        "        video_segment_filepath = output_dir / video_segment_filename\n",
        "        try:\n",
        "            # Write the generated video bytes to file.\n",
        "            with open(video_segment_filepath, \"wb\") as f:\n",
        "                f.write(generated_video_bytes)\n",
        "            # Add path of saved segment for later stitching.\n",
        "            generated_video_segment_paths.append(str(video_segment_filepath))\n",
        "        except IOError as e:\n",
        "            # Handle errors during file saving.\n",
        "            raise RuntimeError(f\"Failed to save video segment {video_segment_filepath}: {e}\")\n",
        "\n",
        "        # --- Step 5.b / 5.e: Decompose video, get last frame (if not the last prompt) ---\n",
        "        # This is needed to feed into the *next* iteration.\n",
        "        if idx < len(prompts) - 1: # If there's a next prompt\n",
        "            try:\n",
        "                # Get last frame from the just-saved video.\n",
        "                last_frame_bytes = _get_last_frame_from_video(str(video_segment_filepath))\n",
        "                # Update current_input_image_bytes for the next iteration.\n",
        "                current_input_image_bytes = last_frame_bytes\n",
        "            except Exception as e:\n",
        "                # Propagate error from frame extraction.\n",
        "                raise RuntimeError(f\"Failed to extract last frame from {video_segment_filepath}: {e}\")\n",
        "        # Step 5.f and 5.g are implicitly handled by this loop structure.\n",
        "\n",
        "    # --- Step 6: Stitch all generated video segments together ---\n",
        "    if not generated_video_segment_paths:\n",
        "        # This should ideally not be reached due to prior prompt validation.\n",
        "        raise RuntimeError(\"No video segments were generated; cannot stitch.\")\n",
        "\n",
        "    final_video_filename = \"final.mp4\"\n",
        "    final_video_filepath = output_dir / final_video_filename\n",
        "\n",
        "    video_clips_to_stitch: List[VideoFileClip] = []\n",
        "    try:\n",
        "        # Load each generated video segment as a MoviePy VideoFileClip.\n",
        "        for segment_path_str in generated_video_segment_paths:\n",
        "            try:\n",
        "                # Load the video clip.\n",
        "                clip = VideoFileClip(segment_path_str)\n",
        "                video_clips_to_stitch.append(clip)\n",
        "            except Exception as e:\n",
        "                # Handle error if a segment cannot be loaded.\n",
        "                raise RuntimeError(f\"MoviePy: Failed to load video segment {segment_path_str} for stitching: {e}\")\n",
        "\n",
        "        if not video_clips_to_stitch:\n",
        "            raise RuntimeError(\"MoviePy: No video clips successfully loaded for stitching.\")\n",
        "\n",
        "        # Concatenate all video clips.\n",
        "        final_clip = concatenate_videoclips(video_clips_to_stitch, method=\"compose\")\n",
        "\n",
        "        # Write the final stitched video to file.\n",
        "        # Ensure VEO-2 generated videos have consistent FPS, resolution for best results.\n",
        "        # Specify codec, threads, logger for `write_videofile` as needed.\n",
        "        final_clip.write_videofile(\n",
        "            str(final_video_filepath),\n",
        "            codec=\"libx264\", # Common, good quality MP4 codec\n",
        "            # audio_codec=\"aac\", # Add if VEO-2 includes audio and it should be preserved\n",
        "            # threads=os.cpu_count(), # Utilize available CPU cores for encoding\n",
        "            # logger=\"bar\" # Shows a progress bar\n",
        "        )\n",
        "        # Return the path to the final video.\n",
        "        return str(final_video_filepath)\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle errors during video stitching or saving.\n",
        "        raise RuntimeError(f\"MoviePy: Failed to stitch video segments or save final video: {e}\")\n",
        "    finally:\n",
        "        # Clean up: Close all loaded MoviePy clips.\n",
        "        for clip_obj in video_clips_to_stitch:\n",
        "            try:\n",
        "                clip_obj.close()\n",
        "            except Exception:\n",
        "                # Log or ignore errors during cleanup of individual clips.\n",
        "                # print(f\"Warning: MoviePy: Failed to close a video clip resource for {clip_obj.filename}\")\n",
        "                pass\n"
      ],
      "metadata": {
        "id": "RJpcFhxXTzKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Pzw-u22Vlvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sonnet 4 *Draft*"
      ],
      "metadata": {
        "id": "vZ_tTeW4Vnpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Draft 1\n",
        "\n",
        "### Assessment\n",
        "\n",
        "# VEO-2 Video Generation Pipeline Code Analysis\n",
        "\n",
        "## Overview\n",
        "This is a comprehensive analysis of the VEO-2 video generation pipeline implementation. I'll examine each section for accuracy, best practices, and potential issues.\n",
        "\n",
        "## Import Section Analysis\n",
        "\n",
        "### ✅ Standard Library Imports - CORRECT\n",
        "```python\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import base64\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional, Tuple, Union\n",
        "```\n",
        "- All standard library imports are correct and properly used throughout the code\n",
        "- Type hints imports are appropriate for the code's type annotations\n",
        "\n",
        "### ⚠️ Third-Party Imports - MIXED ACCURACY\n",
        "```python\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from google.auth import default\n",
        "from google.auth.transport.requests import Request\n",
        "from google.cloud import storage\n",
        "import moviepy.editor as mp\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "import tempfile\n",
        "import shutil\n",
        "```\n",
        "\n",
        "**Issues Found:**\n",
        "1. `import tempfile` and `import shutil` are imported but never used in the code\n",
        "2. `import moviepy.editor as mp` is redundant since specific functions are imported on the next line\n",
        "3. Missing error handling for import failures of optional dependencies\n",
        "\n",
        "## Logging Configuration - ✅ CORRECT\n",
        "```python\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "```\n",
        "- Professional logging setup is appropriate and well-configured\n",
        "\n",
        "## Class Definition and Initialization\n",
        "\n",
        "### ✅ Exception Class - CORRECT\n",
        "```python\n",
        "class VEO2VideoGenerationError(Exception):\n",
        "    \"\"\"Custom exception for VEO-2 video generation errors.\"\"\"\n",
        "    pass\n",
        "```\n",
        "- Simple, appropriate custom exception class\n",
        "\n",
        "### ✅ Main Class Initialization - MOSTLY CORRECT\n",
        "```python\n",
        "def __init__(self, project_id: str, location: str = \"us-central1\"):\n",
        "```\n",
        "**Analysis:**\n",
        "- Parameter validation is good\n",
        "- Instance variable initialization is appropriate\n",
        "- API endpoint construction is correct for Vertex AI\n",
        "\n",
        "**Minor Issue:** The model ID `\"veo-2.0-generate-001\"` should be verified against actual Vertex AI model naming conventions.\n",
        "\n",
        "## Authentication Method\n",
        "\n",
        "### ⚠️ Authentication Issues Found\n",
        "```python\n",
        "def _initialize_authentication(self) -> None:\n",
        "    try:\n",
        "        self.credentials, _ = default()\n",
        "        if not self.credentials.valid:\n",
        "            self.credentials.refresh(Request())\n",
        "    except Exception as e:\n",
        "        raise VEO2VideoGenerationError(f\"Failed to initialize authentication: {str(e)}\")\n",
        "```\n",
        "\n",
        "**Issues:**\n",
        "1. The `default()` function returns `(credentials, project_id)`, but the project_id is ignored with `_`\n",
        "2. Should handle the case where credentials are None\n",
        "3. Missing import for specific Google Auth exceptions\n",
        "\n",
        "## Input Validation\n",
        "\n",
        "### ✅ Validation Logic - EXCELLENT\n",
        "```python\n",
        "def _validate_inputs(self, reference_image_path: str, scene_prompts: List[str],\n",
        "                    api_key: str, output_folder_name: str) -> None:\n",
        "```\n",
        "- Comprehensive validation of all input parameters\n",
        "- Proper type checking and existence verification\n",
        "- Good error messages\n",
        "\n",
        "## Directory Creation\n",
        "\n",
        "### ✅ Directory Creation - CORRECT\n",
        "```python\n",
        "def _create_output_directory(self, folder_name: str) -> Path:\n",
        "    home_dir = Path.home()\n",
        "    output_dir = home_dir / folder_name\n",
        "    output_dir.mkdir(mode=0o755, parents=True, exist_ok=True)\n",
        "```\n",
        "- Uses pathlib appropriately\n",
        "- Proper permissions and error handling\n",
        "\n",
        "## Image Processing Methods\n",
        "\n",
        "### ✅ Image Loading and Encoding - WELL IMPLEMENTED\n",
        "```python\n",
        "def _load_and_encode_image(self, image_path: str) -> Tuple[str, str]:\n",
        "```\n",
        "**Strengths:**\n",
        "- Proper PIL usage for image handling\n",
        "- Format conversion and base64 encoding is correct\n",
        "- Good error handling\n",
        "\n",
        "### ✅ Image Resizing - CORRECT\n",
        "```python\n",
        "def _resize_image_for_veo2(self, img: Image.Image) -> Image.Image:\n",
        "```\n",
        "- Aspect ratio calculation is correct\n",
        "- Uses high-quality resampling (LANCZOS)\n",
        "- Appropriate target dimensions\n",
        "\n",
        "## Critical Issues in API Integration\n",
        "\n",
        "### ❌ MAJOR ISSUES in VEO-2 API Call\n",
        "```python\n",
        "def _generate_video_with_veo2(self, prompt: str, image_data: Optional[str] = None,\n",
        "                             mime_type: Optional[str] = None, storage_uri: Optional[str] = None) -> str:\n",
        "```\n",
        "\n",
        "**Critical Problems:**\n",
        "\n",
        "1. **Incorrect API Endpoint Structure:**\n",
        "   ```python\n",
        "   url = (f\"{self.api_endpoint}/v1/projects/{self.project_id}/\"\n",
        "          f\"locations/{self.location}/publishers/google/\"\n",
        "          f\"models/{self.model_id}:predictLongRunning\")\n",
        "   ```\n",
        "   This endpoint structure is incorrect for VEO-2. The actual Vertex AI endpoint should be different.\n",
        "\n",
        "2. **Wrong Request Body Format:**\n",
        "   ```python\n",
        "   request_body = {\n",
        "       \"instances\": [{\n",
        "           \"prompt\": prompt\n",
        "       }],\n",
        "       \"parameters\": {\n",
        "           \"durationSeconds\": 8,\n",
        "           \"sampleCount\": 1,\n",
        "           \"aspectRatio\": \"16:9\"\n",
        "       }\n",
        "   }\n",
        "   ```\n",
        "   This format doesn't match VEO-2's actual API specification.\n",
        "\n",
        "3. **Authentication Header Issue:**\n",
        "   ```python\n",
        "   headers = {\n",
        "       'Authorization': f'Bearer {self.credentials.token}',\n",
        "       'Content-Type': 'application/json; charset=utf-8'\n",
        "   }\n",
        "   ```\n",
        "   Should ensure credentials are refreshed and handle token expiration.\n",
        "\n",
        "## Polling Operation\n",
        "\n",
        "### ⚠️ Polling Logic - MOSTLY CORRECT BUT ISSUES\n",
        "```python\n",
        "def _poll_operation_status(self, operation_name: str) -> str:\n",
        "```\n",
        "\n",
        "**Issues:**\n",
        "1. **Incorrect Polling Endpoint:**\n",
        "   ```python\n",
        "   url = (f\"{self.api_endpoint}/v1/projects/{self.project_id}/\"\n",
        "          f\"locations/{self.location}/publishers/google/\"\n",
        "          f\"models/{self.model_id}:fetchPredictOperation\")\n",
        "   ```\n",
        "   This endpoint structure is not correct for standard Google Cloud operations.\n",
        "\n",
        "2. **Should use standard Google Cloud Operations API:**\n",
        "   ```python\n",
        "   # Should be something like:\n",
        "   url = f\"{self.api_endpoint}/v1/{operation_name}\"\n",
        "   ```\n",
        "\n",
        "## File Download Method\n",
        "\n",
        "### ✅ GCS Download - CORRECT\n",
        "```python\n",
        "def _download_video_from_gcs(self, gcs_uri: str, local_path: Path) -> None:\n",
        "```\n",
        "- URI parsing is correct\n",
        "- Google Cloud Storage client usage is appropriate\n",
        "- Error handling is good\n",
        "\n",
        "## Video Processing Methods\n",
        "\n",
        "### ✅ Frame Extraction - CORRECT\n",
        "```python\n",
        "def _extract_last_frame(self, video_path: Path) -> np.ndarray:\n",
        "```\n",
        "- OpenCV usage is correct\n",
        "- Proper resource cleanup with `cap.release()`\n",
        "- Good error handling\n",
        "\n",
        "### ✅ Frame Conversion - CORRECT\n",
        "```python\n",
        "def _frame_to_base64(self, frame: np.ndarray) -> Tuple[str, str]:\n",
        "```\n",
        "- BGR to RGB conversion is necessary and correct\n",
        "- PIL integration is appropriate\n",
        "- Base64 encoding is implemented correctly\n",
        "\n",
        "### ✅ Video Stitching - CORRECT\n",
        "```python\n",
        "def _stitch_videos(self, video_paths: List[Path], output_path: Path) -> None:\n",
        "```\n",
        "- MoviePy usage is correct\n",
        "- Proper resource cleanup with clip.close()\n",
        "- Good codec settings for output\n",
        "\n",
        "## Main Pipeline Method\n",
        "\n",
        "### ⚠️ Pipeline Logic - GOOD STRUCTURE, API ISSUES\n",
        "```python\n",
        "def generate_sequential_videos(self, ...):\n",
        "```\n",
        "\n",
        "**Strengths:**\n",
        "- Well-structured pipeline flow\n",
        "- Good error handling and logging\n",
        "- Proper iteration through prompts with frame chaining\n",
        "\n",
        "**Issues:**\n",
        "- Inherits all the API-related problems from the helper methods\n",
        "- The api_key parameter is accepted but not used (relies on default authentication)\n",
        "\n",
        "## Helper Function\n",
        "\n",
        "### ⚠️ Auto-detection Logic Issues\n",
        "```python\n",
        "def create_veo2_video_pipeline(...):\n",
        "    if project_id is None:\n",
        "        try:\n",
        "            _, project_id = default()  # This is incorrect\n",
        "```\n",
        "\n",
        "**Critical Issue:** The `default()` function returns `(credentials, project_id)`, but in most cases, the project_id returned is None. The code should use:\n",
        "```python\n",
        "from google.auth import default\n",
        "import google.auth.exceptions\n",
        "\n",
        "credentials, project_id = default()\n",
        "if not project_id:\n",
        "    project_id = os.environ.get('GOOGLE_CLOUD_PROJECT')\n",
        "```\n",
        "\n",
        "## Summary of Critical Issues\n",
        "\n",
        "### 🔴 Major Problems:\n",
        "1. **VEO-2 API Integration**: The API endpoints and request formats are incorrect\n",
        "2. **Authentication Flow**: Improper handling of project ID detection\n",
        "3. **Unused Parameters**: api_key parameter is not utilized\n",
        "4. **Import Redundancy**: Unused imports and redundant moviepy imports\n",
        "\n",
        "### 🟡 Minor Issues:\n",
        "1. Missing specific exception handling for Google Cloud errors\n",
        "2. Model ID naming should be verified\n",
        "3. Some parameters could have better validation\n",
        "\n",
        "### ✅ Well-Implemented Areas:\n",
        "1. Image processing and encoding\n",
        "2. Video file operations (extraction, stitching)\n",
        "3. File system operations\n",
        "4. Error handling structure\n",
        "5. Logging implementation\n",
        "6. Type annotations and documentation\n",
        "\n",
        "## Recommendations for Fixes:\n",
        "\n",
        "1. **Fix API Integration**: Research and implement correct VEO-2 API endpoints and request formats\n",
        "2. **Fix Authentication**: Properly handle project ID detection and credential management\n",
        "3. **Remove Unused Code**: Clean up unused imports and parameters\n",
        "4. **Add Specific Exception Handling**: Handle Google Cloud specific exceptions\n",
        "5. **Verify Model Naming**: Confirm correct VEO-2 model identifier\n",
        "6. **Integration Testing**: The code needs testing with actual VEO-2 API to verify correctness\n",
        "\n",
        "The code shows excellent software engineering practices in terms of structure, documentation, and error handling, but has critical issues in the core API integration that would prevent it from working with the actual VEO-2 service."
      ],
      "metadata": {
        "id": "wcHCcxAM33r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Professional Implementation-Grade VEO-2 Video Generation Pipeline\n",
        "MIT PhD Computer Science Implementation with Google Vertex AI Integration\n",
        "\n",
        "This module provides a comprehensive solution for generating sequential videos\n",
        "using Google's VEO-2 model, with frame extraction and seamless stitching capabilities.\n",
        "\n",
        "Author: MIT PhD Computer Science Professor\n",
        "Specialization: Large Language Models, Prompting, Google Vertex AI\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import base64\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional, Tuple, Union\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from google.auth import default\n",
        "from google.auth.transport.requests import Request\n",
        "from google.cloud import storage\n",
        "import moviepy.editor as mp\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "# Configure logging for professional debugging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class VEO2VideoGenerationError(Exception):\n",
        "    \"\"\"Custom exception for VEO-2 video generation errors.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "class VEO2VideoPipeline:\n",
        "    \"\"\"\n",
        "    Professional implementation-grade class for VEO-2 video generation pipeline.\n",
        "\n",
        "    This class handles the complete workflow of generating sequential videos using\n",
        "    Google's VEO-2 model, including frame extraction and video stitching.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, project_id: str, location: str = \"us-central1\"):\n",
        "        \"\"\"\n",
        "        Initialize the VEO-2 video generation pipeline.\n",
        "\n",
        "        Args:\n",
        "            project_id (str): Google Cloud project ID\n",
        "            location (str): Vertex AI location, defaults to us-central1\n",
        "\n",
        "        Raises:\n",
        "            VEO2VideoGenerationError: If initialization fails\n",
        "        \"\"\"\n",
        "        # Validate input parameters\n",
        "        if not project_id or not isinstance(project_id, str):\n",
        "            raise ValueError(\"project_id must be a non-empty string\")\n",
        "\n",
        "        # Initialize instance variables\n",
        "        self.project_id: str = project_id\n",
        "        self.location: str = location\n",
        "        self.model_id: str = \"veo-2.0-generate-001\"\n",
        "        self.api_endpoint: str = f\"https://{location}-aiplatform.googleapis.com\"\n",
        "\n",
        "        # Initialize authentication\n",
        "        self._initialize_authentication()\n",
        "\n",
        "        logger.info(f\"VEO2VideoPipeline initialized for project: {project_id}\")\n",
        "\n",
        "    def _initialize_authentication(self) -> None:\n",
        "        \"\"\"\n",
        "        Initialize Google Cloud authentication credentials.\n",
        "\n",
        "        Raises:\n",
        "            VEO2VideoGenerationError: If authentication fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Obtain default credentials for Google Cloud authentication\n",
        "            self.credentials, _ = default()\n",
        "\n",
        "            # Refresh credentials if needed\n",
        "            if not self.credentials.valid:\n",
        "                self.credentials.refresh(Request())\n",
        "\n",
        "        except Exception as e:\n",
        "            raise VEO2VideoGenerationError(f\"Failed to initialize authentication: {str(e)}\")\n",
        "\n",
        "    def _validate_inputs(\n",
        "        self,\n",
        "        reference_image_path: str,\n",
        "        scene_prompts: List[str],\n",
        "        api_key: str,\n",
        "        output_folder_name: str\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Validate all input parameters for the video generation pipeline.\n",
        "\n",
        "        Args:\n",
        "            reference_image_path (str): Path to reference image file\n",
        "            scene_prompts (List[str]): List of scene description prompts\n",
        "            api_key (str): Google Vertex AI API key\n",
        "            output_folder_name (str): Name for output folder\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If any input parameter is invalid\n",
        "        \"\"\"\n",
        "        # Validate reference image path\n",
        "        if not reference_image_path or not isinstance(reference_image_path, str):\n",
        "            raise ValueError(\"reference_image_path must be a non-empty string\")\n",
        "\n",
        "        if not os.path.exists(reference_image_path):\n",
        "            raise ValueError(f\"Reference image file does not exist: {reference_image_path}\")\n",
        "\n",
        "        # Validate scene prompts\n",
        "        if not scene_prompts or not isinstance(scene_prompts, list):\n",
        "            raise ValueError(\"scene_prompts must be a non-empty list\")\n",
        "\n",
        "        if not all(isinstance(prompt, str) and prompt.strip() for prompt in scene_prompts):\n",
        "            raise ValueError(\"All scene prompts must be non-empty strings\")\n",
        "\n",
        "        # Validate API key\n",
        "        if not api_key or not isinstance(api_key, str):\n",
        "            raise ValueError(\"api_key must be a non-empty string\")\n",
        "\n",
        "        # Validate output folder name\n",
        "        if not output_folder_name or not isinstance(output_folder_name, str):\n",
        "            raise ValueError(\"output_folder_name must be a non-empty string\")\n",
        "\n",
        "    def _create_output_directory(self, folder_name: str) -> Path:\n",
        "        \"\"\"\n",
        "        Create a subdirectory in the home directory with the specified name.\n",
        "\n",
        "        Args:\n",
        "            folder_name (str): Name of the folder to create\n",
        "\n",
        "        Returns:\n",
        "            Path: Path object pointing to the created directory\n",
        "\n",
        "        Raises:\n",
        "            VEO2VideoGenerationError: If directory creation fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Get home directory path\n",
        "            home_dir = Path.home()\n",
        "\n",
        "            # Create subdirectory path\n",
        "            output_dir = home_dir / folder_name\n",
        "\n",
        "            # Create directory if it doesn't exist, with proper permissions\n",
        "            output_dir.mkdir(mode=0o755, parents=True, exist_ok=True)\n",
        "\n",
        "            logger.info(f\"Created output directory: {output_dir}\")\n",
        "            return output_dir\n",
        "\n",
        "        except Exception as e:\n",
        "            raise VEO2VideoGenerationError(f\"Failed to create output directory: {str(e)}\")\n",
        "\n",
        "    def _load_and_encode_image(self, image_path: str) -> Tuple[str, str]:\n",
        "        \"\"\"\n",
        "        Load image from file path and encode it to base64 format for API usage.\n",
        "\n",
        "        Args:\n",
        "            image_path (str): Path to the image file\n",
        "\n",
        "        Returns:\n",
        "            Tuple[str, str]: Base64 encoded image data and MIME type\n",
        "\n",
        "        Raises:\n",
        "            VEO2VideoGenerationError: If image loading or encoding fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Open and validate image using PIL\n",
        "            with Image.open(image_path) as img:\n",
        "                # Convert to RGB if necessary (removes alpha channel)\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "\n",
        "                # Resize image to recommended dimensions (1280x720 or 720x1280)\n",
        "                # while maintaining aspect ratio\n",
        "                img = self._resize_image_for_veo2(img)\n",
        "\n",
        "                # Convert PIL Image to bytes\n",
        "                import io\n",
        "                buffer = io.BytesIO()\n",
        "\n",
        "                # Determine output format and MIME type\n",
        "                original_format = img.format if img.format else 'JPEG'\n",
        "                if original_format.upper() in ['JPEG', 'JPG']:\n",
        "                    img.save(buffer, format='JPEG', quality=95)\n",
        "                    mime_type = 'image/jpeg'\n",
        "                else:\n",
        "                    img.save(buffer, format='PNG')\n",
        "                    mime_type = 'image/png'\n",
        "\n",
        "                # Encode to base64\n",
        "                image_bytes = buffer.getvalue()\n",
        "                base64_encoded = base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "                logger.info(f\"Successfully encoded image: {image_path}\")\n",
        "                return base64_encoded, mime_type\n",
        "\n",
        "        except Exception as e:\n",
        "            raise VEO2VideoGenerationError(f\"Failed to load and encode image: {str(e)}\")\n",
        "\n",
        "    def _resize_image_for_veo2(self, img: Image.Image) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Resize image to VEO-2 recommended dimensions while preserving aspect ratio.\n",
        "\n",
        "        Args:\n",
        "            img (Image.Image): PIL Image object\n",
        "\n",
        "        Returns:\n",
        "            Image.Image: Resized PIL Image object\n",
        "        \"\"\"\n",
        "        # Get current dimensions\n",
        "        width, height = img.size\n",
        "        aspect_ratio = width / height\n",
        "\n",
        "        # Determine target dimensions based on aspect ratio\n",
        "        if aspect_ratio > 1:  # Landscape\n",
        "            target_width, target_height = 1280, 720\n",
        "        else:  # Portrait\n",
        "            target_width, target_height = 720, 1280\n",
        "\n",
        "        # Resize image using high-quality resampling\n",
        "        resized_img = img.resize(\n",
        "            (target_width, target_height),\n",
        "            Image.Resampling.LANCZOS\n",
        "        )\n",
        "\n",
        "        return resized_img\n",
        "\n",
        "    def _generate_video_with_veo2(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        image_data: Optional[str] = None,\n",
        "        mime_type: Optional[str] = None,\n",
        "        storage_uri: Optional[str] = None\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generate video using VEO-2 model via Vertex AI API.\n",
        "\n",
        "        Args:\n",
        "            prompt (str): Text prompt for video generation\n",
        "            image_data (Optional[str]): Base64 encoded image data\n",
        "            mime_type (Optional[str]): MIME type of the image\n",
        "            storage_uri (Optional[str]): Cloud Storage URI for output\n",
        "\n",
        "        Returns:\n",
        "            str: Cloud Storage URI of generated video\n",
        "\n",
        "        Raises:\n",
        "            VEO2VideoGenerationError: If video generation fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Construct API endpoint URL\n",
        "            url = (f\"{self.api_endpoint}/v1/projects/{self.project_id}/\"\n",
        "                   f\"locations/{self.location}/publishers/google/\"\n",
        "                   f\"models/{self.model_id}:predictLongRunning\")\n",
        "\n",
        "            # Prepare request headers\n",
        "            headers = {\n",
        "                'Authorization': f'Bearer {self.credentials.token}',\n",
        "                'Content-Type': 'application/json; charset=utf-8'\n",
        "            }\n",
        "\n",
        "            # Construct request body\n",
        "            request_body = {\n",
        "                \"instances\": [{\n",
        "                    \"prompt\": prompt\n",
        "                }],\n",
        "                \"parameters\": {\n",
        "                    \"durationSeconds\": 8,\n",
        "                    \"sampleCount\": 1,\n",
        "                    \"aspectRatio\": \"16:9\"\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Add image data if provided\n",
        "            if image_data and mime_type:\n",
        "                request_body[\"instances\"][0][\"image\"] = {\n",
        "                    \"bytesBase64Encoded\": image_data,\n",
        "                    \"mimeType\": mime_type\n",
        "                }\n",
        "\n",
        "            # Add storage URI if provided\n",
        "            if storage_uri:\n",
        "                request_body[\"parameters\"][\"storageUri\"] = storage_uri\n",
        "\n",
        "            # Send initial request\n",
        "            response = requests.post(url, headers=headers, json=request_body)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Extract operation name from response\n",
        "            operation_data = response.json()\n",
        "            operation_name = operation_data.get(\"name\")\n",
        "\n",
        "            if not operation_name:\n",
        "                raise VEO2VideoGenerationError(\"No operation name returned from API\")\n",
        "\n",
        "            logger.info(f\"Video generation started with operation: {operation_name}\")\n",
        "\n",
        "            # Poll operation status until completion\n",
        "            video_uri = self._poll_operation_status(operation_name)\n",
        "\n",
        "            return video_uri\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            raise VEO2VideoGenerationError(f\"API request failed: {str(e)}\")\n",
        "        except Exception as e:\n",
        "            raise VEO2VideoGenerationError(f\"Video generation failed: {str(e)}\")\n",
        "\n",
        "    def _poll_operation_status(self, operation_name: str) -> str:\n",
        "        \"\"\"\n",
        "        Poll the status of a long-running video generation operation.\n",
        "\n",
        "        Args:\n",
        "            operation_name (str): Full operation name from initial request\n",
        "\n",
        "        Returns:\n",
        "            str: Cloud Storage URI of generated video\n",
        "\n",
        "        Raises:\n",
        "            VEO2VideoGenerationError: If polling fails or operation errors\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Construct polling endpoint URL\n",
        "            url = (f\"{self.api_endpoint}/v1/projects/{self.project_id}/\"\n",
        "                   f\"locations/{self.location}/publishers/google/\"\n",
        "                   f\"models/{self.model_id}:fetchPredictOperation\")\n",
        "\n",
        "            # Prepare request headers\n",
        "            headers = {\n",
        "                'Authorization': f'Bearer {self.credentials.token}',\n",
        "                'Content-Type': 'application/json; charset=utf-8'\n",
        "            }\n",
        "\n",
        "            # Prepare request body\n",
        "            request_body = {\n",
        "                \"operationName\": operation_name\n",
        "            }\n",
        "\n",
        "            # Poll with exponential backoff\n",
        "            max_attempts = 60  # Maximum 30 minutes (30 seconds * 60)\n",
        "            attempt = 0\n",
        "            wait_time = 30  # Start with 30 seconds\n",
        "\n",
        "            while attempt < max_attempts:\n",
        "                # Send polling request\n",
        "                response = requests.post(url, headers=headers, json=request_body)\n",
        "                response.raise_for_status()\n",
        "\n",
        "                # Parse response\n",
        "                result = response.json()\n",
        "\n",
        "                # Check if operation is complete\n",
        "                if result.get(\"done\", False):\n",
        "                    # Extract video URI from completed operation\n",
        "                    response_data = result.get(\"response\", {})\n",
        "                    generated_samples = response_data.get(\"generatedSamples\", [])\n",
        "\n",
        "                    if not generated_samples:\n",
        "                        raise VEO2VideoGenerationError(\"No generated samples in response\")\n",
        "\n",
        "                    video_info = generated_samples[0].get(\"video\", {})\n",
        "                    video_uri = video_info.get(\"uri\")\n",
        "\n",
        "                    if not video_uri:\n",
        "                        raise VEO2VideoGenerationError(\"No video URI in response\")\n",
        "\n",
        "                    logger.info(f\"Video generation completed: {video_uri}\")\n",
        "                    return video_uri\n",
        "\n",
        "                # Wait before next poll\n",
        "                time.sleep(wait_time)\n",
        "                attempt += 1\n",
        "\n",
        "                # Exponential backoff (cap at 120 seconds)\n",
        "                wait_time = min(wait_time * 1.1, 120)\n",
        "\n",
        "                logger.info(f\"Polling attempt {attempt}/{max_attempts}, waiting {wait_time:.1f}s\")\n",
        "\n",
        "            raise VEO2VideoGenerationError(\"Operation timeout: video generation took too long\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            raise VEO2VideoGenerationError(f\"Polling request failed: {str(e)}\")\n",
        "        except Exception as e:\n",
        "            raise VEO2VideoGenerationError(f\"Operation polling failed: {str(e)}\")\n",
        "\n",
        "    def _download_video_from_gcs(self, gcs_uri: str, local_path: Path) -> None:\n",
        "        \"\"\"\n",
        "        Download video from Google Cloud Storage to local filesystem.\n",
        "\n",
        "        Args:\n",
        "            gcs_uri (str): Google Cloud Storage URI (gs://bucket/path)\n",
        "            local_path (Path): Local file path for download\n",
        "\n",
        "        Raises:\n",
        "            VEO2VideoGenerationError: If download fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Parse GCS URI\n",
        "            if not gcs_uri.startswith('gs://'):\n",
        "                raise ValueError(f\"Invalid GCS URI format: {gcs_uri}\")\n",
        "\n",
        "            # Extract bucket and blob name\n",
        "            uri_parts = gcs_uri[5:].split('/', 1)  # Remove 'gs://' prefix\n",
        "            bucket_name = uri_parts[0]\n",
        "            blob_name = uri_parts[1] if len(uri_parts) > 1 else ''\n",
        "\n",
        "            # Initialize GCS client\n",
        "            storage_client = storage.Client(project=self.project_id, credentials=self.credentials)\n",
        "\n",
        "            # Get bucket and blob\n",
        "            bucket = storage_client.bucket(bucket_name)\n",
        "            blob = bucket.blob(blob_name)\n",
        "\n",
        "            # Download to local file\n",
        "            blob.download_to_filename(str(local_path))\n",
        "\n",
        "            logger.info(f\"Downloaded video from {gcs_uri} to {local_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise VEO2VideoGenerationError(f\"Failed to download video from GCS: {str(e)}\")\n",
        "\n",
        "    def _extract_last_frame(self, video_path: Path) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Extract the last frame from a video file using OpenCV.\n",
        "\n",
        "        Args:\n",
        "            video_path (Path): Path to the video file\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Last frame as numpy array\n",
        "\n",
        "        Raises:\n",
        "            VEO2VideoGenerationError: If frame extraction fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Open video capture\n",
        "            cap = cv2.VideoCapture(str(video_path))\n",
        "\n",
        "            if not cap.isOpened():\n",
        "                raise VEO2VideoGenerationError(f\"Cannot open video file: {video_path}\")\n",
        "\n",
        "            # Get total number of frames\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "            if total_frames == 0:\n",
        "                raise VEO2VideoGenerationError(f\"Video has no frames: {video_path}\")\n",
        "\n",
        "            # Seek to last frame\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)\n",
        "\n",
        "            # Read last frame\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                raise VEO2VideoGenerationError(f\"Cannot read last frame from: {video_path}\")\n",
        "\n",
        "            # Release video capture\n",
        "            cap.release()\n",
        "\n",
        "            logger.info(f\"Extracted last frame from video: {video_path}\")\n",
        "            return frame\n",
        "\n",
        "        except Exception as e:\n",
        "            raise VEO2VideoGenerationError(f\"Frame extraction failed: {str(e)}\")\n",
        "\n",
        "    def _frame_to_base64(self, frame: np.ndarray) -> Tuple[str, str]:\n",
        "        \"\"\"\n",
        "        Convert OpenCV frame (numpy array) to base64 encoded string.\n",
        "\n",
        "        Args:\n",
        "            frame (np.ndarray): OpenCV frame as numpy array\n",
        "\n",
        "        Returns:\n",
        "            Tuple[str, str]: Base64 encoded image and MIME type\n",
        "\n",
        "        Raises:\n",
        "            VEO2VideoGenerationError: If conversion fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Convert BGR to RGB (OpenCV uses BGR, PIL uses RGB)\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Convert to PIL Image\n",
        "            pil_image = Image.fromarray(frame_rgb)\n",
        "\n",
        "            # Resize for VEO-2 compatibility\n",
        "            pil_image = self._resize_image_for_veo2(pil_image)\n",
        "\n",
        "            # Convert to bytes\n",
        "            import io\n",
        "            buffer = io.BytesIO()\n",
        "            pil_image.save(buffer, format='JPEG', quality=95)\n",
        "\n",
        "            # Encode to base64\n",
        "            image_bytes = buffer.getvalue()\n",
        "            base64_encoded = base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "            return base64_encoded, 'image/jpeg'\n",
        "\n",
        "        except Exception as e:\n",
        "            raise VEO2VideoGenerationError(f\"Frame to base64 conversion failed: {str(e)}\")\n",
        "\n",
        "    def _stitch_videos(self, video_paths: List[Path], output_path: Path) -> None:\n",
        "        \"\"\"\n",
        "        Stitch multiple video files into a single seamless video.\n",
        "\n",
        "        Args:\n",
        "            video_paths (List[Path]): List of video file paths in sequence\n",
        "            output_path (Path): Path for final stitched video\n",
        "\n",
        "        Raises:\n",
        "            VEO2VideoGenerationError: If video stitching fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Load all video clips\n",
        "            video_clips = []\n",
        "\n",
        "            for video_path in video_paths:\n",
        "                if not video_path.exists():\n",
        "                    raise VEO2VideoGenerationError(f\"Video file not found: {video_path}\")\n",
        "\n",
        "                # Load video clip\n",
        "                clip = VideoFileClip(str(video_path))\n",
        "                video_clips.append(clip)\n",
        "\n",
        "                logger.info(f\"Loaded video clip: {video_path}\")\n",
        "\n",
        "            if not video_clips:\n",
        "                raise VEO2VideoGenerationError(\"No video clips to stitch\")\n",
        "\n",
        "            # Concatenate all clips\n",
        "            final_clip = concatenate_videoclips(video_clips, method=\"compose\")\n",
        "\n",
        "            # Write final video\n",
        "            final_clip.write_videofile(\n",
        "                str(output_path),\n",
        "                codec='libx264',\n",
        "                audio_codec='aac',\n",
        "                temp_audiofile='temp-audio.m4a',\n",
        "                remove_temp=True,\n",
        "                verbose=False,\n",
        "                logger=None\n",
        "            )\n",
        "\n",
        "            # Close all clips to free memory\n",
        "            for clip in video_clips:\n",
        "                clip.close()\n",
        "            final_clip.close()\n",
        "\n",
        "            logger.info(f\"Successfully stitched {len(video_clips)} videos into: {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # Ensure clips are closed on error\n",
        "            for clip in video_clips:\n",
        "                try:\n",
        "                    clip.close()\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            raise VEO2VideoGenerationError(f\"Video stitching failed: {str(e)}\")\n",
        "\n",
        "    def generate_sequential_videos(self,\n",
        "        reference_image_path: str,\n",
        "        scene_prompts: List[str],\n",
        "        api_key: str,\n",
        "        output_folder_name: str\n",
        "    ) -> Path:\n",
        "        \"\"\"\n",
        "        Main function to generate sequential videos using VEO-2 model.\n",
        "\n",
        "        This function implements the complete pipeline as specified:\n",
        "        1. Creates output subdirectory in home directory\n",
        "        2. Loads and encodes reference image\n",
        "        3. Iterates through scene prompts\n",
        "        4. Generates videos using VEO-2 with frame chaining\n",
        "        5. Stitches all videos into a final seamless video\n",
        "\n",
        "        Args:\n",
        "            reference_image_path (str): Directory location of reference image file\n",
        "            scene_prompts (List[str]): List of scene description prompts\n",
        "            api_key (str): Google Vertex AI API key (for compatibility, uses default auth)\n",
        "            output_folder_name (str): Name for output folder in home directory\n",
        "\n",
        "        Returns:\n",
        "            Path: Path to the final stitched video file\n",
        "\n",
        "        Raises:\n",
        "            VEO2VideoGenerationError: If any step in the pipeline fails\n",
        "            ValueError: If input validation fails\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Step 0: Validate all inputs\n",
        "            self._validate_inputs(reference_image_path, scene_prompts, api_key, output_folder_name)\n",
        "\n",
        "            # Step 1: Create subdirectory in home directory\n",
        "            output_dir = self._create_output_directory(output_folder_name)\n",
        "\n",
        "            # Step 2: Load and encode reference image\n",
        "            initial_image_data, initial_mime_type = self._load_and_encode_image(reference_image_path)\n",
        "\n",
        "            # Initialize variables for iteration\n",
        "            current_image_data = initial_image_data\n",
        "            current_mime_type = initial_mime_type\n",
        "            video_paths = []\n",
        "\n",
        "            # Step 3: Iterate through scene prompts\n",
        "            for i, prompt in enumerate(scene_prompts):\n",
        "                logger.info(f\"Processing prompt {i+1}/{len(scene_prompts)}: {prompt[:50]}...\")\n",
        "\n",
        "                # Step 4: Generate video using current image and prompt\n",
        "                video_uri = self._generate_video_with_veo2(\n",
        "                    prompt=prompt,\n",
        "                    image_data=current_image_data,\n",
        "                    mime_type=current_mime_type\n",
        "                )\n",
        "\n",
        "                # Step 5a: Save generated video with enumerated name\n",
        "                video_filename = f\"{i+1}.mp4\"\n",
        "                video_path = output_dir / video_filename\n",
        "\n",
        "                # Download video from GCS\n",
        "                self._download_video_from_gcs(video_uri, video_path)\n",
        "                video_paths.append(video_path)\n",
        "\n",
        "                # Step 5b: Extract last frame for next iteration (if not last prompt)\n",
        "                if i < len(scene_prompts) - 1:\n",
        "                    last_frame = self._extract_last_frame(video_path)\n",
        "                    current_image_data, current_mime_type = self._frame_to_base64(last_frame)\n",
        "\n",
        "                    logger.info(f\"Extracted last frame for next iteration\")\n",
        "\n",
        "            # Step 6: Stitch all videos into final seamless video\n",
        "            final_video_path = output_dir / \"final.mp4\"\n",
        "            self._stitch_videos(video_paths, final_video_path)\n",
        "\n",
        "            logger.info(f\"Sequential video generation completed successfully\")\n",
        "            logger.info(f\"Final video saved to: {final_video_path}\")\n",
        "\n",
        "            return final_video_path\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Sequential video generation failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "def create_veo2_video_pipeline(\n",
        "    reference_image_path: str,\n",
        "    scene_prompts: List[str],\n",
        "    api_key: str,\n",
        "    output_folder_name: str,\n",
        "    project_id: Optional[str] = None\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    Professional implementation-grade function for VEO-2 sequential video generation.\n",
        "\n",
        "    This function creates a complete video generation pipeline that:\n",
        "    1. Creates a subdirectory in the home directory\n",
        "    2. Processes a reference image for VEO-2 compatibility\n",
        "    3. Generates sequential videos using frame chaining\n",
        "    4. Stitches all videos into a seamless final output\n",
        "\n",
        "    Args:\n",
        "        reference_image_path (str): Directory location of reference image file\n",
        "        scene_prompts (List[str]): List of scene description prompts\n",
        "        api_key (str): Google Vertex AI API key\n",
        "        output_folder_name (str): Name for output folder in home directory\n",
        "        project_id (Optional[str]): Google Cloud project ID (auto-detected if None)\n",
        "\n",
        "    Returns:\n",
        "        Path: Path to the final stitched video file\n",
        "\n",
        "    Raises:\n",
        "        VEO2VideoGenerationError: If video generation pipeline fails\n",
        "        ValueError: If input parameters are invalid\n",
        "\n",
        "    Example:\n",
        "        >>> final_video = create_veo2_video_pipeline(\n",
        "        ...     reference_image_path=\"/path/to/image.jpg\",\n",
        "        ...     scene_prompts=[\n",
        "        ...         \"A bird takes flight from the tree\",\n",
        "        ...         \"The bird soars over a mountain landscape\",\n",
        "        ...         \"The bird lands near a peaceful lake\"\n",
        "        ...     ],\n",
        "        ...     api_key=\"your-vertex-ai-key\",\n",
        "        ...     output_folder_name=\"my_video_project\"\n",
        "        ... )\n",
        "        >>> print(f\"Final video created: {final_video}\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Auto-detect project ID if not provided\n",
        "        if project_id is None:\n",
        "            try:\n",
        "                _, project_id = default()\n",
        "                if not project_id:\n",
        "                    # Try to get from environment\n",
        "                    project_id = os.environ.get('GOOGLE_CLOUD_PROJECT')\n",
        "                    if not project_id:\n",
        "                        raise VEO2VideoGenerationError(\n",
        "                            \"Project ID could not be auto-detected. Please provide project_id parameter.\"\n",
        "                        )\n",
        "            except Exception as e:\n",
        "                raise VEO2VideoGenerationError(f\"Failed to auto-detect project ID: {str(e)}\")\n",
        "\n",
        "        # Initialize pipeline\n",
        "        pipeline = VEO2VideoPipeline(project_id=project_id)\n",
        "\n",
        "        # Execute complete video generation pipeline\n",
        "        final_video_path = pipeline.generate_sequential_videos(\n",
        "            reference_image_path=reference_image_path,\n",
        "            scene_prompts=scene_prompts,\n",
        "            api_key=api_key,\n",
        "            output_folder_name=output_folder_name\n",
        "        )\n",
        "\n",
        "        return final_video_path\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"VEO-2 video pipeline creation failed: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# Example usage and testing function\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    Example usage of the VEO-2 video generation pipeline.\n",
        "    \"\"\"\n",
        "\n",
        "    # Example parameters\n",
        "    example_params = {\n",
        "        \"reference_image_path\": \"/path/to/your/reference_image.jpg\",\n",
        "        \"scene_prompts\": [\n",
        "            \"A majestic eagle perched on a rocky cliff overlooking a vast canyon\",\n",
        "            \"The eagle spreads its wings and takes flight into the golden sunset\",\n",
        "            \"Soaring high above snow-capped mountains with clouds below\",\n",
        "            \"The eagle gracefully lands near a crystal clear alpine lake\"\n",
        "        ],\n",
        "        \"api_key\": \"your-google-vertex-ai-api-key\",\n",
        "        \"output_folder_name\": \"eagle_flight_sequence\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Execute the pipeline\n",
        "        final_video = create_veo2_video_pipeline(**example_params)\n",
        "        print(f\"✅ Video generation completed successfully!\")\n",
        "        print(f\"📹 Final video saved to: {final_video}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Video generation failed: {str(e)}\")\n",
        "        sys.exit(1)\n"
      ],
      "metadata": {
        "id": "BA0Z42C6VrYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Draft 2: Edited Using Gemini 2.5 Pro 06-05\n",
        "\n"
      ],
      "metadata": {
        "id": "QUbqPRk33-ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import base64\n",
        "import logging\n",
        "import shutil\n",
        "import subprocess\n",
        "import io\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "\n",
        "# Third-party imports, grouped for clarity\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "from google.auth import default, exceptions as auth_exceptions\n",
        "from google.auth.transport.requests import Request\n",
        "from google.cloud import storage\n",
        "from google.api_core import exceptions as api_core_exceptions\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
        "\n",
        "# Configure professional-grade logging for clear debugging and monitoring\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class VEOVideoGenerationError(Exception):\n",
        "    \"\"\"Custom exception for specific errors within the VEO video generation pipeline.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "# Define a set of HTTP status codes that are safe to retry on.\n",
        "# These typically represent transient server issues or rate limiting.\n",
        "RETRYABLE_STATUS_CODES = {429, 500, 502, 503, 504}\n",
        "\n",
        "def _is_retryable_http_error(exception: BaseException) -> bool:\n",
        "    \"\"\"\n",
        "    Custom tenacity retry condition to check for specific HTTP status codes.\n",
        "\n",
        "    Args:\n",
        "        exception (BaseException): The exception caught by tenacity.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the exception is an HTTPError with a retryable status code, False otherwise.\n",
        "    \"\"\"\n",
        "    # Check if the exception is an instance of requests.exceptions.HTTPError\n",
        "    return (\n",
        "        isinstance(exception, requests.exceptions.HTTPError) and\n",
        "        # Ensure the response attribute exists\n",
        "        hasattr(exception, 'response') and\n",
        "        # Check if the status code is in our set of retryable codes\n",
        "        exception.response.status_code in RETRYABLE_STATUS_CODES\n",
        "    )\n",
        "\n",
        "# Define a reusable, robust retry strategy for API calls.\n",
        "# This handles transient network errors and specific, retryable HTTP status codes.\n",
        "retry_on_api_error = retry(\n",
        "    # Use exponential backoff for waiting, starting at 4s, with a max of 60s between retries.\n",
        "    wait=wait_exponential(multiplier=1, min=4, max=60),\n",
        "    # Stop retrying after 10 attempts to prevent infinite loops.\n",
        "    stop=stop_after_attempt(10),\n",
        "    # Define the conditions for retrying: connection errors, timeouts, or specific HTTP errors.\n",
        "    retry=retry_if_exception_type((\n",
        "        requests.exceptions.ConnectionError,\n",
        "        requests.exceptions.Timeout,\n",
        "    )) | _is_retryable_http_error,\n",
        "    # Log a warning before each retry attempt for better visibility.\n",
        "    before_sleep=lambda retry_state: logger.warning(\n",
        "        f\"Retrying API call due to {retry_state.outcome.exception()}. \"\n",
        "        f\"Attempt #{retry_state.attempt_number}, waiting {retry_state.next_action.sleep:.2f}s...\"\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "class VEOVideoPipeline:\n",
        "    \"\"\"\n",
        "    A professional, implementation-grade class for Google's VEO video generation.\n",
        "\n",
        "    This class orchestrates the complete workflow of generating sequential videos using\n",
        "    Google's VEO model via its synchronous API. It handles authentication, request\n",
        "    building, response parsing (for both base64 and GCS URI), frame extraction,\n",
        "    and memory-efficient video stitching with ffmpeg.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Constants based on the official VEO API documentation ---\n",
        "    # The required OAuth scope for Vertex AI API access.\n",
        "    AUTH_SCOPE = [\"https://www.googleapis.com/auth/cloud-platform\"]\n",
        "    # The official, correct model identifier for VEO.\n",
        "    MODEL_ID = \"video-generation-001\"\n",
        "    # The standard Vertex AI method for synchronous predictions.\n",
        "    API_METHOD = \"predict\"\n",
        "    # A generous timeout for the synchronous API call to allow for video generation.\n",
        "    API_TIMEOUT_SECONDS = 900\n",
        "\n",
        "    def __init__(self, project_id: Optional[str] = None, location: str = \"us-central1\"):\n",
        "        \"\"\"\n",
        "        Initializes the VEO video generation pipeline.\n",
        "\n",
        "        Args:\n",
        "            project_id (Optional[str]): Your Google Cloud project ID. If None, it will be\n",
        "                                        auto-detected from the environment.\n",
        "            location (str): The Google Cloud region for Vertex AI. Defaults to us-central1.\n",
        "\n",
        "        Raises:\n",
        "            VEOVideoGenerationError: If initialization or authentication fails.\n",
        "        \"\"\"\n",
        "        # Validate that the location parameter is a non-empty string.\n",
        "        if not isinstance(location, str) or not location:\n",
        "            raise ValueError(\"location must be a non-empty string\")\n",
        "\n",
        "        # Store the project ID and location.\n",
        "        self.project_id: Optional[str] = project_id\n",
        "        self.location: str = location\n",
        "        # Construct the base API endpoint URL.\n",
        "        self.api_endpoint: str = f\"https://{location}-aiplatform.googleapis.com\"\n",
        "\n",
        "        # Perform authentication upon initialization.\n",
        "        self._initialize_authentication()\n",
        "\n",
        "        # After attempting auto-detection, confirm that a project_id is set.\n",
        "        if not self.project_id:\n",
        "            raise VEOVideoGenerationError(\n",
        "                \"Google Cloud project_id could not be determined. \"\n",
        "                \"Please provide it explicitly or configure the environment.\"\n",
        "            )\n",
        "\n",
        "        # Log successful initialization.\n",
        "        logger.info(f\"VEOVideoPipeline initialized for project: {self.project_id}\")\n",
        "\n",
        "    def _initialize_authentication(self) -> None:\n",
        "        \"\"\"\n",
        "        Initializes Google Cloud authentication using Application Default Credentials (ADC).\n",
        "\n",
        "        This method explicitly requests the necessary scope for Vertex AI, ensuring\n",
        "        the credentials obtained are valid for making API calls.\n",
        "\n",
        "        Raises:\n",
        "            VEOVideoGenerationError: If authentication fails.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Use google.auth.default to find credentials in the environment, requesting the correct scope.\n",
        "            self.credentials, detected_project_id = default(scopes=self.AUTH_SCOPE)\n",
        "\n",
        "            # If the project_id was not provided during initialization, use the one detected by ADC.\n",
        "            if self.project_id is None:\n",
        "                self.project_id = detected_project_id\n",
        "\n",
        "        except auth_exceptions.DefaultCredentialsError as e:\n",
        "            # Provide a user-friendly error if credentials are not found.\n",
        "            raise VEOVideoGenerationError(\n",
        "                \"Failed to find default credentials. Please run \"\n",
        "                \"'gcloud auth application-default login' or configure the environment.\"\n",
        "            ) from e\n",
        "        except Exception as e:\n",
        "            # Catch any other unexpected authentication errors.\n",
        "            raise VEOVideoGenerationError(f\"An unexpected error occurred during authentication: {e}\") from e\n",
        "\n",
        "    def _validate_inputs(\n",
        "        self,\n",
        "        reference_image_path: str,\n",
        "        scene_prompts: List[str],\n",
        "        output_folder_name: str\n",
        "    ) -> None:\n",
        "        \"\"\"Validates all user-provided inputs for the video generation pipeline.\"\"\"\n",
        "        # Validate the path to the reference image.\n",
        "        if not isinstance(reference_image_path, str) or not reference_image_path:\n",
        "            raise ValueError(\"reference_image_path must be a non-empty string.\")\n",
        "        if not os.path.exists(reference_image_path):\n",
        "            raise FileNotFoundError(f\"Reference image file not found: {reference_image_path}\")\n",
        "\n",
        "        # Validate the list of scene prompts.\n",
        "        if not isinstance(scene_prompts, list) or not scene_prompts:\n",
        "            raise ValueError(\"scene_prompts must be a non-empty list of strings.\")\n",
        "        if not all(isinstance(prompt, str) and prompt.strip() for prompt in scene_prompts):\n",
        "            raise ValueError(\"All items in scene_prompts must be non-empty strings.\")\n",
        "\n",
        "        # Validate the name for the output folder.\n",
        "        if not isinstance(output_folder_name, str) or not output_folder_name:\n",
        "            raise ValueError(\"output_folder_name must be a non-empty string.\")\n",
        "\n",
        "    def _create_output_directory(self, folder_name: str) -> Path:\n",
        "        \"\"\"Creates a subdirectory in the user's home directory for storing outputs.\"\"\"\n",
        "        try:\n",
        "            # Use Path.home() for robust, cross-platform path resolution.\n",
        "            home_dir = Path.home()\n",
        "            # Define the full path for the output directory.\n",
        "            output_dir = home_dir / folder_name\n",
        "            # Create the directory, including parent directories if needed, and set permissions.\n",
        "            output_dir.mkdir(mode=0o755, parents=True, exist_ok=True)\n",
        "            logger.info(f\"Output directory ensured at: {output_dir}\")\n",
        "            return output_dir\n",
        "        except OSError as e:\n",
        "            raise VEOVideoGenerationError(f\"Failed to create output directory '{folder_name}': {e}\") from e\n",
        "\n",
        "    def _load_and_encode_image(self, image_path: str) -> str:\n",
        "        \"\"\"Loads an image, resizes it for VEO, and encodes it to a base64 string.\"\"\"\n",
        "        try:\n",
        "            # Open the image file using a context manager to ensure it's properly closed.\n",
        "            with Image.open(image_path) as img:\n",
        "                # Convert the image to RGB to remove any alpha channel (e.g., from PNGs).\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "\n",
        "                # Resize the image to VEO's recommended dimensions while preserving aspect ratio.\n",
        "                img = self._resize_image_for_veo(img)\n",
        "\n",
        "                # Use an in-memory buffer to avoid writing a temporary file to disk.\n",
        "                buffer = io.BytesIO()\n",
        "\n",
        "                # Save the processed image to the buffer in JPEG format for efficiency.\n",
        "                img.save(buffer, format='JPEG', quality=95)\n",
        "\n",
        "                # Get the byte value from the buffer.\n",
        "                image_bytes = buffer.getvalue()\n",
        "\n",
        "                # Encode the image bytes to a base64 string and decode to utf-8.\n",
        "                base64_encoded = base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "                logger.info(f\"Successfully loaded and encoded image: {image_path}\")\n",
        "                return base64_encoded\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            raise VEOVideoGenerationError(f\"Image file not found at path: {image_path}\")\n",
        "        except Exception as e:\n",
        "            raise VEOVideoGenerationError(f\"Failed to load and encode image '{image_path}': {e}\") from e\n",
        "\n",
        "    def _resize_image_for_veo(self, img: Image.Image) -> Image.Image:\n",
        "        \"\"\"Resizes a PIL Image to VEO recommended dimensions, preserving aspect ratio.\"\"\"\n",
        "        # Get the current width and height of the image.\n",
        "        width, height = img.size\n",
        "        # Calculate the aspect ratio to determine orientation.\n",
        "        aspect_ratio = width / height\n",
        "\n",
        "        # Set target dimensions based on whether the image is landscape or portrait.\n",
        "        target_width, target_height = (1024, 576) if aspect_ratio >= 1 else (576, 1024)\n",
        "\n",
        "        # Resize the image using Lanczos resampling for high-quality results.\n",
        "        resized_img = img.resize((target_width, target_height), Image.Resampling.LANCZOS)\n",
        "\n",
        "        return resized_img\n",
        "\n",
        "    def _build_request_body(self, prompt: str, image_data: Optional[str]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Constructs the request body according to the official VEO API specification.\n",
        "\n",
        "        Args:\n",
        "            prompt (str): The text prompt for video generation.\n",
        "            image_data (Optional[str]): Base64 encoded image data for video initialization.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: The structured request body for the API call.\n",
        "        \"\"\"\n",
        "        # Define the instance payload, which contains the prompt.\n",
        "        instance_payload = {\"prompt\": prompt}\n",
        "\n",
        "        # If reference image data is provided, add it to the payload.\n",
        "        if image_data:\n",
        "            instance_payload[\"reference_image\"] = {\"image_bytes\": image_data}\n",
        "\n",
        "        # Construct the full request body with instances and parameters.\n",
        "        request_body = {\n",
        "            \"instances\": [instance_payload],\n",
        "            \"parameters\": {\n",
        "                \"video_length\": \"4s\",  # Specify desired video length (e.g., '4s', '15s').\n",
        "                \"fps\": 24,             # Specify frames per second.\n",
        "                \"seed\": np.random.randint(0, 2**32 - 1) # Use a random seed for creative variety.\n",
        "            }\n",
        "        }\n",
        "        return request_body\n",
        "\n",
        "    @retry_on_api_error\n",
        "    def _generate_video_segment(self, prompt: str, image_data: Optional[str]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generates a single video segment using the synchronous VEO API.\n",
        "\n",
        "        This function sends a request to the model and directly receives the\n",
        "        generated video data or a GCS URI in the response.\n",
        "\n",
        "        Args:\n",
        "            prompt (str): The text prompt for the video segment.\n",
        "            image_data (Optional[str]): Base64 encoded image data for initialization.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: The prediction dictionary from the API response, containing\n",
        "                            either 'video_bytes' or 'gcs_uri'.\n",
        "\n",
        "        Raises:\n",
        "            VEOVideoGenerationError: If the API request fails after all retries.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Refresh credentials before the API call to ensure the token is not expired.\n",
        "            self.credentials.refresh(Request())\n",
        "\n",
        "            # Construct the full API endpoint URL using the correct model and method.\n",
        "            url = (f\"{self.api_endpoint}/v1/projects/{self.project_id}/locations/{self.location}\"\n",
        "                   f\"/publishers/google/models/{self.MODEL_ID}:{self.API_METHOD}\")\n",
        "\n",
        "            # Prepare the authorization and content-type headers.\n",
        "            headers = {\n",
        "                'Authorization': f'Bearer {self.credentials.token}',\n",
        "                'Content-Type': 'application/json; charset=utf-8'\n",
        "            }\n",
        "\n",
        "            # Construct the request body using the dedicated helper method.\n",
        "            request_body = self._build_request_body(prompt, image_data)\n",
        "\n",
        "            logger.info(\"Sending request to VEO API. This may take several minutes...\")\n",
        "            # Send the POST request to the synchronous VEO API endpoint.\n",
        "            response = requests.post(url, headers=headers, json=request_body, timeout=self.API_TIMEOUT_SECONDS)\n",
        "            # Raise an exception for HTTP error codes (4xx or 5xx) to trigger tenacity retry if applicable.\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Parse the JSON response from the API.\n",
        "            response_data = response.json()\n",
        "\n",
        "            # Extract the list of predictions.\n",
        "            predictions = response_data.get(\"predictions\")\n",
        "            if not predictions or not isinstance(predictions, list):\n",
        "                raise VEOVideoGenerationError(f\"API response is missing 'predictions'. Response: {response_data}\")\n",
        "\n",
        "            logger.info(\"Successfully received response from VEO API.\")\n",
        "            # Return the first prediction object.\n",
        "            return predictions[0]\n",
        "\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            # Log the detailed error from the API response if available.\n",
        "            logger.error(f\"HTTP Error during video generation request: {e.response.text}\")\n",
        "            raise  # Re-raise to be handled by tenacity or the caller.\n",
        "        except Exception as e:\n",
        "            # Wrap other exceptions in our custom error type.\n",
        "            raise VEOVideoGenerationError(f\"Video generation failed: {e}\") from e\n",
        "\n",
        "    def _download_video_from_gcs(self, gcs_uri: str, local_path: Path) -> None:\n",
        "        \"\"\"Downloads a video from a Google Cloud Storage URI to a local path.\"\"\"\n",
        "        try:\n",
        "            # Validate that the GCS URI has the correct prefix.\n",
        "            if not gcs_uri.startswith('gs://'):\n",
        "                raise ValueError(f\"Invalid GCS URI format: {gcs_uri}\")\n",
        "\n",
        "            # Parse the bucket name and blob (object) name from the URI.\n",
        "            bucket_name, blob_name = gcs_uri[5:].split('/', 1)\n",
        "\n",
        "            # Initialize the Google Cloud Storage client with the correct project and credentials.\n",
        "            storage_client = storage.Client(project=self.project_id, credentials=self.credentials)\n",
        "\n",
        "            # Get the bucket and blob objects from the client.\n",
        "            bucket = storage_client.bucket(bucket_name)\n",
        "            blob = bucket.blob(blob_name)\n",
        "\n",
        "            # Download the blob to the specified local file path.\n",
        "            blob.download_to_filename(str(local_path))\n",
        "\n",
        "            logger.info(f\"Successfully downloaded video from {gcs_uri} to {local_path}\")\n",
        "\n",
        "        except (api_core_exceptions.NotFound, FileNotFoundError):\n",
        "            raise VEOVideoGenerationError(f\"GCS object not found at URI: {gcs_uri}\")\n",
        "        except Exception as e:\n",
        "            raise VEOVideoGenerationError(f\"Failed to download video from GCS: {e}\") from e\n",
        "\n",
        "    def _extract_last_frame(self, video_path: Path) -> np.ndarray:\n",
        "        \"\"\"Extracts the last frame from a video file using OpenCV.\"\"\"\n",
        "        # Initialize a video capture object with the path to the video file.\n",
        "        cap = cv2.VideoCapture(str(video_path))\n",
        "        if not cap.isOpened():\n",
        "            raise VEOVideoGenerationError(f\"Cannot open video file for frame extraction: {video_path}\")\n",
        "\n",
        "        try:\n",
        "            # Get the total number of frames in the video.\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            if total_frames == 0:\n",
        "                raise VEOVideoGenerationError(f\"Video appears to be empty (0 frames): {video_path}\")\n",
        "\n",
        "            # Set the capture position to the very last frame (which is at index total_frames - 1).\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)\n",
        "\n",
        "            # Read the frame at the current position.\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            # Check if the frame was read successfully.\n",
        "            if not ret or frame is None:\n",
        "                raise VEOVideoGenerationError(f\"Failed to read the last frame from: {video_path}\")\n",
        "\n",
        "            logger.info(f\"Successfully extracted last frame from video: {video_path}\")\n",
        "            return frame\n",
        "\n",
        "        except Exception as e:\n",
        "            raise VEOVideoGenerationError(f\"Frame extraction failed for '{video_path}': {e}\") from e\n",
        "        finally:\n",
        "            # Crucially, release the video capture object to free up resources.\n",
        "            cap.release()\n",
        "\n",
        "    def _frame_to_base64(self, frame: np.ndarray) -> str:\n",
        "        \"\"\"Converts an OpenCV frame (NumPy array) to a base64 encoded string.\"\"\"\n",
        "        try:\n",
        "            # Convert the frame from OpenCV's BGR color space to PIL's RGB color space.\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Create a PIL Image object from the NumPy array.\n",
        "            pil_image = Image.fromarray(frame_rgb)\n",
        "\n",
        "            # Resize the frame to ensure it's compatible with VEO's input requirements.\n",
        "            pil_image = self._resize_image_for_veo(pil_image)\n",
        "\n",
        "            # Use an in-memory buffer to save the image without writing to disk.\n",
        "            buffer = io.BytesIO()\n",
        "            pil_image.save(buffer, format='JPEG', quality=95)\n",
        "\n",
        "            # Get the byte value and encode it to a utf-8 decoded base64 string.\n",
        "            image_bytes = buffer.getvalue()\n",
        "            base64_encoded = base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "            return base64_encoded\n",
        "\n",
        "        except Exception as e:\n",
        "            raise VEOVideoGenerationError(f\"Frame to base64 conversion failed: {e}\") from e\n",
        "\n",
        "    def _stitch_videos_ffmpeg(self, video_paths: List[Path], output_path: Path) -> None:\n",
        "        \"\"\"\n",
        "        Stitches multiple video files into one using ffmpeg's concat demuxer.\n",
        "\n",
        "        This method is highly memory-efficient as it avoids loading video clips\n",
        "        into memory, making it suitable for stitching many or large files.\n",
        "\n",
        "        Args:\n",
        "            video_paths (List[Path]): An ordered list of video file paths to concatenate.\n",
        "            output_path (Path): The path for the final stitched video file.\n",
        "\n",
        "        Raises:\n",
        "            VEOVideoGenerationError: If video stitching fails or ffmpeg is not found.\n",
        "        \"\"\"\n",
        "        # Check if the ffmpeg executable is available in the system's PATH.\n",
        "        if not shutil.which(\"ffmpeg\"):\n",
        "            raise FileNotFoundError(\n",
        "                \"ffmpeg not found. Please install ffmpeg and ensure it is in your system's PATH.\"\n",
        "            )\n",
        "\n",
        "        # Ensure there are videos to stitch.\n",
        "        if not video_paths:\n",
        "            raise VEOVideoGenerationError(\"No video clips were provided to stitch.\")\n",
        "\n",
        "        # Create a temporary manifest file for ffmpeg in the same directory as the output.\n",
        "        manifest_path = output_path.with_suffix('.txt')\n",
        "\n",
        "        try:\n",
        "            # Write the list of video files to the manifest in the format required by ffmpeg.\n",
        "            with open(manifest_path, 'w') as f:\n",
        "                for video_path in video_paths:\n",
        "                    if not video_path.exists():\n",
        "                        raise FileNotFoundError(f\"Video file for stitching not found: {video_path}\")\n",
        "                    # Use resolved absolute paths and quotes to handle special characters safely.\n",
        "                    f.write(f\"file '{video_path.resolve()}'\\n\")\n",
        "\n",
        "            logger.info(f\"Created ffmpeg manifest at: {manifest_path}\")\n",
        "\n",
        "            # Construct the ffmpeg command.\n",
        "            # -y: Overwrite output file if it exists.\n",
        "            # -f concat: Use the concat demuxer.\n",
        "            # -safe 0: Allow absolute paths in the manifest file.\n",
        "            # -i: Specify the input manifest file.\n",
        "            # -c copy: Copy codecs without re-encoding for maximum speed and quality preservation.\n",
        "            #          This assumes all segments have compatible codecs, which is true for VEO outputs.\n",
        "            command = [\n",
        "                \"ffmpeg\",\n",
        "                \"-y\",\n",
        "                \"-f\", \"concat\",\n",
        "                \"-safe\", \"0\",\n",
        "                \"-i\", str(manifest_path),\n",
        "                \"-c\", \"copy\",\n",
        "                str(output_path)\n",
        "            ]\n",
        "\n",
        "            logger.info(f\"Executing ffmpeg command: {' '.join(command)}\")\n",
        "\n",
        "            # Execute the command, capturing stdout and stderr for debugging.\n",
        "            result = subprocess.run(\n",
        "                command,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                check=False # We check the return code manually for better error reporting.\n",
        "            )\n",
        "\n",
        "            # Check if the ffmpeg command executed successfully.\n",
        "            if result.returncode != 0:\n",
        "                # If it failed, raise an error with the stderr from ffmpeg.\n",
        "                raise VEOVideoGenerationError(\n",
        "                    f\"ffmpeg failed with exit code {result.returncode}.\\n\"\n",
        "                    f\"Stderr: {result.stderr}\"\n",
        "                )\n",
        "\n",
        "            logger.info(f\"Successfully stitched {len(video_paths)} videos into: {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # Wrap any exception in our custom error type.\n",
        "            raise VEOVideoGenerationError(f\"Video stitching failed: {e}\") from e\n",
        "        finally:\n",
        "            # Ensure the temporary manifest file is always cleaned up.\n",
        "            if manifest_path.exists():\n",
        "                manifest_path.unlink()\n",
        "                logger.info(f\"Cleaned up manifest file: {manifest_path}\")\n",
        "\n",
        "    def generate_sequential_videos(self,\n",
        "        reference_image_path: str,\n",
        "        scene_prompts: List[str],\n",
        "        output_folder_name: str\n",
        "    ) -> Path:\n",
        "        \"\"\"\n",
        "        Executes the full pipeline to generate a sequence of chained videos.\n",
        "\n",
        "        This is the main public method that orchestrates the entire process from\n",
        "        the initial image to the final stitched video.\n",
        "\n",
        "        Args:\n",
        "            reference_image_path (str): Path to the initial reference image file.\n",
        "            scene_prompts (List[str]): An ordered list of scene description prompts.\n",
        "            output_folder_name (str): The name for the output folder in the home directory.\n",
        "\n",
        "        Returns:\n",
        "            Path: The path to the final, stitched video file.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Step 0: Validate all inputs before starting any processing.\n",
        "            self._validate_inputs(reference_image_path, scene_prompts, output_folder_name)\n",
        "\n",
        "            # Step 1: Create the output directory to store all artifacts.\n",
        "            output_dir = self._create_output_directory(output_folder_name)\n",
        "\n",
        "            # Step 2: Load and encode the initial reference image to start the sequence.\n",
        "            current_image_data = self._load_and_encode_image(reference_image_path)\n",
        "\n",
        "            # Initialize a list to store the paths of the generated video segments.\n",
        "            video_paths = []\n",
        "\n",
        "            # Step 3: Iterate through each scene prompt to generate a video segment.\n",
        "            for i, prompt in enumerate(scene_prompts):\n",
        "                logger.info(f\"--- Processing Scene {i+1}/{len(scene_prompts)} ---\")\n",
        "                logger.info(f\"Prompt: '{prompt[:100]}...'\")\n",
        "\n",
        "                # Step 4: Generate a video segment using the current image and prompt.\n",
        "                prediction = self._generate_video_segment(\n",
        "                    prompt=prompt,\n",
        "                    image_data=current_image_data\n",
        "                )\n",
        "\n",
        "                # Define a unique filename for this video segment.\n",
        "                video_filename = f\"segment_{i+1:03d}.mp4\"\n",
        "                video_path = output_dir / video_filename\n",
        "\n",
        "                # Step 5: Process the API response, which could be bytes or a GCS URI.\n",
        "                if 'video_bytes' in prediction:\n",
        "                    # If video bytes are returned, decode them from base64 and save to a file.\n",
        "                    logger.info(f\"Received video as base64 bytes. Saving to {video_path}\")\n",
        "                    video_bytes = base64.b64decode(prediction['video_bytes'])\n",
        "                    with open(video_path, 'wb') as f:\n",
        "                        f.write(video_bytes)\n",
        "                elif 'gcs_uri' in prediction:\n",
        "                    # If a GCS URI is returned, download the video from the bucket.\n",
        "                    logger.info(f\"Received GCS URI. Downloading from {prediction['gcs_uri']}\")\n",
        "                    self._download_video_from_gcs(prediction['gcs_uri'], video_path)\n",
        "                else:\n",
        "                    # If neither is present, the response is invalid.\n",
        "                    raise VEOVideoGenerationError(f\"API prediction did not contain 'video_bytes' or 'gcs_uri': {prediction}\")\n",
        "\n",
        "                # Add the path of the newly created segment to our list.\n",
        "                video_paths.append(video_path)\n",
        "\n",
        "                # Step 6: For all but the last prompt, extract the last frame to seed the next segment.\n",
        "                if i < len(scene_prompts) - 1:\n",
        "                    logger.info(\"Extracting last frame to use as reference for the next segment...\")\n",
        "                    last_frame = self._extract_last_frame(video_path)\n",
        "                    current_image_data = self._frame_to_base64(last_frame)\n",
        "\n",
        "            # Step 7: Stitch all generated video segments into a single final video.\n",
        "            final_video_path = output_dir / \"final_stitched_video.mp4\"\n",
        "            self._stitch_videos_ffmpeg(video_paths, final_video_path)\n",
        "\n",
        "            logger.info(\"--- Sequential video generation pipeline completed successfully. ---\")\n",
        "            logger.info(f\"Final video saved to: {final_video_path}\")\n",
        "\n",
        "            return final_video_path\n",
        "\n",
        "        except (VEOVideoGenerationError, ValueError, FileNotFoundError) as e:\n",
        "            # Catch known, specific errors and log them before re-raising.\n",
        "            logger.error(f\"A predictable error occurred in the pipeline: {e}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            # Catch any other unexpected errors for robust failure handling.\n",
        "            logger.error(f\"An unexpected error occurred in the main pipeline: {e}\", exc_info=True)\n",
        "            raise VEOVideoGenerationError(f\"An unexpected error occurred in the main pipeline: {e}\") from e\n",
        "\n",
        "\n",
        "def create_veo_video_pipeline(\n",
        "    reference_image_path: str,\n",
        "    scene_prompts: List[str],\n",
        "    output_folder_name: str,\n",
        "    project_id: Optional[str] = None\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    A high-level factory function to create and run the VEO sequential video pipeline.\n",
        "\n",
        "    This function abstracts away the class instantiation and execution, providing a\n",
        "    simple, clean interface to generate a complete video from an image and prompts.\n",
        "\n",
        "    Args:\n",
        "        reference_image_path (str): Path to the initial reference image file.\n",
        "        scene_prompts (List[str]): An ordered list of scene description prompts.\n",
        "        output_folder_name (str): The name for the output folder in the home directory.\n",
        "        project_id (Optional[str]): Your Google Cloud project ID. If None, it will be\n",
        "                                    auto-detected from ADC or environment variables.\n",
        "\n",
        "    Returns:\n",
        "        Path: The path to the final, stitched video file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # If project_id is not provided, attempt to get it from the environment as a fallback.\n",
        "        if project_id is None:\n",
        "            project_id = os.environ.get('GOOGLE_CLOUD_PROJECT')\n",
        "            if project_id:\n",
        "                logger.info(f\"Using project ID from GOOGLE_CLOUD_PROJECT env var: {project_id}\")\n",
        "\n",
        "        # Initialize the VEO pipeline class.\n",
        "        pipeline = VEOVideoPipeline(project_id=project_id)\n",
        "\n",
        "        # Execute the complete video generation pipeline with the provided parameters.\n",
        "        final_video_path = pipeline.generate_sequential_videos(\n",
        "            reference_image_path=reference_image_path,\n",
        "            scene_prompts=scene_prompts,\n",
        "            output_folder_name=output_folder_name\n",
        "        )\n",
        "\n",
        "        return final_video_path\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch and log exceptions from the pipeline for clear top-level error reporting.\n",
        "        logger.error(f\"VEO video pipeline execution failed: {e}\")\n",
        "        # Re-raise the exception to allow the caller to handle it.\n",
        "        raise\n",
        "\n",
        "\n",
        "# Example usage and testing block\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    Example usage of the corrected and robust VEO video generation pipeline.\n",
        "\n",
        "    *** IMPORTANT: CONFIGURATION REQUIRED ***\n",
        "    1.  **AUTHENTICATION**: Run `gcloud auth application-default login` in your terminal.\n",
        "    2.  **PROJECT ID**: Set the `GOOGLE_CLOUD_PROJECT` environment variable to your GCP project ID,\n",
        "        or pass the `project_id` argument to `create_veo_video_pipeline`.\n",
        "    3.  **APIs**: Ensure the Vertex AI API is enabled in your Google Cloud project.\n",
        "    4.  **DEPENDENCIES**: Install required packages:\n",
        "        pip install google-cloud-aiplatform google-cloud-storage opencv-python Pillow requests tenacity numpy\n",
        "    5.  **FFMPEG**: Install ffmpeg (https://ffmpeg.org/download.html) and ensure it is in your system's PATH.\n",
        "    6.  **REFERENCE IMAGE**: Replace the dummy image path with a path to your own image.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- CONFIGURE THESE PARAMETERS FOR YOUR RUN ---\n",
        "    try:\n",
        "        # Get the directory of the current script to create a sample image nearby.\n",
        "        script_dir = Path(__file__).parent\n",
        "    except NameError:\n",
        "        # Fallback for interactive environments where __file__ is not defined.\n",
        "        script_dir = Path.cwd()\n",
        "\n",
        "    # Create a dummy reference image for testing if one doesn't exist.\n",
        "    dummy_image_path = script_dir / \"veo_reference_image.jpg\"\n",
        "    if not dummy_image_path.exists():\n",
        "        print(f\"Creating a dummy reference image at: {dummy_image_path}\")\n",
        "        # A blue 16:9 image.\n",
        "        dummy_img = Image.new('RGB', (1024, 576), color='darkblue')\n",
        "        dummy_img.save(dummy_image_path)\n",
        "\n",
        "    # Define the parameters for the video generation task.\n",
        "    example_params = {\n",
        "        \"reference_image_path\": str(dummy_image_path),\n",
        "        \"scene_prompts\": [\n",
        "            \"A majestic eagle perched on a rocky cliff overlooking a vast canyon, cinematic lighting.\",\n",
        "            \"The eagle spreads its wings and takes flight into the golden sunset, slow motion.\",\n",
        "            \"Soaring high above snow-capped mountains with clouds below, drone shot.\",\n",
        "            \"The eagle gracefully lands near a crystal clear alpine lake, its reflection in the water.\"\n",
        "        ],\n",
        "        \"output_folder_name\": \"veo_eagle_flight_sequence\",\n",
        "        # \"project_id\": \"your-gcp-project-id\"  # Optional: uncomment and set if needed.\n",
        "    }\n",
        "\n",
        "    print(\"--- Starting VEO Video Generation Pipeline ---\")\n",
        "    print(f\"Reference Image: {example_params['reference_image_path']}\")\n",
        "    print(f\"Output Folder Name: {example_params['output_folder_name']}\")\n",
        "    print(f\"Number of Scenes: {len(example_params['scene_prompts'])}\")\n",
        "\n",
        "    try:\n",
        "        # Execute the pipeline.\n",
        "        start_time = time.time()\n",
        "        final_video = create_veo_video_pipeline(**example_params)\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Print a success message with the final output path.\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"✅ Video generation pipeline completed successfully!\")\n",
        "        print(f\"📹 Final video saved to: {final_video}\")\n",
        "        print(f\"⏱️ Total execution time: {end_time - start_time:.2f} seconds.\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    except (VEOVideoGenerationError, ValueError, FileNotFoundError) as e:\n",
        "        # Handle known pipeline failures gracefully.\n",
        "        print(f\"\\n❌ PIPELINE FAILED: {e}\")\n",
        "        sys.exit(1)\n",
        "    except Exception as e:\n",
        "        # Handle any other unexpected errors.\n",
        "        print(f\"\\n❌ AN UNEXPECTED ERROR OCCURRED: {e}\")\n",
        "        sys.exit(1)\n"
      ],
      "metadata": {
        "id": "XN3ZXUmOFfmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Standard Library Imports ---\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import base64\n",
        "import logging\n",
        "import shutil\n",
        "import subprocess\n",
        "import io\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "\n",
        "# --- Third-party Imports, Grouped for Clarity ---\n",
        "import cv2\n",
        "import numpy as np\n",
        "from numpy.typing import NDArray\n",
        "from PIL import Image\n",
        "import requests\n",
        "from google.auth import default, exceptions as auth_exceptions\n",
        "from google.auth.transport.requests import Request\n",
        "from google.cloud import storage\n",
        "from google.api_core import exceptions as api_core_exceptions\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
        "\n",
        "# --- Professional-Grade Logging Configuration ---\n",
        "# Configure a logger for clear, standardized output for debugging and monitoring.\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "# Instantiate the logger using the standard __name__ convention.\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# --- Centralized Configuration Class ---\n",
        "class VEOConfig:\n",
        "    \"\"\"\n",
        "    A centralized, immutable configuration class for VEO API constants.\n",
        "\n",
        "    This provides a single source of truth for static parameters, improving\n",
        "    maintainability and preventing the use of \"magic\" strings or numbers\n",
        "    in the pipeline logic.\n",
        "    \"\"\"\n",
        "    # The required OAuth scope for authenticating with the Vertex AI API.\n",
        "    AUTH_SCOPE: List[str] = [\"https://www.googleapis.com/auth/cloud-platform\"]\n",
        "    # The official, versioned model identifier for Google's VEO model.\n",
        "    MODEL_ID: str = \"video-generation-001\"\n",
        "    # The standard Vertex AI API method for synchronous (blocking) predictions.\n",
        "    API_METHOD: str = \"predict\"\n",
        "    # A generous timeout for the synchronous API call to allow for video generation.\n",
        "    API_TIMEOUT_SECONDS: int = 900\n",
        "    # The set of HTTP status codes that indicate transient server-side issues safe to retry.\n",
        "    RETRYABLE_STATUS_CODES: set[int] = {429, 500, 502, 503, 504}\n",
        "    # Recommended VEO dimensions for landscape videos (width, height).\n",
        "    LANDSCAPE_DIMS: Tuple[int, int] = (1024, 576)\n",
        "    # Recommended VEO dimensions for portrait videos (width, height).\n",
        "    PORTRAIT_DIMS: Tuple[int, int] = (576, 1024)\n",
        "    # Default video generation parameters.\n",
        "    DEFAULT_VIDEO_LENGTH: str = \"4s\"\n",
        "    DEFAULT_FPS: int = 24\n",
        "    # JPEG quality for encoding reference frames. 95 is a high-quality setting.\n",
        "    JPEG_ENCODING_QUALITY: int = 95\n",
        "\n",
        "\n",
        "# --- Custom Exception for Pipeline-Specific Errors ---\n",
        "class VEOVideoGenerationError(Exception):\n",
        "    \"\"\"Custom exception for specific, identifiable errors within the VEO video generation pipeline.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "# --- Robust Retry Logic for API Calls ---\n",
        "def _is_retryable_http_error(exception: BaseException) -> bool:\n",
        "    \"\"\"\n",
        "    Custom tenacity retry condition to check for specific HTTP status codes.\n",
        "\n",
        "    This function determines if a caught exception is a requests.HTTPError with a\n",
        "    status code that is defined as retryable in VEOConfig.\n",
        "\n",
        "    Args:\n",
        "        exception (BaseException): The exception caught by tenacity.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the exception is an HTTPError with a retryable status code, False otherwise.\n",
        "    \"\"\"\n",
        "    # Return True only if the exception is an HTTPError and its status code is in our retryable set.\n",
        "    return (\n",
        "        isinstance(exception, requests.exceptions.HTTPError) and\n",
        "        hasattr(exception, 'response') and\n",
        "        exception.response.status_code in VEOConfig.RETRYABLE_STATUS_CODES\n",
        "    )\n",
        "\n",
        "# Define a reusable, robust retry strategy for API calls using the tenacity library.\n",
        "retry_on_api_error = retry(\n",
        "    # Use exponential backoff, starting at 4s and maxing out at 60s between retries.\n",
        "    wait=wait_exponential(multiplier=1, min=4, max=60),\n",
        "    # Stop retrying after 10 attempts to prevent indefinite loops and fail gracefully.\n",
        "    stop=stop_after_attempt(10),\n",
        "    # Define the conditions for retrying: network errors or specific HTTP server errors.\n",
        "    retry=retry_if_exception_type((\n",
        "        requests.exceptions.ConnectionError,\n",
        "        requests.exceptions.Timeout,\n",
        "    )) | _is_retryable_http_error,\n",
        "    # Log a warning before each retry attempt for visibility into transient failures.\n",
        "    before_sleep=lambda retry_state: logger.warning(\n",
        "        f\"Retrying API call due to {retry_state.outcome.exception()}. \"\n",
        "        f\"Attempt #{retry_state.attempt_number}, waiting {retry_state.next_action.sleep:.2f}s...\"\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "class VEOVideoPipeline:\n",
        "    \"\"\"\n",
        "    A professional, implementation-grade class for Google's VEO video generation.\n",
        "\n",
        "    This class orchestrates the complete workflow of generating sequential videos using\n",
        "    Google's VEO model via its synchronous API. It handles authentication, request\n",
        "    building, response parsing, frame extraction, and memory-efficient video stitching.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, project_id: Optional[str] = None, location: str = \"us-central1\"):\n",
        "        \"\"\"\n",
        "        Initializes the VEO video generation pipeline.\n",
        "\n",
        "        Args:\n",
        "            project_id (Optional[str]): Your Google Cloud project ID. If None, it will be\n",
        "                                        auto-detected from the environment.\n",
        "            location (str): The Google Cloud region for Vertex AI. Defaults to us-central1.\n",
        "\n",
        "        Raises:\n",
        "            VEOVideoGenerationError: If initialization or authentication fails.\n",
        "            ValueError: If input parameters are invalid.\n",
        "        \"\"\"\n",
        "        # Validate that the location parameter is a non-empty string.\n",
        "        if not isinstance(location, str) or not location:\n",
        "            raise ValueError(\"location must be a non-empty string\")\n",
        "\n",
        "        # Store the project ID and location as instance-specific attributes.\n",
        "        self.project_id: Optional[str] = project_id\n",
        "        self.location: str = location\n",
        "        # Construct the base API endpoint URL for Vertex AI.\n",
        "        self.api_endpoint: str = f\"https://{location}-aiplatform.googleapis.com\"\n",
        "\n",
        "        # Perform authentication immediately upon initialization to fail fast.\n",
        "        self._initialize_authentication()\n",
        "\n",
        "        # After attempting auto-detection, confirm that a project_id is set.\n",
        "        if not self.project_id:\n",
        "            raise VEOVideoGenerationError(\n",
        "                \"Google Cloud project_id could not be determined. \"\n",
        "                \"Please provide it explicitly or configure the environment.\"\n",
        "            )\n",
        "\n",
        "        # Log successful initialization for monitoring purposes.\n",
        "        logger.info(f\"VEOVideoPipeline initialized for project: {self.project_id}\")\n",
        "\n",
        "    def _initialize_authentication(self) -> None:\n",
        "        \"\"\"\n",
        "        Initializes Google Cloud authentication using Application Default Credentials (ADC).\n",
        "\n",
        "        This method explicitly requests the necessary scope for Vertex AI, ensuring\n",
        "        the credentials obtained are valid for making API calls.\n",
        "\n",
        "        Raises:\n",
        "            VEOVideoGenerationError: If authentication fails for any reason.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Use google.auth.default to find credentials, requesting the correct scope from VEOConfig.\n",
        "            self.credentials, detected_project_id = default(scopes=VEOConfig.AUTH_SCOPE)\n",
        "\n",
        "            # If the project_id was not provided during initialization, use the one detected by ADC.\n",
        "            if self.project_id is None:\n",
        "                self.project_id = detected_project_id\n",
        "\n",
        "        except auth_exceptions.DefaultCredentialsError as e:\n",
        "            # Provide a user-friendly error if credentials are not found in the environment.\n",
        "            raise VEOVideoGenerationError(\n",
        "                \"Failed to find default credentials. Please run \"\n",
        "                \"'gcloud auth application-default login' or configure the environment.\"\n",
        "            ) from e\n",
        "        except Exception as e:\n",
        "            # Catch any other unexpected authentication errors and wrap them in our custom exception.\n",
        "            raise VEOVideoGenerationError(f\"An unexpected error occurred during authentication: {e}\") from e\n",
        "\n",
        "    def _validate_inputs(\n",
        "        self,\n",
        "        reference_image_path: str,\n",
        "        scene_prompts: List[str],\n",
        "        output_folder_name: str\n",
        "    ) -> None:\n",
        "        \"\"\"Validates all user-provided inputs for the video generation pipeline.\"\"\"\n",
        "        # Validate the path to the reference image is a non-empty string.\n",
        "        if not isinstance(reference_image_path, str) or not reference_image_path:\n",
        "            raise ValueError(\"reference_image_path must be a non-empty string.\")\n",
        "        # Validate the reference image file actually exists.\n",
        "        if not os.path.exists(reference_image_path):\n",
        "            raise FileNotFoundError(f\"Reference image file not found: {reference_image_path}\")\n",
        "\n",
        "        # Validate that scene_prompts is a non-empty list.\n",
        "        if not isinstance(scene_prompts, list) or not scene_prompts:\n",
        "            raise ValueError(\"scene_prompts must be a non-empty list of strings.\")\n",
        "        # Validate that every item in the list is a non-empty, non-whitespace string.\n",
        "        if not all(isinstance(prompt, str) and prompt.strip() for prompt in scene_prompts):\n",
        "            raise ValueError(\"All items in scene_prompts must be non-empty strings.\")\n",
        "\n",
        "        # Validate the name for the output folder is a non-empty string.\n",
        "        if not isinstance(output_folder_name, str) or not output_folder_name:\n",
        "            raise ValueError(\"output_folder_name must be a non-empty string.\")\n",
        "\n",
        "    def _create_output_directory(self, folder_name: str) -> Path:\n",
        "        \"\"\"Creates a subdirectory in the user's home directory for storing outputs.\"\"\"\n",
        "        try:\n",
        "            # Use Path.home() for robust, cross-platform path resolution to the user's home directory.\n",
        "            home_dir = Path.home()\n",
        "            # Define the full path for the output directory.\n",
        "            output_dir = home_dir / folder_name\n",
        "            # Create the directory, including parent directories if needed, and set standard permissions.\n",
        "            output_dir.mkdir(mode=0o755, parents=True, exist_ok=True)\n",
        "            # Log the successful creation or confirmation of the directory.\n",
        "            logger.info(f\"Output directory ensured at: {output_dir}\")\n",
        "            return output_dir\n",
        "        except OSError as e:\n",
        "            # Raise a custom error if directory creation fails due to OS-level issues.\n",
        "            raise VEOVideoGenerationError(f\"Failed to create output directory '{folder_name}': {e}\") from e\n",
        "\n",
        "    def _load_and_encode_image(self, image_path: str) -> str:\n",
        "        \"\"\"Loads an image, resizes it for VEO, and encodes it to a base64 string.\"\"\"\n",
        "        try:\n",
        "            # Open the image file using a context manager to ensure it's properly closed.\n",
        "            with Image.open(image_path) as img:\n",
        "                # Convert the image to RGB to remove any alpha channel (e.g., from PNGs), ensuring compatibility.\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "\n",
        "                # Resize the image to VEO's recommended dimensions while preserving aspect ratio.\n",
        "                img = self._resize_image_for_veo(img)\n",
        "\n",
        "                # Use an in-memory buffer to avoid writing a temporary file to disk, which is more efficient.\n",
        "                buffer = io.BytesIO()\n",
        "\n",
        "                # Save the processed image to the buffer in JPEG format for efficiency and smaller payload size.\n",
        "                img.save(buffer, format='JPEG', quality=VEOConfig.JPEG_ENCODING_QUALITY)\n",
        "\n",
        "                # Get the raw byte value from the buffer.\n",
        "                image_bytes = buffer.getvalue()\n",
        "\n",
        "                # Encode the image bytes to a base64 string and decode to utf-8 for JSON serialization.\n",
        "                base64_encoded = base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "                # Log the successful operation.\n",
        "                logger.info(f\"Successfully loaded and encoded image: {image_path}\")\n",
        "                return base64_encoded\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            # Raise a specific error if the file does not exist.\n",
        "            raise VEOVideoGenerationError(f\"Image file not found at path: {image_path}\")\n",
        "        except Exception as e:\n",
        "            # Wrap any other image processing errors in our custom exception.\n",
        "            raise VEOVideoGenerationError(f\"Failed to load and encode image '{image_path}': {e}\") from e\n",
        "\n",
        "    def _resize_image_for_veo(self, img: Image.Image) -> Image.Image:\n",
        "        \"\"\"Resizes a PIL Image to VEO recommended dimensions, preserving aspect ratio.\"\"\"\n",
        "        # Get the current width and height of the image.\n",
        "        width, height = img.size\n",
        "        # Calculate the aspect ratio to determine if the image is landscape, portrait, or square.\n",
        "        aspect_ratio = width / height\n",
        "\n",
        "        # Set target dimensions from VEOConfig based on whether the image is landscape (or square) or portrait.\n",
        "        target_dims = VEOConfig.LANDSCAPE_DIMS if aspect_ratio >= 1 else VEOConfig.PORTRAIT_DIMS\n",
        "\n",
        "        # Resize the image using Lanczos resampling, which provides high-quality downscaling results.\n",
        "        resized_img = img.resize(target_dims, Image.Resampling.LANCZOS)\n",
        "\n",
        "        return resized_img\n",
        "\n",
        "    def _build_request_body(self, prompt: str, image_data: Optional[str]) -> Dict[str, Any]:\n",
        "        \"\"\"Constructs the request body according to the official VEO API specification.\"\"\"\n",
        "        # Define the instance payload, which contains the core prompt.\n",
        "        instance_payload = {\"prompt\": prompt}\n",
        "\n",
        "        # If reference image data is provided (for the first or subsequent segments), add it to the payload.\n",
        "        if image_data:\n",
        "            instance_payload[\"reference_image\"] = {\"image_bytes\": image_data}\n",
        "\n",
        "        # Construct the full request body with instances and parameters from VEOConfig.\n",
        "        request_body = {\n",
        "            \"instances\": [instance_payload],\n",
        "            \"parameters\": {\n",
        "                \"video_length\": VEOConfig.DEFAULT_VIDEO_LENGTH,\n",
        "                \"fps\": VEOConfig.DEFAULT_FPS,\n",
        "                \"seed\": np.random.randint(0, 2**32 - 1) # Use a random seed for creative variety.\n",
        "            }\n",
        "        }\n",
        "        return request_body\n",
        "\n",
        "    @retry_on_api_error\n",
        "    def _generate_video_segment(self, prompt: str, image_data: Optional[str]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generates a single video segment using the synchronous VEO API with robust retries.\n",
        "\n",
        "        Args:\n",
        "            prompt (str): The text prompt for the video segment.\n",
        "            image_data (Optional[str]): Base64 encoded image data for initialization.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: The prediction dictionary from the API response.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Refresh credentials before the API call to ensure the auth token is not expired.\n",
        "            self.credentials.refresh(Request())\n",
        "\n",
        "            # Construct the full API endpoint URL using constants from VEOConfig for accuracy.\n",
        "            url = (f\"{self.api_endpoint}/v1/projects/{self.project_id}/locations/{self.location}\"\n",
        "                   f\"/publishers/google/models/{VEOConfig.MODEL_ID}:{VEOConfig.API_METHOD}\")\n",
        "\n",
        "            # Prepare the authorization and content-type headers for the request.\n",
        "            headers = {\n",
        "                'Authorization': f'Bearer {self.credentials.token}',\n",
        "                'Content-Type': 'application/json; charset=utf-8'\n",
        "            }\n",
        "\n",
        "            # Construct the request body using the dedicated helper method.\n",
        "            request_body = self._build_request_body(prompt, image_data)\n",
        "\n",
        "            # Log the request initiation. This is a long-running operation.\n",
        "            logger.info(\"Sending request to VEO API. This may take several minutes...\")\n",
        "            # Send the POST request to the VEO API with a configured timeout.\n",
        "            response = requests.post(url, headers=headers, json=request_body, timeout=VEOConfig.API_TIMEOUT_SECONDS)\n",
        "            # Raise an exception for HTTP error codes (4xx or 5xx), which tenacity will catch for retries.\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Parse the JSON response from the API.\n",
        "            response_data = response.json()\n",
        "\n",
        "            # Extract the list of predictions from the response body.\n",
        "            predictions = response_data.get(\"predictions\")\n",
        "            # Validate that the predictions list exists and is not empty.\n",
        "            if not predictions or not isinstance(predictions, list):\n",
        "                raise VEOVideoGenerationError(f\"API response is missing 'predictions'. Response: {response_data}\")\n",
        "\n",
        "            # Log the successful receipt of the response.\n",
        "            logger.info(\"Successfully received response from VEO API.\")\n",
        "            # Return the first prediction object, as we send one instance at a time.\n",
        "            return predictions[0]\n",
        "\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            # Log the detailed error from the API response body if available for easier debugging.\n",
        "            logger.error(f\"HTTP Error during video generation request: {e.response.text}\")\n",
        "            raise  # Re-raise the exception to be handled by the tenacity retry decorator or the caller.\n",
        "        except Exception as e:\n",
        "            # Wrap any other exceptions in our custom error type for consistent error handling.\n",
        "            raise VEOVideoGenerationError(f\"Video generation failed: {e}\") from e\n",
        "\n",
        "    def _download_video_from_gcs(self, gcs_uri: str, local_path: Path) -> None:\n",
        "        \"\"\"Downloads a video from a Google Cloud Storage URI to a local path.\"\"\"\n",
        "        try:\n",
        "            # Validate that the GCS URI has the correct 'gs://' prefix.\n",
        "            if not gcs_uri.startswith('gs://'):\n",
        "                raise ValueError(f\"Invalid GCS URI format: {gcs_uri}\")\n",
        "\n",
        "            # Parse the bucket name and blob (object) name from the URI string.\n",
        "            bucket_name, blob_name = gcs_uri[5:].split('/', 1)\n",
        "\n",
        "            # Initialize the Google Cloud Storage client with the correct project and credentials.\n",
        "            storage_client = storage.Client(project=self.project_id, credentials=self.credentials)\n",
        "\n",
        "            # Get a reference to the bucket and blob objects.\n",
        "            bucket = storage_client.bucket(bucket_name)\n",
        "            blob = bucket.blob(blob_name)\n",
        "\n",
        "            # Download the blob's contents to the specified local file path.\n",
        "            blob.download_to_filename(str(local_path))\n",
        "\n",
        "            # Log the successful download.\n",
        "            logger.info(f\"Successfully downloaded video from {gcs_uri} to {local_path}\")\n",
        "\n",
        "        except (api_core_exceptions.NotFound, FileNotFoundError):\n",
        "            # Handle cases where the GCS object does not exist.\n",
        "            raise VEOVideoGenerationError(f\"GCS object not found at URI: {gcs_uri}\")\n",
        "        except Exception as e:\n",
        "            # Wrap any other GCS-related errors.\n",
        "            raise VEOVideoGenerationError(f\"Failed to download video from GCS: {e}\") from e\n",
        "\n",
        "    def _extract_last_frame(self, video_path: Path) -> NDArray[np.uint8]:\n",
        "        \"\"\"Extracts the last frame from a video file using OpenCV.\"\"\"\n",
        "        # Initialize a video capture object with the path to the video file.\n",
        "        cap = cv2.VideoCapture(str(video_path))\n",
        "        # Check if the video file was opened successfully.\n",
        "        if not cap.isOpened():\n",
        "            raise VEOVideoGenerationError(f\"Cannot open video file for frame extraction: {video_path}\")\n",
        "\n",
        "        try:\n",
        "            # Get the total number of frames in the video.\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            # Ensure the video is not empty.\n",
        "            if total_frames == 0:\n",
        "                raise VEOVideoGenerationError(f\"Video appears to be empty (0 frames): {video_path}\")\n",
        "\n",
        "            # Set the capture position to the very last frame (index is total_frames - 1).\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)\n",
        "\n",
        "            # Read the frame at the new position.\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            # Check if the frame was read successfully. 'ret' will be False if it fails.\n",
        "            if not ret or frame is None:\n",
        "                raise VEOVideoGenerationError(f\"Failed to read the last frame from: {video_path}\")\n",
        "\n",
        "            # Log the successful extraction.\n",
        "            logger.info(f\"Successfully extracted last frame from video: {video_path}\")\n",
        "            # Return the frame as a NumPy array.\n",
        "            return frame\n",
        "\n",
        "        except Exception as e:\n",
        "            # Wrap any OpenCV or other errors in our custom exception.\n",
        "            raise VEOVideoGenerationError(f\"Frame extraction failed for '{video_path}': {e}\") from e\n",
        "        finally:\n",
        "            # Crucially, release the video capture object to free up system resources.\n",
        "            cap.release()\n",
        "\n",
        "    def _frame_to_base64(self, frame: NDArray[np.uint8]) -> str:\n",
        "        \"\"\"Converts an OpenCV frame (NumPy array) to a base64 encoded string.\"\"\"\n",
        "        try:\n",
        "            # Convert the frame from OpenCV's default BGR color space to PIL's expected RGB color space.\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Create a PIL Image object from the NumPy array for easier processing.\n",
        "            pil_image = Image.fromarray(frame_rgb)\n",
        "\n",
        "            # Resize the frame to ensure it's compatible with VEO's input requirements, using the same logic.\n",
        "            pil_image = self._resize_image_for_veo(pil_image)\n",
        "\n",
        "            # Use an in-memory buffer to save the image without writing to disk.\n",
        "            buffer = io.BytesIO()\n",
        "            # Save the image to the buffer as a high-quality JPEG.\n",
        "            pil_image.save(buffer, format='JPEG', quality=VEOConfig.JPEG_ENCODING_QUALITY)\n",
        "\n",
        "            # Get the raw byte value and encode it to a utf-8 decoded base64 string.\n",
        "            image_bytes = buffer.getvalue()\n",
        "            base64_encoded = base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "            return base64_encoded\n",
        "\n",
        "        except Exception as e:\n",
        "            # Wrap any conversion errors.\n",
        "            raise VEOVideoGenerationError(f\"Frame to base64 conversion failed: {e}\") from e\n",
        "\n",
        "    def _stitch_videos_ffmpeg(self, video_paths: List[Path], output_path: Path) -> None:\n",
        "        \"\"\"Stitches multiple video files into one using ffmpeg's concat demuxer for efficiency.\"\"\"\n",
        "        # Check if the ffmpeg executable is available in the system's PATH before proceeding.\n",
        "        if not shutil.which(\"ffmpeg\"):\n",
        "            raise FileNotFoundError(\n",
        "                \"ffmpeg not found. Please install ffmpeg and ensure it is in your system's PATH.\"\n",
        "            )\n",
        "\n",
        "        # Ensure there is at least one video to process.\n",
        "        if not video_paths:\n",
        "            raise VEOVideoGenerationError(\"No video clips were provided to stitch.\")\n",
        "\n",
        "        # Create a temporary manifest file for ffmpeg in the same directory as the output.\n",
        "        manifest_path = output_path.with_suffix('.txt')\n",
        "\n",
        "        try:\n",
        "            # Write the list of video files to the manifest in the format required by ffmpeg's concat demuxer.\n",
        "            with open(manifest_path, 'w') as f:\n",
        "                for video_path in video_paths:\n",
        "                    # Verify each video file exists before adding it to the manifest.\n",
        "                    if not video_path.exists():\n",
        "                        raise FileNotFoundError(f\"Video file for stitching not found: {video_path}\")\n",
        "                    # Use resolved absolute paths and quotes to handle spaces or special characters safely.\n",
        "                    f.write(f\"file '{video_path.resolve()}'\\n\")\n",
        "\n",
        "            # Log the creation of the manifest file.\n",
        "            logger.info(f\"Created ffmpeg manifest at: {manifest_path}\")\n",
        "\n",
        "            # Construct the ffmpeg command for efficient, lossless concatenation.\n",
        "            command = [\n",
        "                \"ffmpeg\",\n",
        "                \"-y\",                   # Overwrite output file if it exists.\n",
        "                \"-f\", \"concat\",         # Use the concat demuxer.\n",
        "                \"-safe\", \"0\",           # Allow absolute paths in the manifest file (required for resolved paths).\n",
        "                \"-i\", str(manifest_path), # Specify the input manifest file.\n",
        "                \"-c\", \"copy\",           # Copy codecs without re-encoding for maximum speed and quality preservation.\n",
        "                str(output_path)        # Specify the final output file path.\n",
        "            ]\n",
        "\n",
        "            # Log the command being executed for debugging purposes.\n",
        "            logger.info(f\"Executing ffmpeg command: {' '.join(command)}\")\n",
        "\n",
        "            # Execute the command, capturing stdout and stderr for detailed error reporting.\n",
        "            result = subprocess.run(\n",
        "                command,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                check=False # We check the return code manually for better error logging.\n",
        "            )\n",
        "\n",
        "            # Check if the ffmpeg command executed successfully.\n",
        "            if result.returncode != 0:\n",
        "                # If it failed, raise an error with the detailed stderr from ffmpeg.\n",
        "                raise VEOVideoGenerationError(\n",
        "                    f\"ffmpeg failed with exit code {result.returncode}.\\n\"\n",
        "                    f\"Stderr: {result.stderr}\"\n",
        "                )\n",
        "\n",
        "            # Log the successful completion of the stitching process.\n",
        "            logger.info(f\"Successfully stitched {len(video_paths)} videos into: {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # Wrap any exception in our custom error type.\n",
        "            raise VEOVideoGenerationError(f\"Video stitching failed: {e}\") from e\n",
        "        finally:\n",
        "            # Ensure the temporary manifest file is always cleaned up, even if errors occur.\n",
        "            if manifest_path.exists():\n",
        "                manifest_path.unlink()\n",
        "                logger.info(f\"Cleaned up manifest file: {manifest_path}\")\n",
        "\n",
        "    def generate_sequential_videos(self,\n",
        "        reference_image_path: str,\n",
        "        scene_prompts: List[str],\n",
        "        output_folder_name: str\n",
        "    ) -> Path:\n",
        "        \"\"\"Executes the full pipeline to generate a sequence of chained videos.\"\"\"\n",
        "        try:\n",
        "            # Step 0: Validate all inputs before starting any expensive processing.\n",
        "            self._validate_inputs(reference_image_path, scene_prompts, output_folder_name)\n",
        "\n",
        "            # Step 1: Create the output directory to store all generated artifacts.\n",
        "            output_dir = self._create_output_directory(output_folder_name)\n",
        "\n",
        "            # Step 2: Load and encode the initial reference image to start the sequence.\n",
        "            current_image_data: Optional[str] = self._load_and_encode_image(reference_image_path)\n",
        "\n",
        "            # Initialize a list to store the paths of the generated video segments for later stitching.\n",
        "            video_paths: List[Path] = []\n",
        "\n",
        "            # Step 3: Iterate through each scene prompt to generate a corresponding video segment.\n",
        "            for i, prompt in enumerate(scene_prompts):\n",
        "                logger.info(f\"--- Processing Scene {i+1}/{len(scene_prompts)} ---\")\n",
        "                logger.info(f\"Prompt: '{prompt[:100]}...'\")\n",
        "\n",
        "                # Step 4: Generate a video segment using the current image data and prompt.\n",
        "                prediction = self._generate_video_segment(\n",
        "                    prompt=prompt,\n",
        "                    image_data=current_image_data\n",
        "                )\n",
        "\n",
        "                # Define a unique, ordered filename for this video segment.\n",
        "                video_filename = f\"segment_{i+1:03d}.mp4\"\n",
        "                video_path = output_dir / video_filename\n",
        "\n",
        "                # Step 5: Process the API response, which could contain bytes or a GCS URI.\n",
        "                if 'video_bytes' in prediction:\n",
        "                    # If video bytes are returned directly, decode them from base64 and save to a file.\n",
        "                    logger.info(f\"Received video as base64 bytes. Saving to {video_path}\")\n",
        "                    video_bytes = base64.b64decode(prediction['video_bytes'])\n",
        "                    with open(video_path, 'wb') as f:\n",
        "                        f.write(video_bytes)\n",
        "                elif 'gcs_uri' in prediction:\n",
        "                    # If a GCS URI is returned, download the video from the bucket.\n",
        "                    logger.info(f\"Received GCS URI. Downloading from {prediction['gcs_uri']}\")\n",
        "                    self._download_video_from_gcs(prediction['gcs_uri'], video_path)\n",
        "                else:\n",
        "                    # If neither key is present, the API response is invalid.\n",
        "                    raise VEOVideoGenerationError(f\"API prediction did not contain 'video_bytes' or 'gcs_uri': {prediction}\")\n",
        "\n",
        "                # Add the path of the newly created segment to our list for the final stitching step.\n",
        "                video_paths.append(video_path)\n",
        "\n",
        "                # Step 6: For all but the last prompt, extract the last frame to seed the next segment.\n",
        "                if i < len(scene_prompts) - 1:\n",
        "                    logger.info(\"Extracting last frame to use as reference for the next segment...\")\n",
        "                    last_frame = self._extract_last_frame(video_path)\n",
        "                    current_image_data = self._frame_to_base64(last_frame)\n",
        "\n",
        "            # Step 7: Stitch all generated video segments into a single final video file.\n",
        "            final_video_path = output_dir / \"final_stitched_video.mp4\"\n",
        "            self._stitch_videos_ffmpeg(video_paths, final_video_path)\n",
        "\n",
        "            # Log the successful completion of the entire pipeline.\n",
        "            logger.info(\"--- Sequential video generation pipeline completed successfully. ---\")\n",
        "            logger.info(f\"Final video saved to: {final_video_path}\")\n",
        "\n",
        "            # Return the path to the final product.\n",
        "            return final_video_path\n",
        "\n",
        "        except (VEOVideoGenerationError, ValueError, FileNotFoundError) as e:\n",
        "            # Catch known, specific errors and log them clearly before re-raising.\n",
        "            logger.error(f\"A predictable error occurred in the pipeline: {e}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            # Catch any other unexpected errors for robust failure handling.\n",
        "            logger.error(f\"An unexpected error occurred in the main pipeline: {e}\", exc_info=True)\n",
        "            raise VEOVideoGenerationError(f\"An unexpected error occurred in the main pipeline: {e}\") from e\n",
        "\n",
        "\n",
        "def create_veo_video_pipeline(\n",
        "    reference_image_path: str,\n",
        "    scene_prompts: List[str],\n",
        "    output_folder_name: str,\n",
        "    project_id: Optional[str] = None\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    A high-level factory function to create and run the VEO sequential video pipeline.\n",
        "\n",
        "    This function abstracts away the class instantiation and execution, providing a\n",
        "    simple, clean interface to generate a complete video from an image and prompts.\n",
        "\n",
        "    Args:\n",
        "        reference_image_path (str): Path to the initial reference image file.\n",
        "        scene_prompts (List[str]): An ordered list of scene description prompts.\n",
        "        output_folder_name (str): The name for the output folder in the home directory.\n",
        "        project_id (Optional[str]): Your Google Cloud project ID. If None, it will be\n",
        "                                    auto-detected from ADC or environment variables.\n",
        "\n",
        "    Returns:\n",
        "        Path: The path to the final, stitched video file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # If project_id is not provided, attempt to get it from the environment as a fallback.\n",
        "        if project_id is None:\n",
        "            project_id = os.environ.get('GOOGLE_CLOUD_PROJECT')\n",
        "            if project_id:\n",
        "                logger.info(f\"Using project ID from GOOGLE_CLOUD_PROJECT env var: {project_id}\")\n",
        "\n",
        "        # Initialize the VEO pipeline class with the determined project ID.\n",
        "        pipeline = VEOVideoPipeline(project_id=project_id)\n",
        "\n",
        "        # Execute the complete video generation pipeline with the provided parameters.\n",
        "        final_video_path = pipeline.generate_sequential_videos(\n",
        "            reference_image_path=reference_image_path,\n",
        "            scene_prompts=scene_prompts,\n",
        "            output_folder_name=output_folder_name\n",
        "        )\n",
        "\n",
        "        return final_video_path\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch and log any exceptions from the pipeline for clear top-level error reporting.\n",
        "        logger.error(f\"VEO video pipeline execution failed: {e}\")\n",
        "        # Re-raise the exception to allow the calling script to handle it as needed.\n",
        "        raise\n",
        "\n",
        "\n",
        "# --- Example Usage and Testing Block ---\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    Example usage of the corrected and robust VEO video generation pipeline.\n",
        "\n",
        "    *** IMPORTANT: CONFIGURATION REQUIRED ***\n",
        "    1.  **AUTHENTICATION**: Run `gcloud auth application-default login` in your terminal.\n",
        "    2.  **PROJECT ID**: Set the `GOOGLE_CLOUD_PROJECT` environment variable to your GCP project ID,\n",
        "        or pass the `project_id` argument to `create_veo_video_pipeline`.\n",
        "    3.  **APIs**: Ensure the Vertex AI API is enabled in your Google Cloud project.\n",
        "    4.  **DEPENDENCIES**: Install required packages:\n",
        "        pip install google-cloud-aiplatform google-cloud-storage opencv-python Pillow requests tenacity numpy\n",
        "    5.  **FFMPEG**: Install ffmpeg (https://ffmpeg.org/download.html) and ensure it is in your system's PATH.\n",
        "    6.  **REFERENCE IMAGE**: Replace the dummy image path with a path to your own image.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- CONFIGURE THESE PARAMETERS FOR YOUR RUN ---\n",
        "    try:\n",
        "        # Get the directory of the current script to create a sample image nearby.\n",
        "        script_dir = Path(__file__).parent\n",
        "    except NameError:\n",
        "        # Fallback for interactive environments (like Jupyter) where __file__ is not defined.\n",
        "        script_dir = Path.cwd()\n",
        "\n",
        "    # Create a dummy reference image for testing if one doesn't exist.\n",
        "    dummy_image_path = script_dir / \"veo_reference_image.jpg\"\n",
        "    if not dummy_image_path.exists():\n",
        "        print(f\"Creating a dummy reference image at: {dummy_image_path}\")\n",
        "        # A blue 16:9 image matching VEO's landscape dimensions.\n",
        "        dummy_img = Image.new('RGB', VEOConfig.LANDSCAPE_DIMS, color='darkblue')\n",
        "        dummy_img.save(dummy_image_path)\n",
        "\n",
        "    # Define the parameters for the video generation task.\n",
        "    example_params = {\n",
        "        \"reference_image_path\": str(dummy_image_path),\n",
        "        \"scene_prompts\": [\n",
        "            \"A majestic eagle perched on a rocky cliff overlooking a vast canyon, cinematic lighting.\",\n",
        "            \"The eagle spreads its wings and takes flight into the golden sunset, slow motion.\",\n",
        "            \"Soaring high above snow-capped mountains with clouds below, drone shot.\",\n",
        "            \"The eagle gracefully lands near a crystal clear alpine lake, its reflection in the water.\"\n",
        "        ],\n",
        "        \"output_folder_name\": \"veo_eagle_flight_sequence\",\n",
        "        # \"project_id\": \"your-gcp-project-id\"  # Optional: uncomment and set if needed.\n",
        "    }\n",
        "\n",
        "    print(\"--- Starting VEO Video Generation Pipeline ---\")\n",
        "    print(f\"Reference Image: {example_params['reference_image_path']}\")\n",
        "    print(f\"Output Folder Name: {example_params['output_folder_name']}\")\n",
        "    print(f\"Number of Scenes: {len(example_params['scene_prompts'])}\")\n",
        "\n",
        "    try:\n",
        "        # Execute the pipeline and time its execution.\n",
        "        start_time = time.time()\n",
        "        final_video = create_veo_video_pipeline(**example_params)\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Print a clear success message with the final output path and total time.\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"✅ Video generation pipeline completed successfully!\")\n",
        "        print(f\"📹 Final video saved to: {final_video}\")\n",
        "        print(f\"⏱️ Total execution time: {end_time - start_time:.2f} seconds.\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    except (VEOVideoGenerationError, ValueError, FileNotFoundError) as e:\n",
        "        # Handle known, controlled pipeline failures gracefully with a clear error message.\n",
        "        print(f\"\\n❌ PIPELINE FAILED: {e}\")\n",
        "        sys.exit(1)\n",
        "    except Exception as e:\n",
        "        # Handle any other unexpected errors to prevent unhandled stack traces.\n",
        "        print(f\"\\n❌ AN UNEXPECTED ERROR OCCURRED: {e}\")\n",
        "        sys.exit(1)\n"
      ],
      "metadata": {
        "id": "4wv4z6GZJUeZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}