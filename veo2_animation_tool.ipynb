{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKRwvnR8xOzw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# README\n",
        "# VEO Sequential Video Generation Pipeline\n",
        "\n",
        "A professional, production-ready Python implementation for generating sequential videos using Google's VEO-2 (Video Generation) model via Vertex AI. This pipeline enables the creation of coherent, multi-scene video sequences by chaining together individual video segments, using the last frame of each segment as the reference image for the next.\n",
        "\n",
        "## üéØ Overview\n",
        "\n",
        "The VEO Sequential Video Generation Pipeline orchestrates the complete workflow of creating cinematic video sequences from a single reference image and a series of scene prompts. Each generated video segment seamlessly transitions into the next, creating a cohesive narrative flow ideal for storytelling, product demonstrations, or creative content generation.\n",
        "\n",
        "### Key Features\n",
        "\n",
        "- **Sequential Video Chaining**: Automatically extracts the last frame from each segment to seed the next generation\n",
        "- **Robust Error Handling**: Comprehensive exception handling with custom error types and detailed logging\n",
        "- **Production-Grade Authentication**: Seamless integration with Google Cloud Authentication (ADC)\n",
        "- **Efficient Video Processing**: Memory-optimized frame extraction and FFmpeg-based video stitching\n",
        "- **Configurable Parameters**: Centralized configuration with sensible defaults for video dimensions, quality, and API settings\n",
        "- **Comprehensive Retry Logic**: Exponential backoff retry strategy for transient API failures\n",
        "- **Cross-Platform Compatibility**: Works on Windows, macOS, and Linux environments\n",
        "\n",
        "## üèóÔ∏è Architecture\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Reference      ‚îÇ    ‚îÇ  VEO API         ‚îÇ    ‚îÇ  Video          ‚îÇ\n",
        "‚îÇ  Image          ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Generation      ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Segments       ‚îÇ\n",
        "‚îÇ                 ‚îÇ    ‚îÇ                  ‚îÇ    ‚îÇ                 ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                                ‚îÇ                        ‚îÇ\n",
        "                                ‚ñº                        ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Frame          ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ  Last Frame      ‚îÇ    ‚îÇ  FFmpeg         ‚îÇ\n",
        "‚îÇ  Extraction     ‚îÇ    ‚îÇ  Extraction      ‚îÇ    ‚îÇ  Stitching      ‚îÇ\n",
        "‚îÇ                 ‚îÇ    ‚îÇ                  ‚îÇ    ‚îÇ                 ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "## üìã Prerequisites\n",
        "\n",
        "### System Requirements\n",
        "\n",
        "- Python 3.8 or higher\n",
        "- FFmpeg installed and available in system PATH\n",
        "- Google Cloud Project with Vertex AI API enabled\n",
        "- Sufficient disk space for video processing (minimum 1GB recommended)\n",
        "\n",
        "### Authentication Setup\n",
        "\n",
        "1. **Install Google Cloud CLI**:\n",
        "   ```bash\n",
        "   # macOS\n",
        "   brew install google-cloud-sdk\n",
        "   \n",
        "   # Ubuntu/Debian\n",
        "   sudo apt-get update && sudo apt-get install google-cloud-cli\n",
        "   \n",
        "   # Windows: Download from https://cloud.google.com/sdk/docs/install\n",
        "   ```\n",
        "\n",
        "2. **Authenticate with Google Cloud**:\n",
        "   ```bash\n",
        "   gcloud auth application-default login\n",
        "   gcloud config set project YOUR_PROJECT_ID\n",
        "   ```\n",
        "\n",
        "3. **Enable Required APIs**:\n",
        "   ```bash\n",
        "   gcloud services enable aiplatform.googleapis.com\n",
        "   gcloud services enable storage.googleapis.com\n",
        "   ```\n",
        "\n",
        "## üöÄ Installation\n",
        "\n",
        "### Option 1: Direct Installation\n",
        "\n",
        "```bash\n",
        "# Clone the repository\n",
        "git clone https://github.com/chirindaopensource/veo-video-pipeline.git\n",
        "cd veo-video-pipeline\n",
        "\n",
        "# Install dependencies\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "### Option 2: Virtual Environment (Recommended)\n",
        "\n",
        "```bash\n",
        "# Create and activate virtual environment\n",
        "python -m venv veo-pipeline-env\n",
        "\n",
        "# Activate environment\n",
        "# On Windows:\n",
        "veo-pipeline-env\\Scripts\\activate\n",
        "# On macOS/Linux:\n",
        "source veo-pipeline-env/bin/activate\n",
        "\n",
        "# Install dependencies\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "### Dependencies\n",
        "\n",
        "```text\n",
        "google-cloud-aiplatform>=1.34.0\n",
        "google-cloud-storage>=2.10.0\n",
        "opencv-python>=4.8.0\n",
        "Pillow>=10.0.0\n",
        "requests>=2.31.0\n",
        "tenacity>=8.2.0\n",
        "numpy>=1.24.0\n",
        "```\n",
        "\n",
        "## üìñ Usage\n",
        "\n",
        "### Basic Usage\n",
        "\n",
        "```python\n",
        "from veo_pipeline import create_veo_video_pipeline\n",
        "\n",
        "# Generate sequential video\n",
        "final_video_path = create_veo_video_pipeline(\n",
        "    reference_image_path=\"path/to/your/reference_image.jpg\",\n",
        "    scene_prompts=[\n",
        "        \"A serene lake at sunrise with mist rising from the water\",\n",
        "        \"A family of ducks swimming peacefully across the lake\",\n",
        "        \"The camera pans to reveal mountains in the background\",\n",
        "        \"Golden sunlight breaks through the clouds, illuminating the scene\"\n",
        "    ],\n",
        "    output_folder_name=\"lake_sunrise_sequence\",\n",
        "    project_id=\"your-gcp-project-id\"  # Optional if set in environment\n",
        ")\n",
        "\n",
        "print(f\"Video generated successfully: {final_video_path}\")\n",
        "```\n",
        "\n",
        "### Advanced Usage with Custom Pipeline\n",
        "\n",
        "```python\n",
        "from veo_pipeline import VEOVideoPipeline, VEOConfig\n",
        "from pathlib import Path\n",
        "\n",
        "# Initialize pipeline with custom configuration\n",
        "pipeline = VEOVideoPipeline(\n",
        "    project_id=\"your-project-id\",\n",
        "    location=\"us-central1\"\n",
        ")\n",
        "\n",
        "# Generate with custom parameters\n",
        "output_path = pipeline.generate_sequential_videos(\n",
        "    reference_image_path=\"reference.jpg\",\n",
        "    scene_prompts=[\n",
        "        \"Professional product showcase with dramatic lighting\",\n",
        "        \"Smooth 360-degree rotation revealing product details\",\n",
        "        \"Close-up shots highlighting key features\",\n",
        "        \"Final hero shot with brand elements\"\n",
        "    ],\n",
        "    output_folder_name=\"product_demo_2024\"\n",
        ")\n",
        "```\n",
        "\n",
        "### Environment Configuration\n",
        "\n",
        "Set environment variables for seamless operation:\n",
        "\n",
        "```bash\n",
        "export GOOGLE_CLOUD_PROJECT=\"your-project-id\"\n",
        "export GOOGLE_APPLICATION_CREDENTIALS=\"path/to/service-account.json\"  # Optional\n",
        "export VEO_DEFAULT_LOCATION=\"us-central1\"  # Optional\n",
        "```\n",
        "\n",
        "## ‚öôÔ∏è Configuration\n",
        "\n",
        "### VEOConfig Class\n",
        "\n",
        "The pipeline uses a centralized configuration class for easy customization:\n",
        "\n",
        "```python\n",
        "class VEOConfig:\n",
        "    # API Configuration\n",
        "    MODEL_ID = \"video-generation-001\"\n",
        "    API_TIMEOUT_SECONDS = 900\n",
        "    \n",
        "    # Video Parameters\n",
        "    DEFAULT_VIDEO_LENGTH = \"4s\"\n",
        "    DEFAULT_FPS = 24\n",
        "    LANDSCAPE_DIMS = (1024, 576)\n",
        "    PORTRAIT_DIMS = (576, 1024)\n",
        "    \n",
        "    # Quality Settings\n",
        "    JPEG_ENCODING_QUALITY = 95\n",
        "    \n",
        "    # Retry Configuration\n",
        "    RETRYABLE_STATUS_CODES = {429, 500, 502, 503, 504}\n",
        "```\n",
        "\n",
        "### Custom Configuration\n",
        "\n",
        "```python\n",
        "# Override default settings\n",
        "VEOConfig.DEFAULT_VIDEO_LENGTH = \"8s\"\n",
        "VEOConfig.DEFAULT_FPS = 30\n",
        "VEOConfig.API_TIMEOUT_SECONDS = 1800\n",
        "```\n",
        "\n",
        "## üß™ Testing\n",
        "\n",
        "### Run Example Pipeline\n",
        "\n",
        "```bash\n",
        "python veo_pipeline.py\n",
        "```\n",
        "\n",
        "This will create a test video sequence using a generated reference image and sample prompts.\n",
        "\n",
        "### Unit Tests\n",
        "\n",
        "```bash\n",
        "python -m pytest tests/\n",
        "```\n",
        "\n",
        "### Integration Tests\n",
        "\n",
        "```bash\n",
        "python -m pytest tests/integration/ --slow\n",
        "```\n",
        "\n",
        "## üîß Troubleshooting\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "1. **Authentication Errors**\n",
        "   ```\n",
        "   DefaultCredentialsError: Could not automatically determine credentials\n",
        "   ```\n",
        "   **Solution**: Run `gcloud auth application-default login`\n",
        "\n",
        "2. **FFmpeg Not Found**\n",
        "   ```\n",
        "   FileNotFoundError: ffmpeg not found\n",
        "   ```\n",
        "   **Solution**: Install FFmpeg and add to PATH\n",
        "   - macOS: `brew install ffmpeg`\n",
        "   - Ubuntu: `sudo apt update && sudo apt install ffmpeg`\n",
        "   - Windows: Download from https://ffmpeg.org/\n",
        "\n",
        "3. **API Quota Exceeded**\n",
        "   ```\n",
        "   HTTPError: 429 Too Many Requests\n",
        "   ```\n",
        "   **Solution**: The pipeline automatically retries with exponential backoff. Check your API quotas in the Google Cloud Console.\n",
        "\n",
        "4. **Video Generation Timeout**\n",
        "   ```\n",
        "   VEOVideoGenerationError: Video generation failed\n",
        "   ```\n",
        "   **Solution**: Increase `API_TIMEOUT_SECONDS` in VEOConfig or simplify prompts.\n",
        "\n",
        "### Debug Mode\n",
        "\n",
        "Enable detailed logging:\n",
        "\n",
        "```python\n",
        "import logging\n",
        "logging.getLogger().setLevel(logging.DEBUG)\n",
        "```\n",
        "\n",
        "## üìä Performance Considerations\n",
        "\n",
        "### Resource Usage\n",
        "\n",
        "- **Memory**: ~2-4GB RAM during processing\n",
        "- **Storage**: ~100-500MB per video segment\n",
        "- **Network**: ~10-50MB per API request\n",
        "- **Processing Time**: 2-5 minutes per segment\n",
        "\n",
        "### Optimization Tips\n",
        "\n",
        "1. **Batch Processing**: Process multiple sequences in parallel\n",
        "2. **Image Preprocessing**: Resize images to optimal dimensions beforehand\n",
        "3. **Prompt Engineering**: Use clear, specific prompts for better results\n",
        "4. **Caching**: Implement local caching for frequently used reference images\n",
        "\n",
        "## ü§ù Contributing\n",
        "\n",
        "We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.\n",
        "\n",
        "### Development Setup\n",
        "\n",
        "```bash\n",
        "# Clone repository\n",
        "git clone https://github.com/chirindaopensource/veo-video-pipeline.git\n",
        "cd veo-video-pipeline\n",
        "\n",
        "# Install development dependencies\n",
        "pip install -r requirements-dev.txt\n",
        "\n",
        "# Install pre-commit hooks\n",
        "pre-commit install\n",
        "\n",
        "# Run tests\n",
        "python -m pytest\n",
        "```\n",
        "\n",
        "### Code Style\n",
        "\n",
        "This project follows PEP 8 standards with the following tools:\n",
        "- **Black**: Code formatting\n",
        "- **isort**: Import sorting\n",
        "- **flake8**: Linting\n",
        "- **mypy**: Type checking\n",
        "\n",
        "## üìÑ License\n",
        "\n",
        "This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
        "\n",
        "## üÜò Support\n",
        "\n",
        "- **Documentation**: [Full API Documentation](docs/)\n",
        "- **Issues**: [GitHub Issues](https://github.com/chirindaopensource/veo-video-pipeline/issues)\n",
        "- **Discussions**: [GitHub Discussions](https://github.com/chirindaopensource/veo-video-pipeline/discussions)\n",
        "- **Email**: N/A\n",
        "\n",
        "## üôè Acknowledgments\n",
        "\n",
        "- Google Cloud Vertex AI team for the VEO model\n",
        "- OpenCV community for computer vision tools\n",
        "- FFmpeg project for video processing capabilities\n",
        "- The Python packaging community for excellent tooling\n",
        "\n",
        "## üìö Related Projects\n",
        "\n",
        "- [Google Cloud Vertex AI Python SDK](https://github.com/googleapis/python-aiplatform)\n",
        "- [OpenCV Python](https://github.com/opencv/opencv-python)\n",
        "- [Pillow (PIL Fork)](https://github.com/python-pillow/Pillow)\n",
        "\n",
        "--\n",
        "\n",
        "**Built with ‚ù§Ô∏è by CS Chirinda**\n",
        "\n",
        "*For questions or support, please open an issue*"
      ],
      "metadata": {
        "id": "4A2twyw9znZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "tI1MrwOq34ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard Library Imports\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import base64\n",
        "import logging\n",
        "import shutil\n",
        "import subprocess\n",
        "import io\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "\n",
        "# Third-party Imports, Grouped for Clarity\n",
        "import cv2\n",
        "import numpy as np\n",
        "from numpy.typing import NDArray\n",
        "from PIL import Image\n",
        "import requests\n",
        "from google.auth import default, exceptions as auth_exceptions\n",
        "from google.auth.transport.requests import Request\n",
        "from google.cloud import storage\n",
        "from google.api_core import exceptions as api_core_exceptions\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n"
      ],
      "metadata": {
        "id": "TRvBcTlq38Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "xh4-t2Kq4RFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logging Configuration\n",
        "# Configure a logger for clear, standardized output for debugging and monitoring.\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "# Instantiate the logger using the standard __name__ convention.\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# Centralized Configuration Class\n",
        "class VEOConfig:\n",
        "    \"\"\"\n",
        "    A centralized, immutable configuration class for VEO API constants.\n",
        "\n",
        "    This provides a single source of truth for static parameters, improving\n",
        "    maintainability and preventing the use of \"magic\" strings or numbers\n",
        "    in the pipeline logic.\n",
        "    \"\"\"\n",
        "    # The required OAuth scope for authenticating with the Vertex AI API.\n",
        "    AUTH_SCOPE: List[str] = [\"https://www.googleapis.com/auth/cloud-platform\"]\n",
        "    # The official, versioned model identifier for Google's VEO model.\n",
        "    MODEL_ID: str = \"video-generation-001\"\n",
        "    # The standard Vertex AI API method for synchronous (blocking) predictions.\n",
        "    API_METHOD: str = \"predict\"\n",
        "    # A generous timeout for the synchronous API call to allow for video generation.\n",
        "    API_TIMEOUT_SECONDS: int = 900\n",
        "    # The set of HTTP status codes that indicate transient server-side issues safe to retry.\n",
        "    RETRYABLE_STATUS_CODES: set[int] = {429, 500, 502, 503, 504}\n",
        "    # Recommended VEO dimensions for landscape videos (width, height).\n",
        "    LANDSCAPE_DIMS: Tuple[int, int] = (1024, 576)\n",
        "    # Recommended VEO dimensions for portrait videos (width, height).\n",
        "    PORTRAIT_DIMS: Tuple[int, int] = (576, 1024)\n",
        "    # Default video generation parameters.\n",
        "    DEFAULT_VIDEO_LENGTH: str = \"4s\"\n",
        "    DEFAULT_FPS: int = 24\n",
        "    # JPEG quality for encoding reference frames. 95 is a high-quality setting.\n",
        "    JPEG_ENCODING_QUALITY: int = 95\n",
        "\n",
        "\n",
        "# --- Custom Exception for Pipeline-Specific Errors ---\n",
        "class VEOVideoGenerationError(Exception):\n",
        "    \"\"\"Custom exception for specific, identifiable errors within the VEO video generation pipeline.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "# --- Robust Retry Logic for API Calls ---\n",
        "def _is_retryable_http_error(exception: BaseException) -> bool:\n",
        "    \"\"\"\n",
        "    Custom tenacity retry condition to check for specific HTTP status codes.\n",
        "\n",
        "    This function determines if a caught exception is a requests.HTTPError with a\n",
        "    status code that is defined as retryable in VEOConfig.\n",
        "\n",
        "    Args:\n",
        "        exception (BaseException): The exception caught by tenacity.\n",
        "\n",
        "    Returns:\n",
        "        bool: True if the exception is an HTTPError with a retryable status code, False otherwise.\n",
        "    \"\"\"\n",
        "    # Return True only if the exception is an HTTPError and its status code is in our retryable set.\n",
        "    return (\n",
        "        isinstance(exception, requests.exceptions.HTTPError) and\n",
        "        hasattr(exception, 'response') and\n",
        "        exception.response.status_code in VEOConfig.RETRYABLE_STATUS_CODES\n",
        "    )\n",
        "\n",
        "# Define a reusable, robust retry strategy for API calls using the tenacity library.\n",
        "retry_on_api_error = retry(\n",
        "    # Use exponential backoff, starting at 4s and maxing out at 60s between retries.\n",
        "    wait=wait_exponential(multiplier=1, min=4, max=60),\n",
        "    # Stop retrying after 10 attempts to prevent indefinite loops and fail gracefully.\n",
        "    stop=stop_after_attempt(10),\n",
        "    # Define the conditions for retrying: network errors or specific HTTP server errors.\n",
        "    retry=retry_if_exception_type((\n",
        "        requests.exceptions.ConnectionError,\n",
        "        requests.exceptions.Timeout,\n",
        "    )) | _is_retryable_http_error,\n",
        "    # Log a warning before each retry attempt for visibility into transient failures.\n",
        "    before_sleep=lambda retry_state: logger.warning(\n",
        "        f\"Retrying API call due to {retry_state.outcome.exception()}. \"\n",
        "        f\"Attempt #{retry_state.attempt_number}, waiting {retry_state.next_action.sleep:.2f}s...\"\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "lQ2mmj-U4VtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation\n"
      ],
      "metadata": {
        "id": "wb0sE-2u4tu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Class\n",
        "\n",
        "class VEOVideoPipeline:\n",
        "    \"\"\"\n",
        "    A professional, implementation-grade class for Google's VEO video generation.\n",
        "\n",
        "    This class orchestrates the complete workflow of generating sequential videos using\n",
        "    Google's VEO model via its synchronous API. It handles authentication, request\n",
        "    building, response parsing, frame extraction, and memory-efficient video stitching.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, project_id: Optional[str] = None, location: str = \"us-central1\"):\n",
        "        \"\"\"\n",
        "        Initializes the VEO video generation pipeline.\n",
        "\n",
        "        Args:\n",
        "            project_id (Optional[str]): Your Google Cloud project ID. If None, it will be\n",
        "                                        auto-detected from the environment.\n",
        "            location (str): The Google Cloud region for Vertex AI. Defaults to us-central1.\n",
        "\n",
        "        Raises:\n",
        "            VEOVideoGenerationError: If initialization or authentication fails.\n",
        "            ValueError: If input parameters are invalid.\n",
        "        \"\"\"\n",
        "        # Validate that the location parameter is a non-empty string.\n",
        "        if not isinstance(location, str) or not location:\n",
        "            raise ValueError(\"location must be a non-empty string\")\n",
        "\n",
        "        # Store the project ID and location as instance-specific attributes.\n",
        "        self.project_id: Optional[str] = project_id\n",
        "        self.location: str = location\n",
        "        # Construct the base API endpoint URL for Vertex AI.\n",
        "        self.api_endpoint: str = f\"https://{location}-aiplatform.googleapis.com\"\n",
        "\n",
        "        # Perform authentication immediately upon initialization to fail fast.\n",
        "        self._initialize_authentication()\n",
        "\n",
        "        # After attempting auto-detection, confirm that a project_id is set.\n",
        "        if not self.project_id:\n",
        "            raise VEOVideoGenerationError(\n",
        "                \"Google Cloud project_id could not be determined. \"\n",
        "                \"Please provide it explicitly or configure the environment.\"\n",
        "            )\n",
        "\n",
        "        # Log successful initialization for monitoring purposes.\n",
        "        logger.info(f\"VEOVideoPipeline initialized for project: {self.project_id}\")\n",
        "\n",
        "    def _initialize_authentication(self) -> None:\n",
        "        \"\"\"\n",
        "        Initializes Google Cloud authentication using Application Default Credentials (ADC).\n",
        "\n",
        "        This method explicitly requests the necessary scope for Vertex AI, ensuring\n",
        "        the credentials obtained are valid for making API calls.\n",
        "\n",
        "        Raises:\n",
        "            VEOVideoGenerationError: If authentication fails for any reason.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Use google.auth.default to find credentials, requesting the correct scope from VEOConfig.\n",
        "            self.credentials, detected_project_id = default(scopes=VEOConfig.AUTH_SCOPE)\n",
        "\n",
        "            # If the project_id was not provided during initialization, use the one detected by ADC.\n",
        "            if self.project_id is None:\n",
        "                self.project_id = detected_project_id\n",
        "\n",
        "        except auth_exceptions.DefaultCredentialsError as e:\n",
        "            # Provide a user-friendly error if credentials are not found in the environment.\n",
        "            raise VEOVideoGenerationError(\n",
        "                \"Failed to find default credentials. Please run \"\n",
        "                \"'gcloud auth application-default login' or configure the environment.\"\n",
        "            ) from e\n",
        "        except Exception as e:\n",
        "            # Catch any other unexpected authentication errors and wrap them in our custom exception.\n",
        "            raise VEOVideoGenerationError(f\"An unexpected error occurred during authentication: {e}\") from e\n",
        "\n",
        "    def _validate_inputs(\n",
        "        self,\n",
        "        reference_image_path: str,\n",
        "        scene_prompts: List[str],\n",
        "        output_folder_name: str\n",
        "    ) -> None:\n",
        "        \"\"\"Validates all user-provided inputs for the video generation pipeline.\"\"\"\n",
        "        # Validate the path to the reference image is a non-empty string.\n",
        "        if not isinstance(reference_image_path, str) or not reference_image_path:\n",
        "            raise ValueError(\"reference_image_path must be a non-empty string.\")\n",
        "        # Validate the reference image file actually exists.\n",
        "        if not os.path.exists(reference_image_path):\n",
        "            raise FileNotFoundError(f\"Reference image file not found: {reference_image_path}\")\n",
        "\n",
        "        # Validate that scene_prompts is a non-empty list.\n",
        "        if not isinstance(scene_prompts, list) or not scene_prompts:\n",
        "            raise ValueError(\"scene_prompts must be a non-empty list of strings.\")\n",
        "        # Validate that every item in the list is a non-empty, non-whitespace string.\n",
        "        if not all(isinstance(prompt, str) and prompt.strip() for prompt in scene_prompts):\n",
        "            raise ValueError(\"All items in scene_prompts must be non-empty strings.\")\n",
        "\n",
        "        # Validate the name for the output folder is a non-empty string.\n",
        "        if not isinstance(output_folder_name, str) or not output_folder_name:\n",
        "            raise ValueError(\"output_folder_name must be a non-empty string.\")\n",
        "\n",
        "    def _create_output_directory(self, folder_name: str) -> Path:\n",
        "        \"\"\"Creates a subdirectory in the user's home directory for storing outputs.\"\"\"\n",
        "        try:\n",
        "            # Use Path.home() for robust, cross-platform path resolution to the user's home directory.\n",
        "            home_dir = Path.home()\n",
        "            # Define the full path for the output directory.\n",
        "            output_dir = home_dir / folder_name\n",
        "            # Create the directory, including parent directories if needed, and set standard permissions.\n",
        "            output_dir.mkdir(mode=0o755, parents=True, exist_ok=True)\n",
        "            # Log the successful creation or confirmation of the directory.\n",
        "            logger.info(f\"Output directory ensured at: {output_dir}\")\n",
        "            return output_dir\n",
        "        except OSError as e:\n",
        "            # Raise a custom error if directory creation fails due to OS-level issues.\n",
        "            raise VEOVideoGenerationError(f\"Failed to create output directory '{folder_name}': {e}\") from e\n",
        "\n",
        "    def _load_and_encode_image(self, image_path: str) -> str:\n",
        "        \"\"\"Loads an image, resizes it for VEO, and encodes it to a base64 string.\"\"\"\n",
        "        try:\n",
        "            # Open the image file using a context manager to ensure it's properly closed.\n",
        "            with Image.open(image_path) as img:\n",
        "                # Convert the image to RGB to remove any alpha channel (e.g., from PNGs), ensuring compatibility.\n",
        "                if img.mode != 'RGB':\n",
        "                    img = img.convert('RGB')\n",
        "\n",
        "                # Resize the image to VEO's recommended dimensions while preserving aspect ratio.\n",
        "                img = self._resize_image_for_veo(img)\n",
        "\n",
        "                # Use an in-memory buffer to avoid writing a temporary file to disk, which is more efficient.\n",
        "                buffer = io.BytesIO()\n",
        "\n",
        "                # Save the processed image to the buffer in JPEG format for efficiency and smaller payload size.\n",
        "                img.save(buffer, format='JPEG', quality=VEOConfig.JPEG_ENCODING_QUALITY)\n",
        "\n",
        "                # Get the raw byte value from the buffer.\n",
        "                image_bytes = buffer.getvalue()\n",
        "\n",
        "                # Encode the image bytes to a base64 string and decode to utf-8 for JSON serialization.\n",
        "                base64_encoded = base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "                # Log the successful operation.\n",
        "                logger.info(f\"Successfully loaded and encoded image: {image_path}\")\n",
        "                return base64_encoded\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            # Raise a specific error if the file does not exist.\n",
        "            raise VEOVideoGenerationError(f\"Image file not found at path: {image_path}\")\n",
        "        except Exception as e:\n",
        "            # Wrap any other image processing errors in our custom exception.\n",
        "            raise VEOVideoGenerationError(f\"Failed to load and encode image '{image_path}': {e}\") from e\n",
        "\n",
        "    def _resize_image_for_veo(self, img: Image.Image) -> Image.Image:\n",
        "        \"\"\"Resizes a PIL Image to VEO recommended dimensions, preserving aspect ratio.\"\"\"\n",
        "        # Get the current width and height of the image.\n",
        "        width, height = img.size\n",
        "        # Calculate the aspect ratio to determine if the image is landscape, portrait, or square.\n",
        "        aspect_ratio = width / height\n",
        "\n",
        "        # Set target dimensions from VEOConfig based on whether the image is landscape (or square) or portrait.\n",
        "        target_dims = VEOConfig.LANDSCAPE_DIMS if aspect_ratio >= 1 else VEOConfig.PORTRAIT_DIMS\n",
        "\n",
        "        # Resize the image using Lanczos resampling, which provides high-quality downscaling results.\n",
        "        resized_img = img.resize(target_dims, Image.Resampling.LANCZOS)\n",
        "\n",
        "        return resized_img\n",
        "\n",
        "    def _build_request_body(self, prompt: str, image_data: Optional[str]) -> Dict[str, Any]:\n",
        "        \"\"\"Constructs the request body according to the official VEO API specification.\"\"\"\n",
        "        # Define the instance payload, which contains the core prompt.\n",
        "        instance_payload = {\"prompt\": prompt}\n",
        "\n",
        "        # If reference image data is provided (for the first or subsequent segments), add it to the payload.\n",
        "        if image_data:\n",
        "            instance_payload[\"reference_image\"] = {\"image_bytes\": image_data}\n",
        "\n",
        "        # Construct the full request body with instances and parameters from VEOConfig.\n",
        "        request_body = {\n",
        "            \"instances\": [instance_payload],\n",
        "            \"parameters\": {\n",
        "                \"video_length\": VEOConfig.DEFAULT_VIDEO_LENGTH,\n",
        "                \"fps\": VEOConfig.DEFAULT_FPS,\n",
        "                \"seed\": np.random.randint(0, 2**32 - 1) # Use a random seed for creative variety.\n",
        "            }\n",
        "        }\n",
        "        return request_body\n",
        "\n",
        "    @retry_on_api_error\n",
        "    def _generate_video_segment(self, prompt: str, image_data: Optional[str]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Generates a single video segment using the synchronous VEO API with robust retries.\n",
        "\n",
        "        Args:\n",
        "            prompt (str): The text prompt for the video segment.\n",
        "            image_data (Optional[str]): Base64 encoded image data for initialization.\n",
        "\n",
        "        Returns:\n",
        "            Dict[str, Any]: The prediction dictionary from the API response.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Refresh credentials before the API call to ensure the auth token is not expired.\n",
        "            self.credentials.refresh(Request())\n",
        "\n",
        "            # Construct the full API endpoint URL using constants from VEOConfig for accuracy.\n",
        "            url = (f\"{self.api_endpoint}/v1/projects/{self.project_id}/locations/{self.location}\"\n",
        "                   f\"/publishers/google/models/{VEOConfig.MODEL_ID}:{VEOConfig.API_METHOD}\")\n",
        "\n",
        "            # Prepare the authorization and content-type headers for the request.\n",
        "            headers = {\n",
        "                'Authorization': f'Bearer {self.credentials.token}',\n",
        "                'Content-Type': 'application/json; charset=utf-8'\n",
        "            }\n",
        "\n",
        "            # Construct the request body using the dedicated helper method.\n",
        "            request_body = self._build_request_body(prompt, image_data)\n",
        "\n",
        "            # Log the request initiation. This is a long-running operation.\n",
        "            logger.info(\"Sending request to VEO API. This may take several minutes...\")\n",
        "            # Send the POST request to the VEO API with a configured timeout.\n",
        "            response = requests.post(url, headers=headers, json=request_body, timeout=VEOConfig.API_TIMEOUT_SECONDS)\n",
        "            # Raise an exception for HTTP error codes (4xx or 5xx), which tenacity will catch for retries.\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Parse the JSON response from the API.\n",
        "            response_data = response.json()\n",
        "\n",
        "            # Extract the list of predictions from the response body.\n",
        "            predictions = response_data.get(\"predictions\")\n",
        "            # Validate that the predictions list exists and is not empty.\n",
        "            if not predictions or not isinstance(predictions, list):\n",
        "                raise VEOVideoGenerationError(f\"API response is missing 'predictions'. Response: {response_data}\")\n",
        "\n",
        "            # Log the successful receipt of the response.\n",
        "            logger.info(\"Successfully received response from VEO API.\")\n",
        "            # Return the first prediction object, as we send one instance at a time.\n",
        "            return predictions[0]\n",
        "\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            # Log the detailed error from the API response body if available for easier debugging.\n",
        "            logger.error(f\"HTTP Error during video generation request: {e.response.text}\")\n",
        "            raise  # Re-raise the exception to be handled by the tenacity retry decorator or the caller.\n",
        "        except Exception as e:\n",
        "            # Wrap any other exceptions in our custom error type for consistent error handling.\n",
        "            raise VEOVideoGenerationError(f\"Video generation failed: {e}\") from e\n",
        "\n",
        "    def _download_video_from_gcs(self, gcs_uri: str, local_path: Path) -> None:\n",
        "        \"\"\"Downloads a video from a Google Cloud Storage URI to a local path.\"\"\"\n",
        "        try:\n",
        "            # Validate that the GCS URI has the correct 'gs://' prefix.\n",
        "            if not gcs_uri.startswith('gs://'):\n",
        "                raise ValueError(f\"Invalid GCS URI format: {gcs_uri}\")\n",
        "\n",
        "            # Parse the bucket name and blob (object) name from the URI string.\n",
        "            bucket_name, blob_name = gcs_uri[5:].split('/', 1)\n",
        "\n",
        "            # Initialize the Google Cloud Storage client with the correct project and credentials.\n",
        "            storage_client = storage.Client(project=self.project_id, credentials=self.credentials)\n",
        "\n",
        "            # Get a reference to the bucket and blob objects.\n",
        "            bucket = storage_client.bucket(bucket_name)\n",
        "            blob = bucket.blob(blob_name)\n",
        "\n",
        "            # Download the blob's contents to the specified local file path.\n",
        "            blob.download_to_filename(str(local_path))\n",
        "\n",
        "            # Log the successful download.\n",
        "            logger.info(f\"Successfully downloaded video from {gcs_uri} to {local_path}\")\n",
        "\n",
        "        except (api_core_exceptions.NotFound, FileNotFoundError):\n",
        "            # Handle cases where the GCS object does not exist.\n",
        "            raise VEOVideoGenerationError(f\"GCS object not found at URI: {gcs_uri}\")\n",
        "        except Exception as e:\n",
        "            # Wrap any other GCS-related errors.\n",
        "            raise VEOVideoGenerationError(f\"Failed to download video from GCS: {e}\") from e\n",
        "\n",
        "    def _extract_last_frame(self, video_path: Path) -> NDArray[np.uint8]:\n",
        "        \"\"\"Extracts the last frame from a video file using OpenCV.\"\"\"\n",
        "        # Initialize a video capture object with the path to the video file.\n",
        "        cap = cv2.VideoCapture(str(video_path))\n",
        "        # Check if the video file was opened successfully.\n",
        "        if not cap.isOpened():\n",
        "            raise VEOVideoGenerationError(f\"Cannot open video file for frame extraction: {video_path}\")\n",
        "\n",
        "        try:\n",
        "            # Get the total number of frames in the video.\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            # Ensure the video is not empty.\n",
        "            if total_frames == 0:\n",
        "                raise VEOVideoGenerationError(f\"Video appears to be empty (0 frames): {video_path}\")\n",
        "\n",
        "            # Set the capture position to the very last frame (index is total_frames - 1).\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)\n",
        "\n",
        "            # Read the frame at the new position.\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            # Check if the frame was read successfully. 'ret' will be False if it fails.\n",
        "            if not ret or frame is None:\n",
        "                raise VEOVideoGenerationError(f\"Failed to read the last frame from: {video_path}\")\n",
        "\n",
        "            # Log the successful extraction.\n",
        "            logger.info(f\"Successfully extracted last frame from video: {video_path}\")\n",
        "            # Return the frame as a NumPy array.\n",
        "            return frame\n",
        "\n",
        "        except Exception as e:\n",
        "            # Wrap any OpenCV or other errors in our custom exception.\n",
        "            raise VEOVideoGenerationError(f\"Frame extraction failed for '{video_path}': {e}\") from e\n",
        "        finally:\n",
        "            # Crucially, release the video capture object to free up system resources.\n",
        "            cap.release()\n",
        "\n",
        "    def _frame_to_base64(self, frame: NDArray[np.uint8]) -> str:\n",
        "        \"\"\"Converts an OpenCV frame (NumPy array) to a base64 encoded string.\"\"\"\n",
        "        try:\n",
        "            # Convert the frame from OpenCV's default BGR color space to PIL's expected RGB color space.\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Create a PIL Image object from the NumPy array for easier processing.\n",
        "            pil_image = Image.fromarray(frame_rgb)\n",
        "\n",
        "            # Resize the frame to ensure it's compatible with VEO's input requirements, using the same logic.\n",
        "            pil_image = self._resize_image_for_veo(pil_image)\n",
        "\n",
        "            # Use an in-memory buffer to save the image without writing to disk.\n",
        "            buffer = io.BytesIO()\n",
        "            # Save the image to the buffer as a high-quality JPEG.\n",
        "            pil_image.save(buffer, format='JPEG', quality=VEOConfig.JPEG_ENCODING_QUALITY)\n",
        "\n",
        "            # Get the raw byte value and encode it to a utf-8 decoded base64 string.\n",
        "            image_bytes = buffer.getvalue()\n",
        "            base64_encoded = base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "            return base64_encoded\n",
        "\n",
        "        except Exception as e:\n",
        "            # Wrap any conversion errors.\n",
        "            raise VEOVideoGenerationError(f\"Frame to base64 conversion failed: {e}\") from e\n",
        "\n",
        "    def _stitch_videos_ffmpeg(self, video_paths: List[Path], output_path: Path) -> None:\n",
        "        \"\"\"Stitches multiple video files into one using ffmpeg's concat demuxer for efficiency.\"\"\"\n",
        "        # Check if the ffmpeg executable is available in the system's PATH before proceeding.\n",
        "        if not shutil.which(\"ffmpeg\"):\n",
        "            raise FileNotFoundError(\n",
        "                \"ffmpeg not found. Please install ffmpeg and ensure it is in your system's PATH.\"\n",
        "            )\n",
        "\n",
        "        # Ensure there is at least one video to process.\n",
        "        if not video_paths:\n",
        "            raise VEOVideoGenerationError(\"No video clips were provided to stitch.\")\n",
        "\n",
        "        # Create a temporary manifest file for ffmpeg in the same directory as the output.\n",
        "        manifest_path = output_path.with_suffix('.txt')\n",
        "\n",
        "        try:\n",
        "            # Write the list of video files to the manifest in the format required by ffmpeg's concat demuxer.\n",
        "            with open(manifest_path, 'w') as f:\n",
        "                for video_path in video_paths:\n",
        "                    # Verify each video file exists before adding it to the manifest.\n",
        "                    if not video_path.exists():\n",
        "                        raise FileNotFoundError(f\"Video file for stitching not found: {video_path}\")\n",
        "                    # Use resolved absolute paths and quotes to handle spaces or special characters safely.\n",
        "                    f.write(f\"file '{video_path.resolve()}'\\n\")\n",
        "\n",
        "            # Log the creation of the manifest file.\n",
        "            logger.info(f\"Created ffmpeg manifest at: {manifest_path}\")\n",
        "\n",
        "            # Construct the ffmpeg command for efficient, lossless concatenation.\n",
        "            command = [\n",
        "                \"ffmpeg\",\n",
        "                \"-y\",                   # Overwrite output file if it exists.\n",
        "                \"-f\", \"concat\",         # Use the concat demuxer.\n",
        "                \"-safe\", \"0\",           # Allow absolute paths in the manifest file (required for resolved paths).\n",
        "                \"-i\", str(manifest_path), # Specify the input manifest file.\n",
        "                \"-c\", \"copy\",           # Copy codecs without re-encoding for maximum speed and quality preservation.\n",
        "                str(output_path)        # Specify the final output file path.\n",
        "            ]\n",
        "\n",
        "            # Log the command being executed for debugging purposes.\n",
        "            logger.info(f\"Executing ffmpeg command: {' '.join(command)}\")\n",
        "\n",
        "            # Execute the command, capturing stdout and stderr for detailed error reporting.\n",
        "            result = subprocess.run(\n",
        "                command,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                check=False # We check the return code manually for better error logging.\n",
        "            )\n",
        "\n",
        "            # Check if the ffmpeg command executed successfully.\n",
        "            if result.returncode != 0:\n",
        "                # If it failed, raise an error with the detailed stderr from ffmpeg.\n",
        "                raise VEOVideoGenerationError(\n",
        "                    f\"ffmpeg failed with exit code {result.returncode}.\\n\"\n",
        "                    f\"Stderr: {result.stderr}\"\n",
        "                )\n",
        "\n",
        "            # Log the successful completion of the stitching process.\n",
        "            logger.info(f\"Successfully stitched {len(video_paths)} videos into: {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # Wrap any exception in our custom error type.\n",
        "            raise VEOVideoGenerationError(f\"Video stitching failed: {e}\") from e\n",
        "        finally:\n",
        "            # Ensure the temporary manifest file is always cleaned up, even if errors occur.\n",
        "            if manifest_path.exists():\n",
        "                manifest_path.unlink()\n",
        "                logger.info(f\"Cleaned up manifest file: {manifest_path}\")\n",
        "\n",
        "    def generate_sequential_videos(self,\n",
        "        reference_image_path: str,\n",
        "        scene_prompts: List[str],\n",
        "        output_folder_name: str\n",
        "    ) -> Path:\n",
        "        \"\"\"Executes the full pipeline to generate a sequence of chained videos.\"\"\"\n",
        "        try:\n",
        "            # Step 0: Validate all inputs before starting any expensive processing.\n",
        "            self._validate_inputs(reference_image_path, scene_prompts, output_folder_name)\n",
        "\n",
        "            # Step 1: Create the output directory to store all generated artifacts.\n",
        "            output_dir = self._create_output_directory(output_folder_name)\n",
        "\n",
        "            # Step 2: Load and encode the initial reference image to start the sequence.\n",
        "            current_image_data: Optional[str] = self._load_and_encode_image(reference_image_path)\n",
        "\n",
        "            # Initialize a list to store the paths of the generated video segments for later stitching.\n",
        "            video_paths: List[Path] = []\n",
        "\n",
        "            # Step 3: Iterate through each scene prompt to generate a corresponding video segment.\n",
        "            for i, prompt in enumerate(scene_prompts):\n",
        "                logger.info(f\"--- Processing Scene {i+1}/{len(scene_prompts)} ---\")\n",
        "                logger.info(f\"Prompt: '{prompt[:100]}...'\")\n",
        "\n",
        "                # Step 4: Generate a video segment using the current image data and prompt.\n",
        "                prediction = self._generate_video_segment(\n",
        "                    prompt=prompt,\n",
        "                    image_data=current_image_data\n",
        "                )\n",
        "\n",
        "                # Define a unique, ordered filename for this video segment.\n",
        "                video_filename = f\"segment_{i+1:03d}.mp4\"\n",
        "                video_path = output_dir / video_filename\n",
        "\n",
        "                # Step 5: Process the API response, which could contain bytes or a GCS URI.\n",
        "                if 'video_bytes' in prediction:\n",
        "                    # If video bytes are returned directly, decode them from base64 and save to a file.\n",
        "                    logger.info(f\"Received video as base64 bytes. Saving to {video_path}\")\n",
        "                    video_bytes = base64.b64decode(prediction['video_bytes'])\n",
        "                    with open(video_path, 'wb') as f:\n",
        "                        f.write(video_bytes)\n",
        "                elif 'gcs_uri' in prediction:\n",
        "                    # If a GCS URI is returned, download the video from the bucket.\n",
        "                    logger.info(f\"Received GCS URI. Downloading from {prediction['gcs_uri']}\")\n",
        "                    self._download_video_from_gcs(prediction['gcs_uri'], video_path)\n",
        "                else:\n",
        "                    # If neither key is present, the API response is invalid.\n",
        "                    raise VEOVideoGenerationError(f\"API prediction did not contain 'video_bytes' or 'gcs_uri': {prediction}\")\n",
        "\n",
        "                # Add the path of the newly created segment to our list for the final stitching step.\n",
        "                video_paths.append(video_path)\n",
        "\n",
        "                # Step 6: For all but the last prompt, extract the last frame to seed the next segment.\n",
        "                if i < len(scene_prompts) - 1:\n",
        "                    logger.info(\"Extracting last frame to use as reference for the next segment...\")\n",
        "                    last_frame = self._extract_last_frame(video_path)\n",
        "                    current_image_data = self._frame_to_base64(last_frame)\n",
        "\n",
        "            # Step 7: Stitch all generated video segments into a single final video file.\n",
        "            final_video_path = output_dir / \"final_stitched_video.mp4\"\n",
        "            self._stitch_videos_ffmpeg(video_paths, final_video_path)\n",
        "\n",
        "            # Log the successful completion of the entire pipeline.\n",
        "            logger.info(\"--- Sequential video generation pipeline completed successfully. ---\")\n",
        "            logger.info(f\"Final video saved to: {final_video_path}\")\n",
        "\n",
        "            # Return the path to the final product.\n",
        "            return final_video_path\n",
        "\n",
        "        except (VEOVideoGenerationError, ValueError, FileNotFoundError) as e:\n",
        "            # Catch known, specific errors and log them clearly before re-raising.\n",
        "            logger.error(f\"A predictable error occurred in the pipeline: {e}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            # Catch any other unexpected errors for robust failure handling.\n",
        "            logger.error(f\"An unexpected error occurred in the main pipeline: {e}\", exc_info=True)\n",
        "            raise VEOVideoGenerationError(f\"An unexpected error occurred in the main pipeline: {e}\") from e\n",
        "\n",
        "\n",
        "def create_veo_video_pipeline(\n",
        "    reference_image_path: str,\n",
        "    scene_prompts: List[str],\n",
        "    output_folder_name: str,\n",
        "    project_id: Optional[str] = None\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    A high-level factory function to create and run the VEO sequential video pipeline.\n",
        "\n",
        "    This function abstracts away the class instantiation and execution, providing a\n",
        "    simple, clean interface to generate a complete video from an image and prompts.\n",
        "\n",
        "    Args:\n",
        "        reference_image_path (str): Path to the initial reference image file.\n",
        "        scene_prompts (List[str]): An ordered list of scene description prompts.\n",
        "        output_folder_name (str): The name for the output folder in the home directory.\n",
        "        project_id (Optional[str]): Your Google Cloud project ID. If None, it will be\n",
        "                                    auto-detected from ADC or environment variables.\n",
        "\n",
        "    Returns:\n",
        "        Path: The path to the final, stitched video file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # If project_id is not provided, attempt to get it from the environment as a fallback.\n",
        "        if project_id is None:\n",
        "            project_id = os.environ.get('GOOGLE_CLOUD_PROJECT')\n",
        "            if project_id:\n",
        "                logger.info(f\"Using project ID from GOOGLE_CLOUD_PROJECT env var: {project_id}\")\n",
        "\n",
        "        # Initialize the VEO pipeline class with the determined project ID.\n",
        "        pipeline = VEOVideoPipeline(project_id=project_id)\n",
        "\n",
        "        # Execute the complete video generation pipeline with the provided parameters.\n",
        "        final_video_path = pipeline.generate_sequential_videos(\n",
        "            reference_image_path=reference_image_path,\n",
        "            scene_prompts=scene_prompts,\n",
        "            output_folder_name=output_folder_name\n",
        "        )\n",
        "\n",
        "        return final_video_path\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch and log any exceptions from the pipeline for clear top-level error reporting.\n",
        "        logger.error(f\"VEO video pipeline execution failed: {e}\")\n",
        "        # Re-raise the exception to allow the calling script to handle it as needed.\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "J_8LAWbw4vt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Usage Example"
      ],
      "metadata": {
        "id": "J3TBeSdC5BO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage and Testing Block\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    Example usage of the corrected and robust VEO video generation pipeline.\n",
        "\n",
        "    *** IMPORTANT: CONFIGURATION REQUIRED ***\n",
        "    1.  **AUTHENTICATION**: Run `gcloud auth application-default login` in your terminal.\n",
        "    2.  **PROJECT ID**: Set the `GOOGLE_CLOUD_PROJECT` environment variable to your GCP project ID,\n",
        "        or pass the `project_id` argument to `create_veo_video_pipeline`.\n",
        "    3.  **APIs**: Ensure the Vertex AI API is enabled in your Google Cloud project.\n",
        "    4.  **DEPENDENCIES**: Install required packages:\n",
        "        pip install google-cloud-aiplatform google-cloud-storage opencv-python Pillow requests tenacity numpy\n",
        "    5.  **FFMPEG**: Install ffmpeg (https://ffmpeg.org/download.html) and ensure it is in your system's PATH.\n",
        "    6.  **REFERENCE IMAGE**: Replace the dummy image path with a path to your own image.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- CONFIGURE THESE PARAMETERS FOR YOUR RUN ---\n",
        "    try:\n",
        "        # Get the directory of the current script to create a sample image nearby.\n",
        "        script_dir = Path(__file__).parent\n",
        "    except NameError:\n",
        "        # Fallback for interactive environments (like Jupyter) where __file__ is not defined.\n",
        "        script_dir = Path.cwd()\n",
        "\n",
        "    # Create a dummy reference image for testing if one doesn't exist.\n",
        "    dummy_image_path = script_dir / \"veo_reference_image.jpg\"\n",
        "    if not dummy_image_path.exists():\n",
        "        print(f\"Creating a dummy reference image at: {dummy_image_path}\")\n",
        "        # A blue 16:9 image matching VEO's landscape dimensions.\n",
        "        dummy_img = Image.new('RGB', VEOConfig.LANDSCAPE_DIMS, color='darkblue')\n",
        "        dummy_img.save(dummy_image_path)\n",
        "\n",
        "    # Define the parameters for the video generation task.\n",
        "    example_params = {\n",
        "        \"reference_image_path\": str(dummy_image_path),\n",
        "        \"scene_prompts\": [\n",
        "            \"A majestic eagle perched on a rocky cliff overlooking a vast canyon, cinematic lighting.\",\n",
        "            \"The eagle spreads its wings and takes flight into the golden sunset, slow motion.\",\n",
        "            \"Soaring high above snow-capped mountains with clouds below, drone shot.\",\n",
        "            \"The eagle gracefully lands near a crystal clear alpine lake, its reflection in the water.\"\n",
        "        ],\n",
        "        \"output_folder_name\": \"veo_eagle_flight_sequence\",\n",
        "        # \"project_id\": \"your-gcp-project-id\"  # Optional: uncomment and set if needed.\n",
        "    }\n",
        "\n",
        "    print(\"--- Starting VEO Video Generation Pipeline ---\")\n",
        "    print(f\"Reference Image: {example_params['reference_image_path']}\")\n",
        "    print(f\"Output Folder Name: {example_params['output_folder_name']}\")\n",
        "    print(f\"Number of Scenes: {len(example_params['scene_prompts'])}\")\n",
        "\n",
        "    try:\n",
        "        # Execute the pipeline and time its execution.\n",
        "        start_time = time.time()\n",
        "        final_video = create_veo_video_pipeline(**example_params)\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Print a clear success message with the final output path and total time.\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"‚úÖ Video generation pipeline completed successfully!\")\n",
        "        print(f\"üìπ Final video saved to: {final_video}\")\n",
        "        print(f\"‚è±Ô∏è Total execution time: {end_time - start_time:.2f} seconds.\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    except (VEOVideoGenerationError, ValueError, FileNotFoundError) as e:\n",
        "        # Handle known, controlled pipeline failures gracefully with a clear error message.\n",
        "        print(f\"\\n‚ùå PIPELINE FAILED: {e}\")\n",
        "        sys.exit(1)\n",
        "    except Exception as e:\n",
        "        # Handle any other unexpected errors to prevent unhandled stack traces.\n",
        "        print(f\"\\n‚ùå AN UNEXPECTED ERROR OCCURRED: {e}\")\n",
        "        sys.exit(1)\n"
      ],
      "metadata": {
        "id": "8uQBJgZJ4_L6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}